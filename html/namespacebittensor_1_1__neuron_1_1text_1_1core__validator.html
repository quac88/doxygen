<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Bittensor: bittensor._neuron.text.core_validator Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">var page_layout=1;</script>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="side-nav" class="ui-resizable side-nav-resizable"><!-- do not remove this div, it is closed by doxygen! -->
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Bittensor
   </div>
   <div id="projectbrief">Python API</div>
  </td>
 </tr>
   <tr><td colspan="2">        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td></tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">bittensor._neuron.text.core_validator Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="namespaces" name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespacebittensor_1_1__neuron_1_1text_1_1core__validator_1_1main"><td class="memItemLeft" align="right" valign="top">namespace &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator_1_1main.html">main</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__validator_1_1neuron.html">neuron</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__validator_1_1nucleus.html">nucleus</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:afbddc9ae968b91105cb4845cdec271d8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#afbddc9ae968b91105cb4845cdec271d8">scaling_law_loss_to_params</a> (loss)</td></tr>
<tr class="separator:afbddc9ae968b91105cb4845cdec271d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a156659d617f14885b3e5c58286bf0ef5"><td class="memItemLeft" align="right" valign="top">Tuple[torch.FloatTensor, Dict]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#a156659d617f14885b3e5c58286bf0ef5">textcausallm</a> (torch.Tensor uids, List[List[torch.FloatTensor]] query_responses, List[torch.LongTensor] return_ops, List[torch.FloatTensor] times, torch.FloatTensor routing_score, torch.FloatTensor inputs, int validation_len, Callable loss_fct, float scaling_law_power, float synergy_scaling_law_power, float logits_divergence_penalty, int console_width, <a class="el" href="classbittensor_1_1__logging_1_1logging.html">logging</a>, '<a class="el" href="classbittensor_1_1__synapse_1_1text__causallm__impl_1_1_text_causal_l_m.html">bittensor.TextCausalLM</a>' <a class="el" href="classbittensor_1_1__synapse_1_1synapse.html">synapse</a>=None, int index_s=0)</td></tr>
<tr class="separator:a156659d617f14885b3e5c58286bf0ef5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae13e132bc899ab97f56d1243dfdd9628"><td class="memItemLeft" align="right" valign="top">Tuple[torch.FloatTensor, Dict]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#ae13e132bc899ab97f56d1243dfdd9628">textcausallmnext</a> (torch.Tensor uids, List[List[torch.FloatTensor]] query_responses, List[torch.LongTensor] return_ops, List[torch.FloatTensor] times, torch.FloatTensor routing_score, torch.FloatTensor inputs, int validation_len, Callable loss_fct, float scaling_law_power, float synergy_scaling_law_power, float logits_divergence_penalty, int console_width, <a class="el" href="classbittensor_1_1__logging_1_1logging.html">logging</a>, '<a class="el" href="classbittensor_1_1__synapse_1_1text__causallmnext__impl_1_1_text_causal_l_m_next.html">bittensor.TextCausalLMNext</a>' <a class="el" href="classbittensor_1_1__synapse_1_1synapse.html">synapse</a>=None, int index_s=0)</td></tr>
<tr class="separator:ae13e132bc899ab97f56d1243dfdd9628"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a826517b0b4f17e635dafcc3076a57a43"><td class="memItemLeft" align="right" valign="top">Tuple[Union[float, torch.FloatTensor], Dict, List]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#a826517b0b4f17e635dafcc3076a57a43">shapley_base</a> (torch.Tensor uids, List[List[torch.FloatTensor]] query_responses, List[torch.LongTensor] return_ops, List[torch.FloatTensor] times, torch.FloatTensor routing_score, Callable base_params, int index_s=0, str ext=None)</td></tr>
<tr class="separator:a826517b0b4f17e635dafcc3076a57a43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3d48b0eacf487ad14a36ef50ef21df07"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#a3d48b0eacf487ad14a36ef50ef21df07">logits_divergence</a> (Dict stats, torch.Tensor uids, List[List[torch.FloatTensor]] query_responses, List[torch.LongTensor] return_ops, List[torch.FloatTensor] times, int index_s=0, str ext=None)</td></tr>
<tr class="separator:a3d48b0eacf487ad14a36ef50ef21df07"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bd51d8fbf1d03308c1beb60fd961dd1"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#a1bd51d8fbf1d03308c1beb60fd961dd1">shapley_synergy</a> (Dict stats, Callable synergy, str ext, torch.Tensor target=None, float scaling_law_power=0.5)</td></tr>
<tr class="separator:a1bd51d8fbf1d03308c1beb60fd961dd1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad73b7e74829f07cd55e096f14a9a39a8"><td class="memItemLeft" align="right" valign="top">List&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#ad73b7e74829f07cd55e096f14a9a39a8">format_predictions</a> (torch.Tensor uids, List[List[torch.FloatTensor]] query_responses, List[torch.LongTensor] return_ops, torch.FloatTensor inputs, int validation_len, int index_s=0, int number_of_predictions=3)</td></tr>
<tr class="separator:ad73b7e74829f07cd55e096f14a9a39a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c000ee81cd21336cf103755b8ffbe89"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#a0c000ee81cd21336cf103755b8ffbe89">response_table</a> (List batch_predictions, Dict stats, str sort_col, int console_width, int task_repeat=4, int tasks_per_server=3)</td></tr>
<tr class="separator:a0c000ee81cd21336cf103755b8ffbe89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6fd9748649f8e6a6f82cbbcb48b164a4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#a6fd9748649f8e6a6f82cbbcb48b164a4">synergy_table</a> (stats, syn_loss_diff, sort_col, console_width)</td></tr>
<tr class="separator:a6fd9748649f8e6a6f82cbbcb48b164a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3b98321f53ed9671d10985f26470e151"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#a3b98321f53ed9671d10985f26470e151">stats_table</a> (stats, sort_col, console_width, title, caption, mark_uids=None)</td></tr>
<tr class="separator:a3b98321f53ed9671d10985f26470e151"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac65c768421ed57928ee56b3da28e5cf8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#ac65c768421ed57928ee56b3da28e5cf8">synapse_table</a> (name, stats, sort_col, console_width, start_time)</td></tr>
<tr class="separator:ac65c768421ed57928ee56b3da28e5cf8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1b9785136040aef8a5a3e0588151ca1"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html#ab1b9785136040aef8a5a3e0588151ca1">unsuccess</a> (_name, _unsuccessful)</td></tr>
<tr class="separator:ab1b9785136040aef8a5a3e0588151ca1"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:abf245d31bf2b69b6542bb98662ae1b70"><td class="memItemLeft" align="right" valign="top"><a id="abf245d31bf2b69b6542bb98662ae1b70" name="abf245d31bf2b69b6542bb98662ae1b70"></a>
logger&#160;</td><td class="memItemRight" valign="bottom"><b>logger</b> = logger.opt( colors=True )</td></tr>
<tr class="separator:abf245d31bf2b69b6542bb98662ae1b70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac66a622a85b1ee7ea03d6442aa7a04c0"><td class="memItemLeft" align="right" valign="top"><a id="ac66a622a85b1ee7ea03d6442aa7a04c0" name="ac66a622a85b1ee7ea03d6442aa7a04c0"></a>
Console&#160;</td><td class="memItemRight" valign="bottom"><b>console</b> = Console()</td></tr>
<tr class="separator:ac66a622a85b1ee7ea03d6442aa7a04c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6117e317add107345576af8a89a59aa7"><td class="memItemLeft" align="right" valign="top"><a id="a6117e317add107345576af8a89a59aa7" name="a6117e317add107345576af8a89a59aa7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>show_locals</b></td></tr>
<tr class="separator:a6117e317add107345576af8a89a59aa7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81427319fc32ca2122c1af5aeec009a6"><td class="memItemLeft" align="right" valign="top"><a id="a81427319fc32ca2122c1af5aeec009a6" name="a81427319fc32ca2122c1af5aeec009a6"></a>
list&#160;</td><td class="memItemRight" valign="bottom"><b>neuron_stats_columns</b></td></tr>
<tr class="separator:a81427319fc32ca2122c1af5aeec009a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment"> The bittensor base validator

Example:
    $ python3 miners/text/core_validator.py --logging.debug</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="ad73b7e74829f07cd55e096f14a9a39a8" name="ad73b7e74829f07cd55e096f14a9a39a8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad73b7e74829f07cd55e096f14a9a39a8">&#9670;&#160;</a></span>format_predictions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> List bittensor._neuron.text.core_validator.format_predictions </td>
          <td>(</td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>uids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[List[torch.FloatTensor]]&#160;</td>
          <td class="paramname"><em>query_responses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.LongTensor]&#160;</td>
          <td class="paramname"><em>return_ops</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>validation_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>index_s</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>number_of_predictions</em> = <code>3</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Format batch task topk predictions for rich table print of query responses.
</pre> 
</div>
</div>
<a id="a3d48b0eacf487ad14a36ef50ef21df07" name="a3d48b0eacf487ad14a36ef50ef21df07"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3d48b0eacf487ad14a36ef50ef21df07">&#9670;&#160;</a></span>logits_divergence()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_validator.logits_divergence </td>
          <td>(</td>
          <td class="paramtype">Dict&#160;</td>
          <td class="paramname"><em>stats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>uids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[List[torch.FloatTensor]]&#160;</td>
          <td class="paramname"><em>query_responses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.LongTensor]&#160;</td>
          <td class="paramname"><em>return_ops</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.FloatTensor]&#160;</td>
          <td class="paramname"><em>times</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>index_s</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>ext</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculate each logits divergence per neuron per task from the average logits over all neurons per task,
given responses from a synapse.
Args:
stats (:obj:`Dict`, `required`):
Statistics per endpoint for this batch.
uids (:obj:`torch.Tensor`, `required`): [num_neurons]
Neuron UIDs.
query_responses (:obj:`List[List[torch.FloatTensor]]`, `required`):
List of outputs from synapses, each a list of size num_endpoints of tensors with relevant size.
Non-responses are zeroes of relevant synapse shape.
Shape num_synapses * ( num_endpoints * ( -1, -1, -1 ) )
return_ops (:obj:`List[torch.LongTensor]` of shape :obj:`[num_endpoints]`, `required`):
Return code per call per synapse.
times (:obj:`List [torch.FloatTensor]` of shape :obj:`[num_endpoints]`, `required`):
Times per call per synapse.
index_s (:obj:`int`, `optional`):
Index of synapse to extract responses.
ext (:obj:`str`, `optional`):
Extension to parameter string for stats key.
</pre> 
</div>
</div>
<a id="a0c000ee81cd21336cf103755b8ffbe89" name="a0c000ee81cd21336cf103755b8ffbe89"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c000ee81cd21336cf103755b8ffbe89">&#9670;&#160;</a></span>response_table()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_validator.response_table </td>
          <td>(</td>
          <td class="paramtype">List&#160;</td>
          <td class="paramname"><em>batch_predictions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Dict&#160;</td>
          <td class="paramname"><em>stats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>sort_col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>console_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>task_repeat</em> = <code>4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>tasks_per_server</em> = <code>3</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Prints the query response table: top prediction probabilities and texts for batch tasks.
</pre> 
</div>
</div>
<a id="afbddc9ae968b91105cb4845cdec271d8" name="afbddc9ae968b91105cb4845cdec271d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afbddc9ae968b91105cb4845cdec271d8">&#9670;&#160;</a></span>scaling_law_loss_to_params()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_validator.scaling_law_loss_to_params </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>loss</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> (OpenAI scaling laws) Kaplan, Jared, et al. "Scaling laws for neural language models." arXiv:2001.08361 (2020)
</pre> 
</div>
</div>
<a id="a826517b0b4f17e635dafcc3076a57a43" name="a826517b0b4f17e635dafcc3076a57a43"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a826517b0b4f17e635dafcc3076a57a43">&#9670;&#160;</a></span>shapley_base()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[Union[float, torch.FloatTensor],
                                                                                    Dict,
                                                                                    List] bittensor._neuron.text.core_validator.shapley_base </td>
          <td>(</td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>uids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[List[torch.FloatTensor]]&#160;</td>
          <td class="paramname"><em>query_responses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.LongTensor]&#160;</td>
          <td class="paramname"><em>return_ops</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.FloatTensor]&#160;</td>
          <td class="paramname"><em>times</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>routing_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Callable&#160;</td>
          <td class="paramname"><em>base_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>index_s</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>ext</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculate Shapley base values and neuron response validation measure statistics, given responses from a synapse.
    Args:
        uids (:obj:`torch.Tensor`, `required`): [num_neurons]
            Neuron UIDs.
        query_responses (:obj:`List[List[torch.FloatTensor]]`, `required`):
            List of outputs from synapses, each a list of size num_endpoints of tensors with relevant size. Non-responses are zeroes of relevant
            synapse shape. Shape num_synapses * ( num_endpoints * ( -1, -1, -1 ) )
        return_ops (:obj:`List[torch.LongTensor]` of shape :obj:`[num_endpoints]`, `required`):
            Return code per call per synapse.
        times (:obj:`List [torch.FloatTensor]` of shape :obj:`[num_endpoints]`, `required`):
            Times per call per synapse.
        routing_score (:obj:`torch.FloatTensor`, `required`):
            [metagraph.n] Predictive routing score per endpoint in the metagraph, mean over the batch.
        base_params (:obj:`Callable`, `required`):
            CrossEntropy loss function to use.
        index_s (:obj:`int`, `optional`):
            Index of synapse to extract responses.
        ext (:obj:`str`, `optional`):
            Extension to parameter string for stats key.

    Returns:
        loss (:obj:`torch.FloatTensor`):
            Loss for training validator nucleus and dendrite backward to endpoints.
        stats (:obj:`Dict`, `required`):
            Statistics per endpoint for this batch.
        unsuccessful (:obj:`List`, `required`):
            Unsuccessful endpoints [(uid, return_op, time)].
</pre> 
</div>
</div>
<a id="a1bd51d8fbf1d03308c1beb60fd961dd1" name="a1bd51d8fbf1d03308c1beb60fd961dd1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1bd51d8fbf1d03308c1beb60fd961dd1">&#9670;&#160;</a></span>shapley_synergy()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_validator.shapley_synergy </td>
          <td>(</td>
          <td class="paramtype">Dict&#160;</td>
          <td class="paramname"><em>stats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Callable&#160;</td>
          <td class="paramname"><em>synergy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>ext</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.Tensor &#160;</td>
          <td class="paramname"><em>target</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>scaling_law_power</em> = <code>0.5</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculates Shapley synergy for coalition size 2, measured performance above expected performance.
Measured in effective number of model parameters, just like base Shapley values.
Args:
stats (:obj:`Dict`, `required`):
Statistics per endpoint for this batch.
synergy (:obj:`Callable`, `required`)
Function to calculate measured loss.
ext (:obj:`str`, `optional`):
Extension to parameter string for stats key.
target (:obj:`torch.Tensor`, `optional`):
Target to measure loss against.
scaling_law_power (:obj:`float`, `optional`):
Power for modified scaling law, powered down to improve dynamic range, e.g. 3 → 6 nats for 0.5.

Returns:
syn_loss_diff (:obj:`Dict`, `required`):
Dictionary table of pairwise synergies as loss reductions, with direct loss on diagonal.
</pre> 
</div>
</div>
<a id="a3b98321f53ed9671d10985f26470e151" name="a3b98321f53ed9671d10985f26470e151"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3b98321f53ed9671d10985f26470e151">&#9670;&#160;</a></span>stats_table()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_validator.stats_table </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sort_col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>console_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>title</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>caption</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mark_uids</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Gathers data and constructs neuron statistics table and prints it
</pre> 
</div>
</div>
<a id="ac65c768421ed57928ee56b3da28e5cf8" name="ac65c768421ed57928ee56b3da28e5cf8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac65c768421ed57928ee56b3da28e5cf8">&#9670;&#160;</a></span>synapse_table()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_validator.synapse_table </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sort_col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>console_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>start_time</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Prints the evaluation of the neuron responses to the validator request
</pre> 
</div>
</div>
<a id="a6fd9748649f8e6a6f82cbbcb48b164a4" name="a6fd9748649f8e6a6f82cbbcb48b164a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6fd9748649f8e6a6f82cbbcb48b164a4">&#9670;&#160;</a></span>synergy_table()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_validator.synergy_table </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stats</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>syn_loss_diff</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sort_col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>console_width</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Prints the synergy loss diff matrix with pairwise loss reduction due to synergy (original loss on diagonal)
</pre> 
</div>
</div>
<a id="a156659d617f14885b3e5c58286bf0ef5" name="a156659d617f14885b3e5c58286bf0ef5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a156659d617f14885b3e5c58286bf0ef5">&#9670;&#160;</a></span>textcausallm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[torch.FloatTensor, Dict] bittensor._neuron.text.core_validator.textcausallm </td>
          <td>(</td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>uids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[List[torch.FloatTensor]]&#160;</td>
          <td class="paramname"><em>query_responses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.LongTensor]&#160;</td>
          <td class="paramname"><em>return_ops</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.FloatTensor]&#160;</td>
          <td class="paramname"><em>times</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>routing_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>validation_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Callable&#160;</td>
          <td class="paramname"><em>loss_fct</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>scaling_law_power</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>synergy_scaling_law_power</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>logits_divergence_penalty</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>console_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>logging</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">'<a class="el" href="classbittensor_1_1__synapse_1_1text__causallm__impl_1_1_text_causal_l_m.html">bittensor.TextCausalLM</a>' &#160;</td>
          <td class="paramname"><em>synapse</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>index_s</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculate Shapley values and neuron response validation measure statistics, given TextCausalLM synapse responses.
Args:
    uids (:obj:`torch.Tensor`, `required`): [num_neurons]
        Neuron UIDs.
    query_responses (:obj:`List[List[torch.FloatTensor]]`, `required`):
        List of outputs from synapses, each a list of size num_endpoints of tensors with relevant size. Non-responses are zeroes of relevant
        synapse shape. Shape num_synapses * ( num_endpoints * ( -1, -1, -1 ) )
    return_ops (:obj:`List[torch.LongTensor]` of shape :obj:`[num_endpoints]`, `required`):
        Return code per call per synapse.
    times (:obj:`List [torch.FloatTensor]` of shape :obj:`[num_endpoints]`, `required`):
        Times per call per synapse.
    routing_score (:obj:`torch.FloatTensor`, `required`):
        [metagraph.n] Predictive routing score per endpoint in the metagraph, mean over the batch.
    inputs (:obj:`torch.FloatTensor`, `required`):
        [batch_size, sequence_len + validation_len] Token batch of original inputs with validation tokens.
    validation_len (:obj:`int`, `required`):
        Number of held-out phrase token batch for extended validation, not sent to neurons.
    loss_fct (:obj:`Callable`, `required`):
        CrossEntropy loss function to use.
    scaling_law_power (:obj:`float`, `required`):
        Power for modified scaling law, powered down to improve dynamic range, e.g. 3 → 6 nats for 0.5.
    synergy_scaling_law_power (:obj:`float`, `required`):
        Power for synergy modified scaling law, powered down to improve dynamic range, e.g. 3 → 6 nats for 0.5.
    logits_divergence_penalty (:obj:`float`, `required`):
        Penalty scaling for logits divergence.
    console_width (:obj:`int`, `required`):
        Config console width for table print.
    logging (:obj:`bool`, `required`):
        Log tables to console.
    synapse (:obj:`bittensor.TextCausalLM`, `optional`):
        TextCausalLM synapse object.
    index_s (:obj:`int`, `optional`):
        Index of synapse to extract responses.

Returns:
    loss (:obj:`torch.FloatTensor`):
        Loss for training validator nucleus and dendrite backward to endpoints.
    stats (:obj:`Dict`, `required`):
        Statistics per endpoint for this batch.
</pre> 
</div>
</div>
<a id="ae13e132bc899ab97f56d1243dfdd9628" name="ae13e132bc899ab97f56d1243dfdd9628"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae13e132bc899ab97f56d1243dfdd9628">&#9670;&#160;</a></span>textcausallmnext()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[torch.FloatTensor, Dict] bittensor._neuron.text.core_validator.textcausallmnext </td>
          <td>(</td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>uids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[List[torch.FloatTensor]]&#160;</td>
          <td class="paramname"><em>query_responses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.LongTensor]&#160;</td>
          <td class="paramname"><em>return_ops</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.FloatTensor]&#160;</td>
          <td class="paramname"><em>times</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>routing_score</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>validation_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Callable&#160;</td>
          <td class="paramname"><em>loss_fct</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>scaling_law_power</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>synergy_scaling_law_power</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>logits_divergence_penalty</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>console_width</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>logging</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">'<a class="el" href="classbittensor_1_1__synapse_1_1text__causallmnext__impl_1_1_text_causal_l_m_next.html">bittensor.TextCausalLMNext</a>' &#160;</td>
          <td class="paramname"><em>synapse</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>index_s</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculate Shapley values and neuron response validation measure statistics, given TextCausalLMNext synapse responses.
    Args:
        uids (:obj:`torch.Tensor`, `required`): [num_neurons]
            Neuron UIDs.
        query_responses (:obj:`List[List[torch.FloatTensor]]`, `required`):
            List of outputs from synapses, each a list of size num_endpoints of tensors with relevant size. Non-responses are zeroes of relevant
            synapse shape. Shape num_synapses * ( num_endpoints * ( -1, -1, -1 ) )
        return_ops (:obj:`List[torch.LongTensor]` of shape :obj:`[num_endpoints]`, `required`):
            Return code per call per synapse.
        times (:obj:`List [torch.FloatTensor]` of shape :obj:`[num_endpoints]`, `required`):
            Times per call per synapse.
        routing_score (:obj:`torch.FloatTensor`, `required`):
            [metagraph.n] Predictive routing score per endpoint in the metagraph, mean over the batch.
        inputs (:obj:`torch.FloatTensor`, `required`):
            [batch_size, sequence_len + validation_len] Token batch of original inputs with validation tokens.
        validation_len (:obj:`int`, `required`):
            Number of held-out phrase token batch for extended validation, not sent to neurons.
        loss_fct (:obj:`Callable`, `required`):
            CrossEntropy loss function to use.
        scaling_law_power (:obj:`float`, `required`):
            Power for modified scaling law, powered down to improve dynamic range, e.g. 3 → 6 nats for 0.5.
        synergy_scaling_law_power (:obj:`float`, `required`):
            Power for synergy modified scaling law, powered down to improve dynamic range, e.g. 3 → 6 nats for 0.5.
        logits_divergence_penalty (:obj:`float`, `required`):
            Penalty scaling for logits divergence.
        console_width (:obj:`int`, `required`):
            Config console width for table print.
        logging (:obj:`bool`, `required`):
            Log tables to console.
        synapse (:obj:`bittensor.TextCausalLMNext`, `optional`):
            TextCausalLMNext Synapse object.
        index_s (:obj:`int`, `optional`):
            Index of synapse to extract responses.

    Returns:
        loss (:obj:`torch.FloatTensor`):
            Loss for training validator nucleus and dendrite backward to endpoints.
        stats (:obj:`Dict`, `required`):
            Statistics per endpoint for this batch.
</pre> 
</div>
</div>
<a id="ab1b9785136040aef8a5a3e0588151ca1" name="ab1b9785136040aef8a5a3e0588151ca1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1b9785136040aef8a5a3e0588151ca1">&#9670;&#160;</a></span>unsuccess()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_validator.unsuccess </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>_unsuccessful</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Prints the return codes and response times of unsuccessful responses
</pre> 
</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>bittensor</b></li><li class="navelem"><b>_neuron</b></li><li class="navelem"><b>text</b></li><li class="navelem"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__validator.html">core_validator</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6 </li>
  </ul>
</div>
</body>
</html>
