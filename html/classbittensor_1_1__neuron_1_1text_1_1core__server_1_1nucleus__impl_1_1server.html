<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Bittensor: bittensor._neuron.text.core_server.nucleus_impl.server Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">var page_layout=1;</script>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="side-nav" class="ui-resizable side-nav-resizable"><!-- do not remove this div, it is closed by doxygen! -->
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Bittensor
   </div>
   <div id="projectbrief">Python API</div>
  </td>
 </tr>
   <tr><td colspan="2">        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td></tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">bittensor._neuron.text.core_server.nucleus_impl.server Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for bittensor._neuron.text.core_server.nucleus_impl.server:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.png" alt=""/>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a6132e85ef58f7a42c1fe91a77ce700d7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#a6132e85ef58f7a42c1fe91a77ce700d7">__init__</a> (self, '<a class="el" href="classbittensor_1_1__config_1_1config.html">bittensor.config</a>' <a class="el" href="classbittensor_1_1__config_1_1config.html">config</a>=None, bool pretrained=None, str model_name=None, bool padding=None, bool interpolate=None, str inter_degree=None, model=None, <a class="el" href="classbittensor_1_1__tokenizer_1_1tokenizer.html">tokenizer</a>=None, mapping_function=None, token_remap=None, checking=None)</td></tr>
<tr class="separator:a6132e85ef58f7a42c1fe91a77ce700d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a614100716e4fce09e4e00b12ee6ef1f5"><td class="memItemLeft" align="right" valign="top">Tuple[bool, str]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#a614100716e4fce09e4e00b12ee6ef1f5">set_fine_tuning_params</a> (self)</td></tr>
<tr class="separator:a614100716e4fce09e4e00b12ee6ef1f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62d78b2d208bf64fb184ce6dff244949"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#a62d78b2d208bf64fb184ce6dff244949">remapping_token</a> (self, token_batch, std_tokenizer=None, return_offsets_mapping=False)</td></tr>
<tr class="separator:a62d78b2d208bf64fb184ce6dff244949"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1bba88e9b29c127cc9086eafa8ccb38"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#ae1bba88e9b29c127cc9086eafa8ccb38">forward</a> (self, inputs, <a class="el" href="classbittensor_1_1__tokenizer_1_1tokenizer.html">tokenizer</a>=None)</td></tr>
<tr class="separator:ae1bba88e9b29c127cc9086eafa8ccb38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6638393fba593635bf489b0575b80752"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#a6638393fba593635bf489b0575b80752">local_forward</a> (self, token_batch, <a class="el" href="classbittensor_1_1__tokenizer_1_1tokenizer.html">tokenizer</a>=None, encode_len=bittensor.__network_dim__, model_output=None)</td></tr>
<tr class="separator:a6638393fba593635bf489b0575b80752"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab592da0bacc745c98011d8e064190570"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#ab592da0bacc745c98011d8e064190570">encode_forward</a> (self, inputs, <a class="el" href="classbittensor_1_1__tokenizer_1_1tokenizer.html">tokenizer</a>=None, model_output=None)</td></tr>
<tr class="separator:ab592da0bacc745c98011d8e064190570"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9fe04678b6dcce05a3f9d3f25b31d65f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#a9fe04678b6dcce05a3f9d3f25b31d65f">encode_forward_causallm</a> (self, token_batch, <a class="el" href="classbittensor_1_1__tokenizer_1_1tokenizer.html">tokenizer</a>=None, encode_len=bittensor.__network_dim__, model_output=None)</td></tr>
<tr class="separator:a9fe04678b6dcce05a3f9d3f25b31d65f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa75186146bb39740317a5476a71261ec"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#aa75186146bb39740317a5476a71261ec">encode_forward_causallmnext</a> (self, token_batch, std_tokenizer=None, int topk=4096, model_output=None)</td></tr>
<tr class="separator:aa75186146bb39740317a5476a71261ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af1ec54d7eb69b55a7c551c37bcb01930"><td class="memItemLeft" align="right" valign="top">torch.FloatTensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#af1ec54d7eb69b55a7c551c37bcb01930">get_loss_fct</a> (self, torch.FloatTensor logits, torch.LongTensor labels)</td></tr>
<tr class="separator:af1ec54d7eb69b55a7c551c37bcb01930"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99bcd6cc84c562d1db5cac8e585576d7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html#a99bcd6cc84c562d1db5cac8e585576d7">check</a> (self)</td></tr>
<tr class="separator:a99bcd6cc84c562d1db5cac8e585576d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f32537bd1c84dc6ddcdc2af36bbf093"><td class="memItemLeft" align="right" valign="top"><a id="a0f32537bd1c84dc6ddcdc2af36bbf093" name="a0f32537bd1c84dc6ddcdc2af36bbf093"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>save</b> (self, path)</td></tr>
<tr class="separator:a0f32537bd1c84dc6ddcdc2af36bbf093"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b538863118440e2e0c708c9ecab5caa"><td class="memItemLeft" align="right" valign="top"><a id="a6b538863118440e2e0c708c9ecab5caa" name="a6b538863118440e2e0c708c9ecab5caa"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>load</b> (self, path)</td></tr>
<tr class="separator:a6b538863118440e2e0c708c9ecab5caa"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:ab73ed844f7bac4c98193de3a20df9779"><td class="memItemLeft" align="right" valign="top"><a id="ab73ed844f7bac4c98193de3a20df9779" name="ab73ed844f7bac4c98193de3a20df9779"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>config</b> ()</td></tr>
<tr class="separator:ab73ed844f7bac4c98193de3a20df9779"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a1fe51e3db9d34b727f1065d635974c4e"><td class="memItemLeft" align="right" valign="top"><a id="a1fe51e3db9d34b727f1065d635974c4e" name="a1fe51e3db9d34b727f1065d635974c4e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>config</b></td></tr>
<tr class="separator:a1fe51e3db9d34b727f1065d635974c4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ea0c9a2c94e7361a527199d06c2e7a7"><td class="memItemLeft" align="right" valign="top"><a id="a2ea0c9a2c94e7361a527199d06c2e7a7" name="a2ea0c9a2c94e7361a527199d06c2e7a7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>std_tokenizer</b></td></tr>
<tr class="separator:a2ea0c9a2c94e7361a527199d06c2e7a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae899ad3334d1974b0a39a10e30367abf"><td class="memItemLeft" align="right" valign="top"><a id="ae899ad3334d1974b0a39a10e30367abf" name="ae899ad3334d1974b0a39a10e30367abf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>device</b></td></tr>
<tr class="separator:ae899ad3334d1974b0a39a10e30367abf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58719232feeb83555ed82117b6fa0f0d"><td class="memItemLeft" align="right" valign="top"><a id="a58719232feeb83555ed82117b6fa0f0d" name="a58719232feeb83555ed82117b6fa0f0d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>model_name</b></td></tr>
<tr class="separator:a58719232feeb83555ed82117b6fa0f0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43a711aa5b2f3fb5f3e0444c0b348d2c"><td class="memItemLeft" align="right" valign="top"><a id="a43a711aa5b2f3fb5f3e0444c0b348d2c" name="a43a711aa5b2f3fb5f3e0444c0b348d2c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>pretrained</b></td></tr>
<tr class="separator:a43a711aa5b2f3fb5f3e0444c0b348d2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19dd46f7b10bcf825fceef96966c5273"><td class="memItemLeft" align="right" valign="top"><a id="a19dd46f7b10bcf825fceef96966c5273" name="a19dd46f7b10bcf825fceef96966c5273"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>pre_model</b></td></tr>
<tr class="separator:a19dd46f7b10bcf825fceef96966c5273"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2fb1f8356881cc49cc3d29e12ab5dfc"><td class="memItemLeft" align="right" valign="top"><a id="af2fb1f8356881cc49cc3d29e12ab5dfc" name="af2fb1f8356881cc49cc3d29e12ab5dfc"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>tokenizer</b></td></tr>
<tr class="separator:af2fb1f8356881cc49cc3d29e12ab5dfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b2ffcddff2457f054c9a8defe165bea"><td class="memItemLeft" align="right" valign="top"><a id="a9b2ffcddff2457f054c9a8defe165bea" name="a9b2ffcddff2457f054c9a8defe165bea"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>to_translation_map</b></td></tr>
<tr class="separator:a9b2ffcddff2457f054c9a8defe165bea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98a186d02407406e0600f46340c04cc0"><td class="memItemLeft" align="right" valign="top"><a id="a98a186d02407406e0600f46340c04cc0" name="a98a186d02407406e0600f46340c04cc0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>from_translation_map</b></td></tr>
<tr class="separator:a98a186d02407406e0600f46340c04cc0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a21794b8b4d9c313aa791915cc710105d"><td class="memItemLeft" align="right" valign="top"><a id="a21794b8b4d9c313aa791915cc710105d" name="a21794b8b4d9c313aa791915cc710105d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>split_map_cache</b></td></tr>
<tr class="separator:a21794b8b4d9c313aa791915cc710105d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae8c3bbd769bb479e7ee08d86452f4115"><td class="memItemLeft" align="right" valign="top"><a id="ae8c3bbd769bb479e7ee08d86452f4115" name="ae8c3bbd769bb479e7ee08d86452f4115"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>final_dim</b></td></tr>
<tr class="separator:ae8c3bbd769bb479e7ee08d86452f4115"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91f231d0ec2453812dbba74395ace7d5"><td class="memItemLeft" align="right" valign="top"><a id="a91f231d0ec2453812dbba74395ace7d5" name="a91f231d0ec2453812dbba74395ace7d5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>pre_dimension</b></td></tr>
<tr class="separator:a91f231d0ec2453812dbba74395ace7d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8d8826166f382eb1e2d2f877010737e"><td class="memItemLeft" align="right" valign="top"><a id="aa8d8826166f382eb1e2d2f877010737e" name="aa8d8826166f382eb1e2d2f877010737e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>padding</b></td></tr>
<tr class="separator:aa8d8826166f382eb1e2d2f877010737e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e361a0163795bb84e3ed0c0d8aea22a"><td class="memItemLeft" align="right" valign="top"><a id="a8e361a0163795bb84e3ed0c0d8aea22a" name="a8e361a0163795bb84e3ed0c0d8aea22a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>interpolate</b></td></tr>
<tr class="separator:a8e361a0163795bb84e3ed0c0d8aea22a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b00d04e2efafcd5ab2ef09a0f6e95ec"><td class="memItemLeft" align="right" valign="top"><a id="a4b00d04e2efafcd5ab2ef09a0f6e95ec" name="a4b00d04e2efafcd5ab2ef09a0f6e95ec"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>inter_degree</b></td></tr>
<tr class="separator:a4b00d04e2efafcd5ab2ef09a0f6e95ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0eb233826f22d6a7b03844043ea20102"><td class="memItemLeft" align="right" valign="top"><a id="a0eb233826f22d6a7b03844043ea20102" name="a0eb233826f22d6a7b03844043ea20102"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>checking</b></td></tr>
<tr class="separator:a0eb233826f22d6a7b03844043ea20102"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73c162f7a06d87ef824b2da7c1a1cdb0"><td class="memItemLeft" align="right" valign="top"><a id="a73c162f7a06d87ef824b2da7c1a1cdb0" name="a73c162f7a06d87ef824b2da7c1a1cdb0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>mapping_function</b></td></tr>
<tr class="separator:a73c162f7a06d87ef824b2da7c1a1cdb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e684c0f6202d453f185afba381919be"><td class="memItemLeft" align="right" valign="top"><a id="a3e684c0f6202d453f185afba381919be" name="a3e684c0f6202d453f185afba381919be"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>token_remap</b></td></tr>
<tr class="separator:a3e684c0f6202d453f185afba381919be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24846bd379930a27372f3ae3f3254dc7"><td class="memItemLeft" align="right" valign="top"><a id="a24846bd379930a27372f3ae3f3254dc7" name="a24846bd379930a27372f3ae3f3254dc7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>mapping</b></td></tr>
<tr class="separator:a24846bd379930a27372f3ae3f3254dc7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9d0050ad9132134af85214098b41b8b"><td class="memItemLeft" align="right" valign="top"><a id="af9d0050ad9132134af85214098b41b8b" name="af9d0050ad9132134af85214098b41b8b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>decoder</b></td></tr>
<tr class="separator:af9d0050ad9132134af85214098b41b8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a499385f44e3a8639cb02a41a18adf969"><td class="memItemLeft" align="right" valign="top"><a id="a499385f44e3a8639cb02a41a18adf969" name="a499385f44e3a8639cb02a41a18adf969"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>loss_fct</b></td></tr>
<tr class="separator:a499385f44e3a8639cb02a41a18adf969"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe16b8513b5fabcce755942de484b263"><td class="memItemLeft" align="right" valign="top"><a id="afe16b8513b5fabcce755942de484b263" name="afe16b8513b5fabcce755942de484b263"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>outputs_cache</b></td></tr>
<tr class="separator:afe16b8513b5fabcce755942de484b263"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa712efaf2ecfee34c71ed605fa316533"><td class="memItemLeft" align="right" valign="top"><a id="aa712efaf2ecfee34c71ed605fa316533" name="aa712efaf2ecfee34c71ed605fa316533"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>gradients_cache</b></td></tr>
<tr class="separator:aa712efaf2ecfee34c71ed605fa316533"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4bb4e0ae1dd2ad2978d301a89075b92b"><td class="memItemLeft" align="right" valign="top"><a id="a4bb4e0ae1dd2ad2978d301a89075b92b" name="a4bb4e0ae1dd2ad2978d301a89075b92b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>best_loss</b></td></tr>
<tr class="separator:a4bb4e0ae1dd2ad2978d301a89075b92b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ebc1b62937f368ec16fc15fba2e6731"><td class="memItemLeft" align="right" valign="top"><a id="a0ebc1b62937f368ec16fc15fba2e6731" name="a0ebc1b62937f368ec16fc15fba2e6731"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>best_remote_loss</b></td></tr>
<tr class="separator:a0ebc1b62937f368ec16fc15fba2e6731"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88e13af700b009f4414388f50bc03c1d"><td class="memItemLeft" align="right" valign="top"><a id="a88e13af700b009f4414388f50bc03c1d" name="a88e13af700b009f4414388f50bc03c1d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>backward_gradients_count</b></td></tr>
<tr class="separator:a88e13af700b009f4414388f50bc03c1d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a896fad140124878a2ddf5d34f6467546"><td class="memItemLeft" align="right" valign="top"><a id="a896fad140124878a2ddf5d34f6467546" name="a896fad140124878a2ddf5d34f6467546"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>remote_losses</b></td></tr>
<tr class="separator:a896fad140124878a2ddf5d34f6467546"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a6132e85ef58f7a42c1fe91a77ce700d7" name="a6132e85ef58f7a42c1fe91a77ce700d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6132e85ef58f7a42c1fe91a77ce700d7">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_server.nucleus_impl.server.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">'<a class="el" href="classbittensor_1_1__config_1_1config.html">bittensor.config</a>' &#160;</td>
          <td class="paramname"><em>config</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>pretrained</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_name</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>padding</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>interpolate</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>inter_degree</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tokenizer</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mapping_function</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>token_remap</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>checking</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">" Creates a server that serves up a pretrained miner on the bittensor network
Args:
        config (:obj:`bittensor.Config`, `required`): 
            bittensor.server.config()
        pretrained (:obj:bool , `optional`):
            if the model should pretrained or not
        model_name (:obj:string , `optional`):
            name of the pretrained model from huggingface to use
        padding (:obj:bool, `optional`):
            If the server should pad out to match the hidden units that the bittensor network is using
            If set to False, it will instead create a mapping layer to do the same thing.
        interpolate (:obj:bool, `optional`):
            If the server should interpolate between sequence length differences.
            If set to false, there should be a mapping function that takes care of the differnces
        inter_degree (:obj:str, `optional`):
            The Interpolate algorithm (nearest | linear | bilinear | bicubic | trilinear | area)
        model (:obj:torch.module, `optional`):
            Overrides the huggingface pretrained model with your own pretrained model
        tokenizer (:obj:huggingface.tokenizer, `optional`):
            Overrides the huggingface tokenizer with your tokenizer
        mapping_function (:obj:Callable, `optional`):
            Custom mapping function that maps between sequence length differences between tokenizers
        token_remap (:obj:Callable, `optional`):
            Custom function that maps between tokenizers (defaults to self.remapping_token)
</pre> 
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a99bcd6cc84c562d1db5cac8e585576d7" name="a99bcd6cc84c562d1db5cac8e585576d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a99bcd6cc84c562d1db5cac8e585576d7">&#9670;&#160;</a></span>check()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_server.nucleus_impl.server.check </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Checks the server settings
</pre> 
</div>
</div>
<a id="ab592da0bacc745c98011d8e064190570" name="ab592da0bacc745c98011d8e064190570"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab592da0bacc745c98011d8e064190570">&#9670;&#160;</a></span>encode_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_server.nucleus_impl.server.encode_forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tokenizer</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_output</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Forward pass through the pretrained model and possible mappings between hidden units. 
     The response tensor should be the hidden units computed using the local context and with shape: [batch_size, sequence_len, __network_dim__].

    Args:
        inputs ( :obj:`torch.Tensor`, `required`):
            torch inputs to be forward processed.
        tokenizer ( huggingface.tokenizer, `optional`):
            The tokenizer which was used to tokenize the inputs
        model_outputs (:obj:`transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`, `optional`):
            The output of huggingface auto model.

    Returns:
        model_outputs (:obj:`transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`, `required`):
            The output of huggingface auto model.
            
        encoded_hidden (:type:`torch.Tensor`, `required`)
            The hidden layer output as a torch tensor of shape [batch_size, sequence_len, __network_dim__ ]
</pre> 
</div>
</div>
<a id="a9fe04678b6dcce05a3f9d3f25b31d65f" name="a9fe04678b6dcce05a3f9d3f25b31d65f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9fe04678b6dcce05a3f9d3f25b31d65f">&#9670;&#160;</a></span>encode_forward_causallm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_server.nucleus_impl.server.encode_forward_causallm </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>token_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tokenizer</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encode_len</em> = <code>bittensor.__network_dim__</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_output</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Forward pass through the pretrained model and possible mappings between hidden units.
     The response tensor should be the hidden units computed using the local context and
     with shape: [batch_size, sequence_len, __vocab_size__].

    Args:
        token_batch ( :obj:`torch.LongTensor`, `required`):
            torch inputs to be forward processed, [batch_size, sequence_len]
        tokenizer ( huggingface.tokenizer, `optional`):
            The tokenizer which was used to tokenize the inputs
        encode_len ( :obj:`int`, `optional`):
            logit encoding length, default bittensor.__network_dim__ length
        model_output (:obj:`transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`, `optional`):
            The output of huggingface auto model.

    Returns:
        model_outputs (:obj:`transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`, `required`):
            The output of huggingface auto model.
        
        logits_std (:obj:`torch.FloatTensor`):
            The nucleus's logit outputs as a torch tensor of shape [batch_size, sequence_len, __vocab_size__]
</pre> 
</div>
</div>
<a id="aa75186146bb39740317a5476a71261ec" name="aa75186146bb39740317a5476a71261ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa75186146bb39740317a5476a71261ec">&#9670;&#160;</a></span>encode_forward_causallmnext()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_server.nucleus_impl.server.encode_forward_causallmnext </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>token_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>std_tokenizer</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>topk</em> = <code>4096</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_output</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Forward pass through the pretrained model and select topk tokenizer logits and retokenize with std_tokenizer,
then compact new token phrases and probabilities
into 1-D tensor [ &gt;= batch_size * (2 * topk + 1)] prob + at least 1 token per phrase + floor_prob.
The floor probability is the mean probability of token phrases not captured in topk, required since
the server tokenizer vocab_size may not be known to the receiver/validator.

Args:
    token_batch ( :obj:`torch.LongTensor`, `required`):
        torch inputs to be forward processed, [batch_size, std_sequence_len].
    std_tokenizer ( :obj:`PreTrainedTokenizerBase`, `optional`):
        The standard tokenizer which was used to tokenize the inputs.
    topk ( :obj:`int`, `optional`):
        Amount of std_tokenized server phrases with highest probability to produce.
    model_output (:obj:`transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`, `optional`):
        The output of transformers AutoModel.

Returns:
    model_outputs (:obj:`transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`, `required`):
        The output of transformers AutoModel.
    topk_tensor (:obj:`torch.Tensor`, `required`):
        [batch_size, (topk + 1), max_len] tensor includes topk token probabilities (prob_k) + floor_prob
        in first column with gradients attached, with std_tokens in remaining columns with ignore_index padding.
        Content structure:
        [[[prob_k=0_b=0, tok_0_k=0_b=0, tok_1_k=0_b=0, ..., ignore_index?],
          [prob_k=1_b=0, tok_0_k=1_b=0, tok_1_k=1_b=0, ..., ignore_index?],
          [...],
          [prob_floor_b=0, ignore_index, ..., ignore_index]],
         [[prob_k=0_b=1, tok_0_k=0_b=1, tok_1_k=0_b=1, ..., ignore_index?],
          [prob_k=1_b=1, tok_0_k=1_b=1, tok_1_k=1_b=1, ..., ignore_index?],
          [...],
          [prob_floor_b=1, ignore_index, ..., ignore_index]],
         [...]]
</pre> 
</div>
</div>
<a id="ae1bba88e9b29c127cc9086eafa8ccb38" name="ae1bba88e9b29c127cc9086eafa8ccb38"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1bba88e9b29c127cc9086eafa8ccb38">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_server.nucleus_impl.server.forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tokenizer</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Forward pass through the whole server model. Returns the loss and decoded predictions.

    Args:
        inputs ( :obj:`torch.Tensor`, `required`):
            torch inputs to be forward processed.
        tokenizer (:obj:'huggingface.tokenizer', optional):
            The tokenizer which was used to tokenize the inputs
     Returns:
        loss (:obj:`torch.FloatTensor`):
            MLM loss from the inputs
        decoded_targets (:obj:`torch.FloatTensor`):
            Decoded predictions of the next token in the sentence.</pre> 
</div>
</div>
<a id="af1ec54d7eb69b55a7c551c37bcb01930" name="af1ec54d7eb69b55a7c551c37bcb01930"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af1ec54d7eb69b55a7c551c37bcb01930">&#9670;&#160;</a></span>get_loss_fct()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> torch.FloatTensor bittensor._neuron.text.core_server.nucleus_impl.server.get_loss_fct </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>logits</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.LongTensor&#160;</td>
          <td class="paramname"><em>labels</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Calculate loss_fct, CausalLM loss, next-token prediction loss.
    Args:
        logits (:obj:`torch.FloatTensor`, `required`):
            [batch_size, sequence_len, bittensor.__network_dim__]
        labels (:obj:`torch.LongTensor`, `required`):
            [batch_size, sequence_len]

    Returns:
        loss (:obj:`torch.FloatTensor`):
            scalar
</pre> 
</div>
</div>
<a id="a6638393fba593635bf489b0575b80752" name="a6638393fba593635bf489b0575b80752"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6638393fba593635bf489b0575b80752">&#9670;&#160;</a></span>local_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_server.nucleus_impl.server.local_forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>token_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tokenizer</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>encode_len</em> = <code>bittensor.__network_dim__</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_output</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Forward pass through the pretrained model and possible mappings between hidden units.
     The response tensor should be the hidden units computed using the local context and
     with shape: [batch_size, sequence_len, __vocab_size__].

    Args:
        token_batch ( :obj:`torch.LongTensor`, `required`):
            torch inputs to be forward processed, [batch_size, sequence_len]
        tokenizer ( huggingface.tokenizer, `optional`):
            The tokenizer which was used to tokenize the inputs
        encode_len ( :obj:`int`, `optional`):
            logit encoding length, default bittensor.__network_dim__ length
        model_output (:obj:`transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`, `optional`):
            The output of huggingface auto model.

    Returns:
        model_outputs (:obj:`transformers.modeling_outputs.BaseModelOutputWithCrossAttentions`, `required`):
            The output of huggingface auto model.
        
        logits (:obj:`torch.FloatTensor`):
            The nucleus's logit outputs as a torch tensor of shape [batch_size, sequence_len, __vocab_size__]
</pre> 
</div>
</div>
<a id="a62d78b2d208bf64fb184ce6dff244949" name="a62d78b2d208bf64fb184ce6dff244949"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a62d78b2d208bf64fb184ce6dff244949">&#9670;&#160;</a></span>remapping_token()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._neuron.text.core_server.nucleus_impl.server.remapping_token </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>token_batch</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>std_tokenizer</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_offsets_mapping</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Tokenizer remapping; decodes the message and then remaps the message using a new tokenizer
    Args:
        token_batch ( :obj:`torch.LongTensor`, `required`):
            token_batch to be retokenized, [batch_size, sequence_len]
        std_tokenizer ( :obj:`transformers.Tokenizer`, `optional`):
            The standard tokenizer which was used to tokenize the input.
        return_offsets_mapping ( :obj:`bool`, `required`):
            Return offsets_mapping in tokenization to delineate token segment positions.
</pre> 
</div>
</div>
<a id="a614100716e4fce09e4e00b12ee6ef1f5" name="a614100716e4fce09e4e00b12ee6ef1f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a614100716e4fce09e4e00b12ee6ef1f5">&#9670;&#160;</a></span>set_fine_tuning_params()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[bool, str] bittensor._neuron.text.core_server.nucleus_impl.server.set_fine_tuning_params </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Set to tune only the parameter of the last layer
    Returns: 
        reached_last_layer (:type:`bool`):
            If we have set partial of the model to requires grad.
        
        last_layer_name (:type:`string`):
            The name of the last layer that user specified or we found.
            None if the user did not specify and we couldnt find it. 
</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/macthrasher/bittensor/bittensor/_neuron/text/core_server/nucleus_impl.py</li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>bittensor</b></li><li class="navelem"><b>_neuron</b></li><li class="navelem"><b>text</b></li><li class="navelem"><a class="el" href="namespacebittensor_1_1__neuron_1_1text_1_1core__server.html">core_server</a></li><li class="navelem"><b>nucleus_impl</b></li><li class="navelem"><a class="el" href="classbittensor_1_1__neuron_1_1text_1_1core__server_1_1nucleus__impl_1_1server.html">server</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6 </li>
  </ul>
</div>
</body>
</html>
