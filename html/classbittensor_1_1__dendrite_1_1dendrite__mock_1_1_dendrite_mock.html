<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Bittensor: bittensor._dendrite.dendrite_mock.DendriteMock Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">var page_layout=1;</script>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="side-nav" class="ui-resizable side-nav-resizable"><!-- do not remove this div, it is closed by doxygen! -->
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Bittensor
   </div>
   <div id="projectbrief">Python API</div>
  </td>
 </tr>
   <tr><td colspan="2">        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</td></tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
</div><!-- top -->
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">bittensor._dendrite.dendrite_mock.DendriteMock Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for bittensor._dendrite.dendrite_mock.DendriteMock:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.png" alt=""/>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a81ffefc2213c7563e28f2e2de997f5d5"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#a81ffefc2213c7563e28f2e2de997f5d5">__init__</a> (self, '<a class="el" href="classbittensor_1_1__config_1_1config__impl_1_1_config.html">bittensor.Config</a>' <a class="el" href="classbittensor_1_1__config_1_1config.html">config</a>, '<a class="el" href="classbittensor_1_1__wallet_1_1wallet__impl_1_1_wallet.html">bittensor.Wallet</a>' <a class="el" href="classbittensor_1_1__wallet_1_1wallet.html">wallet</a>)</td></tr>
<tr class="separator:a81ffefc2213c7563e28f2e2de997f5d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae632c778cd7e16859863ceeb57b1b96f"><td class="memItemLeft" align="right" valign="top"><a id="ae632c778cd7e16859863ceeb57b1b96f" name="ae632c778cd7e16859863ceeb57b1b96f"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__str__</b> (self)</td></tr>
<tr class="separator:ae632c778cd7e16859863ceeb57b1b96f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad557a24a1819db6c705133390b0c115c"><td class="memItemLeft" align="right" valign="top"><a id="ad557a24a1819db6c705133390b0c115c" name="ad557a24a1819db6c705133390b0c115c"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__repr__</b> (self)</td></tr>
<tr class="separator:ad557a24a1819db6c705133390b0c115c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a808509a1c1618ec006377e3131becf1a"><td class="memItemLeft" align="right" valign="top"><a id="a808509a1c1618ec006377e3131becf1a" name="a808509a1c1618ec006377e3131becf1a"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__del__</b> (self)</td></tr>
<tr class="separator:a808509a1c1618ec006377e3131becf1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba4861e1bd42622eced10ec450fddfb5"><td class="memItemLeft" align="right" valign="top">Tuple[Union[List[torch.FloatTensor], torch.FloatTensor], torch.LongTensor, torch.FloatTensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#aba4861e1bd42622eced10ec450fddfb5">forward_image</a> (self, Union[List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'], '<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'] endpoints, List[torch.FloatTensor] inputs, int timeout=None, bool requires_grad=None)</td></tr>
<tr class="separator:aba4861e1bd42622eced10ec450fddfb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a596804548b4ab12580fa1ce97fe36e54"><td class="memItemLeft" align="right" valign="top">Tuple[Union[List[torch.FloatTensor], torch.FloatTensor], torch.LongTensor, torch.FloatTensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#a596804548b4ab12580fa1ce97fe36e54">forward_tensor</a> (self, Union[List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'], '<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'] endpoints, List[torch.FloatTensor] inputs, int timeout=None, bool requires_grad=None)</td></tr>
<tr class="separator:a596804548b4ab12580fa1ce97fe36e54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a05b1862d3fcc5a34924ff9d89424585d"><td class="memItemLeft" align="right" valign="top">Tuple[Union[List[torch.FloatTensor], torch.FloatTensor], torch.LongTensor, torch.FloatTensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#a05b1862d3fcc5a34924ff9d89424585d">forward_text</a> (self, Union[torch.LongTensor, List[torch.LongTensor], List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'], '<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'] endpoints, Union[str, List[str], List[torch.LongTensor], torch.LongTensor] inputs, int timeout=None, bool requires_grad=None)</td></tr>
<tr class="separator:a05b1862d3fcc5a34924ff9d89424585d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae078e5bf68d851035d9c4e7a125f3611"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#ae078e5bf68d851035d9c4e7a125f3611">update_stats</a> (self, endpoints, requests, responses, return_ops, query_times)</td></tr>
<tr class="separator:ae078e5bf68d851035d9c4e7a125f3611"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7308a89e8472c87b19e6b1955d4b6a2f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#a7308a89e8472c87b19e6b1955d4b6a2f">to_dataframe</a> (self, <a class="el" href="classbittensor_1_1__metagraph_1_1metagraph.html">metagraph</a>)</td></tr>
<tr class="separator:a7308a89e8472c87b19e6b1955d4b6a2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19bd830edb5d9b7ec5224fb8fe613f63"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#a19bd830edb5d9b7ec5224fb8fe613f63">to_wandb</a> (self)</td></tr>
<tr class="separator:a19bd830edb5d9b7ec5224fb8fe613f63"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:ae81c0740aa0705e26e7aad62de72e2f3"><td class="memItemLeft" align="right" valign="top">Tuple[torch.Tensor,...]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#ae81c0740aa0705e26e7aad62de72e2f3">forward</a> (ctx, '<a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite.html">bittensor.Dendrite</a>' <a class="el" href="classbittensor_1_1__dendrite_1_1dendrite.html">dendrite</a>, torch.Tensor dummy, List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'] endpoints, bittensor.proto.Modality modality, int timeout, bool requires_grad, *torch.Tensor inputs)</td></tr>
<tr class="separator:ae81c0740aa0705e26e7aad62de72e2f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab918018e0982ed5cc000b773a158155b"><td class="memItemLeft" align="right" valign="top">Tuple[Optional[torch.Tensor],...]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#ab918018e0982ed5cc000b773a158155b">backward</a> (ctx, torch.FloatTensor unused_code_grads, torch.FloatTensor unused_time_grads, *torch.FloatTensor output_grads)</td></tr>
<tr class="separator:ab918018e0982ed5cc000b773a158155b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a9f892c0ae3ad0c4215c37e32c06fc9c6"><td class="memItemLeft" align="right" valign="top"><a id="a9f892c0ae3ad0c4215c37e32c06fc9c6" name="a9f892c0ae3ad0c4215c37e32c06fc9c6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>config</b></td></tr>
<tr class="separator:a9f892c0ae3ad0c4215c37e32c06fc9c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a319e9d2b826f7d5e6c1d6eeace3181fb"><td class="memItemLeft" align="right" valign="top"><a id="a319e9d2b826f7d5e6c1d6eeace3181fb" name="a319e9d2b826f7d5e6c1d6eeace3181fb"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>wallet</b></td></tr>
<tr class="separator:a319e9d2b826f7d5e6c1d6eeace3181fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aebb0242acf69b207f575854795c00403"><td class="memItemLeft" align="right" valign="top"><a id="aebb0242acf69b207f575854795c00403" name="aebb0242acf69b207f575854795c00403"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>stats</b></td></tr>
<tr class="separator:aebb0242acf69b207f575854795c00403"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:ab55cc43ecfbdfbe6c12477c357e1f45a"><td class="memItemLeft" align="right" valign="top">Tuple[List[torch.Tensor], torch.LongTensor, torch.FloatTensor]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html#ab55cc43ecfbdfbe6c12477c357e1f45a">_forward</a> (self, List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'] endpoints, List[torch.Tensor] inputs, bittensor.proto.Modality modality, int timeout=None, bool requires_grad=None)</td></tr>
<tr class="separator:ab55cc43ecfbdfbe6c12477c357e1f45a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a769f1dd732c542a449bf729438db3267"><td class="memItemLeft" align="right" valign="top"><a id="a769f1dd732c542a449bf729438db3267" name="a769f1dd732c542a449bf729438db3267"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>_init_stats</b> (self)</td></tr>
<tr class="separator:a769f1dd732c542a449bf729438db3267"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment"> Mocked Dendrite returns random results 50% of the time.
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a81ffefc2213c7563e28f2e2de997f5d5" name="a81ffefc2213c7563e28f2e2de997f5d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a81ffefc2213c7563e28f2e2de997f5d5">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._dendrite.dendrite_mock.DendriteMock.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">'<a class="el" href="classbittensor_1_1__config_1_1config__impl_1_1_config.html">bittensor.Config</a>'&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">'<a class="el" href="classbittensor_1_1__wallet_1_1wallet__impl_1_1_wallet.html">bittensor.Wallet</a>'&#160;</td>
          <td class="paramname"><em>wallet</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Initializes a new Mock Dendrite entry point.</pre> 
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="ab55cc43ecfbdfbe6c12477c357e1f45a" name="ab55cc43ecfbdfbe6c12477c357e1f45a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab55cc43ecfbdfbe6c12477c357e1f45a">&#9670;&#160;</a></span>_forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[List[torch.Tensor], torch.LongTensor, torch.FloatTensor] bittensor._dendrite.dendrite_mock.DendriteMock._forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>']&#160;</td>
          <td class="paramname"><em>endpoints</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.Tensor]&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bittensor.proto.Modality&#160;</td>
          <td class="paramname"><em>modality</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>timeout</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>requires_grad</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment"> Internal Forward tensor inputs to a list of neuron endpoints.

    Args:
        endpoints (:obj:`List[bittensor.Endpoint]` of shape :obj:`(num_endpoints)`, `required`):
            List of remote endpoints which match length of inputs. Tensors from inputs are sent forward to these endpoints.

        inputs (:obj:`List[torch.Tensor]` of shape :obj:`(num_endpoints * [shape])`, `required`):
            List of tensors to send to corresponding endpoints. Tensors are of arbitrary type and shape depending on the
            modality.

        modality (:obj:`bittensor.proto.Modality` of shape :obj:`(1)`, `required`):
            Bittensor forward modality type. Enum in [TEXT, IMAGE, TENSOR]

        timeout (int, default = dendrite.timeout, `required`):
            request timeout.

        requires_grad (int, default = dendrite.requires_grad, `optional`):
            If true, the backward pass triggers passing gradients on the wire.

    Returns:
        responses (:obj:`List[torch.FloatTensor]` of shape :obj:`(batch_size, sequence_len, bittensor.__network_dim__)`, `required`):
            Output encodings of inputs produced by the remote endpoints. Non-responses are zeroes of common shape.

        codes (:obj:`List[torch.LongTensor]` of shape :obj:`[num_endpoints]`, `required`):
            dendrite call return codes.

        times (:obj:`torch.FloatTensor` of shape :obj:`[ num_endpoints ]`, `required`):
            times per call.</pre> 
</div>
</div>
<a id="ab918018e0982ed5cc000b773a158155b" name="ab918018e0982ed5cc000b773a158155b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab918018e0982ed5cc000b773a158155b">&#9670;&#160;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[Optional[torch.Tensor], ...] bittensor._dendrite.dendrite_mock.DendriteMock.backward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>unused_code_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.FloatTensor&#160;</td>
          <td class="paramname"><em>unused_time_grads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*torch.FloatTensor
    &#160;</td>
          <td class="paramname"><em>output_grads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment"> Internal autograd-friendly Backward RPC call to a list of neuron endpoints.

    Args:
        ctx: (:obj:`torch.autograd.ctx`, `required`):
            Autograd context, saves state information between forward and backward calls. i.e. inputs for gradient computation.

        unused_code_grads: (:obj:`List[torch.Tensor]` of shape :obj:`(shape)`, `required`):
            Gradients of this function's codes. (Unused)

        unused_time_grads: (:obj:`List[torch.Tensor]` of shape :obj:`(shape)`, `required`):
            Gradients of this function's query times. (Unused)

        grads (:obj:`List[torch.Tensor]` of shape :obj:`(shape)`, `required`):
            Gradients of this function's outputs computed during the loss.backward() call.
    
    Returns:
        DUMMY, None, None, None,
        outputs (:obj:`List[torch.FloatTensor], `optional`):
            Gradient results for each input.</pre> 
</div>
</div>
<a id="ae81c0740aa0705e26e7aad62de72e2f3" name="ae81c0740aa0705e26e7aad62de72e2f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae81c0740aa0705e26e7aad62de72e2f3">&#9670;&#160;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[torch.Tensor, ...] bittensor._dendrite.dendrite_mock.DendriteMock.forward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">'<a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite.html">bittensor.Dendrite</a>'&#160;</td>
          <td class="paramname"><em>dendrite</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>dummy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>']&#160;</td>
          <td class="paramname"><em>endpoints</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bittensor.proto.Modality&#160;</td>
          <td class="paramname"><em>modality</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>timeout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>requires_grad</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*torch.Tensor
    &#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment"> Internal autograd-friendly Forward RPC call to a list of neuron endpoints.

    Args:
        ctx: (:obj:`torch.autograd.ctx`, `required`):
            Autograd context, saves state information between forward and backward calls. i.e. inputs for gradient computation.

        dendrite: (:obj:`bittensor.Dendrite`, `required`):
            Pointer to a bittensor dendrite object on which we are creating the forward requests.

        dummy: (:obj:`torch.Tensor`, `required`):
            Dummy torch tensor used to ensure that torch.backward computation is called on this function 
            regardless of the input types.

        endpoints (:obj:`List[bittensor.Endpoint']` of shape :obj:`(n_endpoints)`, `required`):
            List of endpoints which match length of inputs. Inputs are sent forward to these endpoints.

        modality (:obj:`bittensor.proto.Modality` of shape :obj:`(1)`, `required`):
            Bittensor forward modality or type ENUM [TEXT, IMAGE, TENSOR]

        inputs (:obj:`List[torch.Tensor]` of shape :obj:`(n_endpoints)`, `required`):
            List of torch tensors to be sent to the associated endpoints.

        timeout (int):
            request timeout.

        requires_grad (int, default = dendrite.requires_grad, `optional`):
            If true, the backward pass triggers passing gradients on the wire.

    Returns:
        codes (:obj:`torch.LongTensor` of shape :obj:`(n_endpoints)` `required`):
            Return code associated with forward call.

        times (:obj:`torch.FloatTensor` of shape :obj:`[ num_endpoints ]`, `required`):
            times per call.
        
        outputs (:obj:`List[torch.FloatTensor]` of shape :obj:`n_endpoints * (batch_size, sequence_len, bittensor.__network_dim__)`, `required`):
                Output encodings of inputs produced by the remote endpoints. Non-responses are zeroes of common shape.
</pre> 
</div>
</div>
<a id="aba4861e1bd42622eced10ec450fddfb5" name="aba4861e1bd42622eced10ec450fddfb5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba4861e1bd42622eced10ec450fddfb5">&#9670;&#160;</a></span>forward_image()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[Union[List[torch.FloatTensor], torch.FloatTensor], torch.LongTensor, torch.FloatTensor] bittensor._dendrite.dendrite_mock.DendriteMock.forward_image </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'], '<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>']&#160;</td>
          <td class="paramname"><em>endpoints</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.FloatTensor]&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>timeout</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>requires_grad</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Forward image inputs to endpoints.

  Args:
        endpoints (:obj:`Union[List[bittensor.Endpoint], bittensor.Endpoint]` of shape :obj:`(num_endpoints)`, `required`):
            List or single of endpoints which match the length of inputs. Inputs are sent forward to these endpoints.

        inputs (:obj:`Union[List[torch.FloatTensor], torch.FloatTensor]` of shape :obj:`(num_endpoints * [ batch_size, sequence_len, channels, rows, cols ])`, `required`):
            List or single of image-tensors to send to corresponding endpoints. Tensors are images encoded using the
            torch.toTensor() or other encoding which produces the shape [batch_size, channels, rows, cols].

        timeout (int, default = dendrite.timeout `optional`):
            Request timeout.

        requires_grad (int, default = dendrite.requires_grad, `optional`):
            If true, the backward pass triggers passing gradients on the wire.

    Returns:
        responses (:obj:`Union[ List[torch.FloatTensor], torch.FloatTensor] ` of shape :obj:`(batch_size, sequence_len, bittensor.__network_dim__)`, `required`):
            Output encodings of inputs produced by remote endpoints. Non-responses are zeroes of input shape plus output dimension.

        codes (:obj:`torch.LongTensor` of shape :obj:`[ num_endpoints ]`, `required`):
            dendrite call return ops.

        times (:obj:`torch.FloatTensor` of shape :obj:`[ num_endpoints ]`, `required`):
            times per call.
</pre> 
</div>
</div>
<a id="a596804548b4ab12580fa1ce97fe36e54" name="a596804548b4ab12580fa1ce97fe36e54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a596804548b4ab12580fa1ce97fe36e54">&#9670;&#160;</a></span>forward_tensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[Union[List[torch.FloatTensor], torch.FloatTensor], torch.LongTensor, torch.FloatTensor] bittensor._dendrite.dendrite_mock.DendriteMock.forward_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'], '<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>']&#160;</td>
          <td class="paramname"><em>endpoints</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">List[torch.FloatTensor]&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>timeout</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>requires_grad</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Forward tensor inputs to endpoints.

    Args:
        endpoints (:obj:`Union[List[bittensor.Endpoint], bittensor.Endpoint]` of shape :obj:`(num_endpoints)`, `required`):
            List or single of endpoints which match the length of inputs. Inputs are sent forward to these endpoints.

        inputs (:obj:`Union[List[torch.LongTensor], torch.LongTensor]` of shape :obj:`(num_endpoints * [batch_size, sequence_len])`, `required`):
            List or single tensors to send to corresponding endpoints. Tensors are of float type and
            with shape [batch_size, sequence_len, bittensor.__network_dim__].

        timeout (int, default = dendrite.timeout `optional`):
            Request timeout.

        requires_grad (int, default = dendrite.requires_grad, `optional`):
            If true, the backward pass triggers passing gradients on the wire.

    Returns:
        responses (:obj:`Union[ List[torch.FloatTensor], torch.FloatTensor] ` of shape :obj:`(batch_size, sequence_len, bittensor.__network_dim__)`, `required`):
            Output encodings of inputs produced by remote endpoints. Non-responses are zeroes of input shape plus output dimension.

        codes (:obj:`torch.LongTensor` of shape :obj:`[ num_endpoints ]`, `required`):
            dendrite call return ops.

        times (:obj:`torch.FloatTensor` of shape :obj:`[ num_endpoints ]`, `required`):
            times per call.
</pre> 
</div>
</div>
<a id="a05b1862d3fcc5a34924ff9d89424585d" name="a05b1862d3fcc5a34924ff9d89424585d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a05b1862d3fcc5a34924ff9d89424585d">&#9670;&#160;</a></span>forward_text()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[Union[List[torch.FloatTensor], torch.FloatTensor], torch.LongTensor, torch.FloatTensor] bittensor._dendrite.dendrite_mock.DendriteMock.forward_text </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[
                torch.LongTensor, List[torch.LongTensor], List['<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>'], '<a class="el" href="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint.html">bittensor.Endpoint</a>']&#160;</td>
          <td class="paramname"><em>endpoints</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[str, List[str], List[torch.LongTensor], torch.LongTensor]&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>timeout</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>requires_grad</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Forward text inputs to a list of neuron endpoints and block until responses or timeout.

        Args:
            endpoints (:obj:`Union[torch.LongTensor, List[torch.LongTensor], List[bittensor.Endpoint], bittensor.Endpoint]` of shape :obj:`(num_endpoints)`, `required`):
                Endpoints to send inputs to. Endpoint can be one of the following types:
                    - a single endpoint tensor shape [250]
                    - a set of endpoint tensors shape [n, 250]
                    - a list of endpoints tensors each of shape [250]
                    - a single endpoint object. Inputs will be sent to this endpoint alone.
                    - a list of endpoint objects. All inputs will be sent to these endpoints.

            inputs (:obj:`Union[str,  List[str], List[torch.LongTensor], torch.LongTensor]` of shape :obj:`(num_endpoints * [batch_size, sequence_len])`, `required`):
                Tokenized sentences to send on the wire. Inputs can be one of the following types:
                    - a single string: the string will be tokenized using the bittensor tokenizer.
                    - a list of strings: the strings will be tokenized using the bittensor tokenizer.
                    - a tensor with shape [batch_size, sequence_len], assumed to be the output of bittensor tokenizer.
                    - a tensor with shape [n, batch_size, sequence_len], the operation will unbind the tensor and pass inputs to endpoints.
                If inputs are tensors they will be cast to int64 format before sending on the wire.

            timeout (:type:`int`, default = dendrite.timeout `optional`):
                Request timeout. Queries that do not respond will be replaced by zeros.

            requires_grad (:type:`int`, default = dendrite.requires_grad, `optional`):
                If true, the backward pass triggers passing gradients on the wire.

        Returns:
            responses (:obj:`torch.FloatTensor` of shape :obj:`(n, batch_size, sequence_len, bittensor.__network_dim__)`, `required`):
                Output encodings of inputs produced by remote endpoints. Non-responses are zeroes of input shape plus output dimension.
                The first dimension will match the number of endpoints queried.

            codes (:obj:`torch.LongTensor` of shape :obj:`[ num_endpoints ]`, `required`):
                dendrite call return ops.

            times (:obj:`torch.FloatTensor` of shape :obj:`[ num_endpoints ]`, `required`):
                times per call.
</pre> 
</div>
</div>
<a id="a7308a89e8472c87b19e6b1955d4b6a2f" name="a7308a89e8472c87b19e6b1955d4b6a2f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7308a89e8472c87b19e6b1955d4b6a2f">&#9670;&#160;</a></span>to_dataframe()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._dendrite.dendrite_mock.DendriteMock.to_dataframe </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>metagraph</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Return a stats info as a pandas dataframe indexed by the metagraph or pubkey if not existend.
Args:
metagraph: (bittensor.Metagraph):
    Indexes the stats data using metagraph hotkeys.
Return:
dataframe (:obj:`pandas.Dataframe`)
</pre> 
</div>
</div>
<a id="a19bd830edb5d9b7ec5224fb8fe613f63" name="a19bd830edb5d9b7ec5224fb8fe613f63"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a19bd830edb5d9b7ec5224fb8fe613f63">&#9670;&#160;</a></span>to_wandb()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._dendrite.dendrite_mock.DendriteMock.to_wandb </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Return a dictionary of dendrite stats as wandb logging info.
Args:
metagraph: (bittensor.Metagraph):
If not None, indexes the wandb data using int uids rather than string pubkeys.
Return:
wandb_info (:obj:`Dict`)
</pre> 
</div>
</div>
<a id="ae078e5bf68d851035d9c4e7a125f3611" name="ae078e5bf68d851035d9c4e7a125f3611"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae078e5bf68d851035d9c4e7a125f3611">&#9670;&#160;</a></span>update_stats()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def bittensor._dendrite.dendrite_mock.DendriteMock.update_stats </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>endpoints</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>requests</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>responses</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_ops</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>query_times</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> Update dendrite stat according to the response we get from peers. Updates were saved to self.stats.
    Args:
        endpoints (:obj:`List[bittensor.Endpoint]` of shape :obj:`(num_endpoints)`, `required`):
            The set of endpoints that dendrite sent request to.

        requests (List[torch.Tensor] of shape :obj:`[ num_endpoints ]`, `required`):
            Requests from the call.

        responses (List[torch.FloatTensor] of shape :obj:`[ num_endpoints ]`, `required`):
            Responses from the call.

        return_ops (:obj:`torch.LongTensor` of shape :obj:`[ num_endpoints ]`, `required`):
            Dendrite call return ops.

        query_times (:obj:`torch.FloatTensor` of shape :obj:`[ num_endpoints ]`, `required`):
            Times per call.
</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_mock.py</li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>bittensor</b></li><li class="navelem"><a class="el" href="namespacebittensor_1_1__dendrite.html">_dendrite</a></li><li class="navelem"><a class="el" href="namespacebittensor_1_1__dendrite_1_1dendrite__mock.html">dendrite_mock</a></li><li class="navelem"><a class="el" href="classbittensor_1_1__dendrite_1_1dendrite__mock_1_1_dendrite_mock.html">DendriteMock</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6 </li>
  </ul>
</div>
</body>
</html>
