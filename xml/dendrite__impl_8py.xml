<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.9.6" xml:lang="en-US">
  <compounddef id="dendrite__impl_8py" kind="file" language="Python">
    <compoundname>dendrite_impl.py</compoundname>
    <innerclass refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite" prot="public">bittensor::_dendrite::dendrite_impl::Dendrite</innerclass>
    <innernamespace refid="namespacebittensor">bittensor</innernamespace>
    <innernamespace refid="namespacebittensor_1_1__dendrite">bittensor::_dendrite</innernamespace>
    <innernamespace refid="namespacebittensor_1_1__dendrite_1_1dendrite__impl">bittensor::_dendrite::dendrite_impl</innernamespace>
      <sectiondef kind="var">
      <memberdef kind="variable" id="namespacebittensor_1_1__dendrite_1_1dendrite__impl_1ac4f585874630d553631b7b4b330282d3" prot="public" static="no" mutable="no">
        <type>logger</type>
        <definition>logger bittensor::_dendrite::dendrite_impl.logger</definition>
        <argsstring></argsstring>
        <name>logger</name>
        <qualifiedname>bittensor._dendrite.dendrite_impl.logger</qualifiedname>
        <initializer>=  logger.opt(colors=True)</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" line="45" column="1" bodyfile="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" bodystart="45" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="namespacebittensor_1_1__dendrite_1_1dendrite__impl_1a12e8119b9e69d55fd3dffa675e534c81" prot="public" static="no" mutable="no">
        <type>torch</type>
        <definition>torch bittensor::_dendrite::dendrite_impl.DUMMY</definition>
        <argsstring></argsstring>
        <name>DUMMY</name>
        <qualifiedname>bittensor._dendrite.dendrite_impl.DUMMY</qualifiedname>
        <initializer>=  torch.empty(0, requires_grad=True)</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" line="48" column="1" bodyfile="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" bodystart="48" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="namespacebittensor_1_1__dendrite_1_1dendrite__impl_1a2ea86ebfd7e0a3c1028f1def1446f64c" prot="public" static="no" mutable="no">
        <type>Counter</type>
        <definition>Counter bittensor::_dendrite::dendrite_impl.PROM_prometheus_counters</definition>
        <argsstring></argsstring>
        <name>PROM_prometheus_counters</name>
        <qualifiedname>bittensor._dendrite.dendrite_impl.PROM_prometheus_counters</qualifiedname>
        <initializer>=  Counter(&apos;dendrite_counters&apos;, &apos;dendrite_counters&apos;, [&apos;wallet&apos;, &apos;identifier&apos;, &apos;name&apos;])</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" line="52" column="1" bodyfile="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" bodystart="52" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="namespacebittensor_1_1__dendrite_1_1dendrite__impl_1ae67559a5be82fe26c374671f6383fe75" prot="public" static="no" mutable="no">
        <type>Histogram</type>
        <definition>Histogram bittensor::_dendrite::dendrite_impl.PROM_prometheus_latency</definition>
        <argsstring></argsstring>
        <name>PROM_prometheus_latency</name>
        <qualifiedname>bittensor._dendrite.dendrite_impl.PROM_prometheus_latency</qualifiedname>
        <initializer>=  Histogram(&apos;dendrite_latency&apos;, &apos;dendrite_latency&apos;, [&apos;wallet&apos;, &apos;identifier&apos;], buckets=list(range(0,bittensor.__blocktime__,1)))</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" line="53" column="1" bodyfile="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" bodystart="53" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="namespacebittensor_1_1__dendrite_1_1dendrite__impl_1aaf1571b020c240e73a200ed6ba68d155" prot="public" static="no" mutable="no">
        <type>Summary</type>
        <definition>Summary bittensor::_dendrite::dendrite_impl.PROM_prometheus_latency_per_uid</definition>
        <argsstring></argsstring>
        <name>PROM_prometheus_latency_per_uid</name>
        <qualifiedname>bittensor._dendrite.dendrite_impl.PROM_prometheus_latency_per_uid</qualifiedname>
        <initializer>=  Summary(&apos;dendrite_latency_per_uid&apos;, &apos;dendrite_latency_per_uid&apos;, [&apos;wallet&apos;, &apos;identifier&apos;, &apos;uid&apos;])</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" line="54" column="1" bodyfile="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" bodystart="54" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="namespacebittensor_1_1__dendrite_1_1dendrite__impl_1a37e974854aa8f50b211920d4fd96dadf" prot="public" static="no" mutable="no">
        <type>Counter</type>
        <definition>Counter bittensor::_dendrite::dendrite_impl.PROM_prometheus_successes_per_uid</definition>
        <argsstring></argsstring>
        <name>PROM_prometheus_successes_per_uid</name>
        <qualifiedname>bittensor._dendrite.dendrite_impl.PROM_prometheus_successes_per_uid</qualifiedname>
        <initializer>=  Counter(&apos;dendrite_successes_per_uid&apos;, &apos;dendrite_successes_per_uid&apos;, [&apos;wallet&apos;, &apos;identifier&apos;, &apos;uid&apos;])</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" line="55" column="1" bodyfile="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" bodystart="55" bodyend="-1"/>
      </memberdef>
      <memberdef kind="variable" id="namespacebittensor_1_1__dendrite_1_1dendrite__impl_1a862940b02916c3856fe6b79fb6a5390c" prot="public" static="no" mutable="no">
        <type>Counter</type>
        <definition>Counter bittensor::_dendrite::dendrite_impl.PROM_prometheus_failures_per_uid</definition>
        <argsstring></argsstring>
        <name>PROM_prometheus_failures_per_uid</name>
        <qualifiedname>bittensor._dendrite.dendrite_impl.PROM_prometheus_failures_per_uid</qualifiedname>
        <initializer>=  Counter(&apos;dendrite_failures_per_uid&apos;, &apos;dendrite_failures_per_uid&apos;, [&apos;wallet&apos;, &apos;identifier&apos;, &apos;uid&apos;])</initializer>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" line="56" column="1" bodyfile="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py" bodystart="56" bodyend="-1"/>
      </memberdef>
      </sectiondef>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1" refid="namespacebittensor_1_1__dendrite_1_1dendrite__impl" refkind="compound"><highlight class="stringliteral">&quot;&quot;&quot;<sp/>Implementation<sp/>of<sp/>class<sp/>dendrite,<sp/>which<sp/>quries<sp/>endpoints<sp/>with<sp/>tensors.</highlight></codeline>
<codeline lineno="2"><highlight class="stringliteral">&quot;&quot;&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight><highlight class="comment">#<sp/>The<sp/>MIT<sp/>License<sp/>(MIT)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="comment">#<sp/>Copyright<sp/>©<sp/>2021<sp/>Yuma<sp/>Rao</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight><highlight class="comment">#<sp/>Permission<sp/>is<sp/>hereby<sp/>granted,<sp/>free<sp/>of<sp/>charge,<sp/>to<sp/>any<sp/>person<sp/>obtaining<sp/>a<sp/>copy<sp/>of<sp/>this<sp/>software<sp/>and<sp/>associated<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight><highlight class="comment">#<sp/>documentation<sp/>files<sp/>(the<sp/>“Software”),<sp/>to<sp/>deal<sp/>in<sp/>the<sp/>Software<sp/>without<sp/>restriction,<sp/>including<sp/>without<sp/>limitation<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight><highlight class="comment">#<sp/>the<sp/>rights<sp/>to<sp/>use,<sp/>copy,<sp/>modify,<sp/>merge,<sp/>publish,<sp/>distribute,<sp/>sublicense,<sp/>and/or<sp/>sell<sp/>copies<sp/>of<sp/>the<sp/>Software,<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight><highlight class="comment">#<sp/>and<sp/>to<sp/>permit<sp/>persons<sp/>to<sp/>whom<sp/>the<sp/>Software<sp/>is<sp/>furnished<sp/>to<sp/>do<sp/>so,<sp/>subject<sp/>to<sp/>the<sp/>following<sp/>conditions:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight></codeline>
<codeline lineno="11"><highlight class="normal"></highlight><highlight class="comment">#<sp/>The<sp/>above<sp/>copyright<sp/>notice<sp/>and<sp/>this<sp/>permission<sp/>notice<sp/>shall<sp/>be<sp/>included<sp/>in<sp/>all<sp/>copies<sp/>or<sp/>substantial<sp/>portions<sp/>of<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="12"><highlight class="normal"></highlight><highlight class="comment">#<sp/>the<sp/>Software.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="13"><highlight class="normal"></highlight></codeline>
<codeline lineno="14"><highlight class="normal"></highlight><highlight class="comment">#<sp/>THE<sp/>SOFTWARE<sp/>IS<sp/>PROVIDED<sp/>“AS<sp/>IS”,<sp/>WITHOUT<sp/>WARRANTY<sp/>OF<sp/>ANY<sp/>KIND,<sp/>EXPRESS<sp/>OR<sp/>IMPLIED,<sp/>INCLUDING<sp/>BUT<sp/>NOT<sp/>LIMITED<sp/>TO</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="15"><highlight class="normal"></highlight><highlight class="comment">#<sp/>THE<sp/>WARRANTIES<sp/>OF<sp/>MERCHANTABILITY,<sp/>FITNESS<sp/>FOR<sp/>A<sp/>PARTICULAR<sp/>PURPOSE<sp/>AND<sp/>NONINFRINGEMENT.<sp/>IN<sp/>NO<sp/>EVENT<sp/>SHALL<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="16"><highlight class="normal"></highlight><highlight class="comment">#<sp/>THE<sp/>AUTHORS<sp/>OR<sp/>COPYRIGHT<sp/>HOLDERS<sp/>BE<sp/>LIABLE<sp/>FOR<sp/>ANY<sp/>CLAIM,<sp/>DAMAGES<sp/>OR<sp/>OTHER<sp/>LIABILITY,<sp/>WHETHER<sp/>IN<sp/>AN<sp/>ACTION<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="17"><highlight class="normal"></highlight><highlight class="comment">#<sp/>OF<sp/>CONTRACT,<sp/>TORT<sp/>OR<sp/>OTHERWISE,<sp/>ARISING<sp/>FROM,<sp/>OUT<sp/>OF<sp/>OR<sp/>IN<sp/>CONNECTION<sp/>WITH<sp/>THE<sp/>SOFTWARE<sp/>OR<sp/>THE<sp/>USE<sp/>OR<sp/>OTHER<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="18"><highlight class="normal"></highlight><highlight class="comment">#<sp/>DEALINGS<sp/>IN<sp/>THE<sp/>SOFTWARE.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="19"><highlight class="normal"></highlight></codeline>
<codeline lineno="20"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>types<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>SimpleNamespace</highlight></codeline>
<codeline lineno="21"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>typing<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>Tuple,<sp/>List,<sp/>Union,<sp/>Optional</highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight></codeline>
<codeline lineno="23"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>sys</highlight></codeline>
<codeline lineno="24"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>torch</highlight></codeline>
<codeline lineno="25"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>pandas</highlight></codeline>
<codeline lineno="26"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>random</highlight></codeline>
<codeline lineno="27"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>time</highlight></codeline>
<codeline lineno="28"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>uuid</highlight></codeline>
<codeline lineno="29"><highlight class="normal"></highlight></codeline>
<codeline lineno="30"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>torch.autograd.function<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>once_differentiable</highlight></codeline>
<codeline lineno="31"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>loguru<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>logger</highlight></codeline>
<codeline lineno="32"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>transformers.utils.logging<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>enable_explicit_format</highlight></codeline>
<codeline lineno="33"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>yaml<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>serialize</highlight></codeline>
<codeline lineno="34"><highlight class="normal"></highlight></codeline>
<codeline lineno="35"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>bittensor</highlight></codeline>
<codeline lineno="36"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/><ref refid="namespacebittensor_1_1__endpoint_1_1endpoint__impl" kindref="compound">bittensor._endpoint.endpoint_impl</ref><sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>Endpoint</highlight></codeline>
<codeline lineno="37"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/><ref refid="namespacebittensor_1_1__serializer" kindref="compound">bittensor._serializer</ref><sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>serializer,<sp/>serializer_impl</highlight></codeline>
<codeline lineno="38"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/><ref refid="namespacebittensor_1_1__synapse" kindref="compound">bittensor._synapse</ref><sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>TextCausalLM,<sp/>synapse</highlight></codeline>
<codeline lineno="39"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/><ref refid="namespacebittensor_1_1utils_1_1stats" kindref="compound">bittensor.utils.stats</ref><sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>stat_utils</highlight></codeline>
<codeline lineno="40"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/><ref refid="namespacebittensor_1_1utils_1_1codes" kindref="compound">bittensor.utils.codes</ref><sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>codes</highlight></codeline>
<codeline lineno="41"><highlight class="normal"></highlight></codeline>
<codeline lineno="42"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>wandb</highlight></codeline>
<codeline lineno="43"><highlight class="normal"></highlight></codeline>
<codeline lineno="44"><highlight class="normal"></highlight></codeline>
<codeline lineno="45"><highlight class="normal">logger<sp/>=<sp/>logger.opt(colors=</highlight><highlight class="keyword">True</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="46"><highlight class="normal"></highlight></codeline>
<codeline lineno="47"><highlight class="normal"></highlight><highlight class="comment">#<sp/>dummy<sp/>tensor<sp/>that<sp/>triggers<sp/>autograd<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="48"><highlight class="normal">DUMMY<sp/>=<sp/>torch.empty(0,<sp/>requires_grad=</highlight><highlight class="keyword">True</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="49"><highlight class="normal"></highlight></codeline>
<codeline lineno="50"><highlight class="normal"></highlight><highlight class="comment">#<sp/>Global<sp/>prometheus<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="51"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>prometheus_client<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>Summary,<sp/>Counter,<sp/>Histogram,<sp/>CollectorRegistry</highlight></codeline>
<codeline lineno="52"><highlight class="normal">PROM_prometheus_counters<sp/>=<sp/>Counter(</highlight><highlight class="stringliteral">&apos;dendrite_counters&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_counters&apos;</highlight><highlight class="normal">,<sp/>[</highlight><highlight class="stringliteral">&apos;wallet&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;identifier&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;name&apos;</highlight><highlight class="normal">])</highlight></codeline>
<codeline lineno="53"><highlight class="normal">PROM_prometheus_latency<sp/>=<sp/>Histogram(</highlight><highlight class="stringliteral">&apos;dendrite_latency&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_latency&apos;</highlight><highlight class="normal">,<sp/>[</highlight><highlight class="stringliteral">&apos;wallet&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;identifier&apos;</highlight><highlight class="normal">],<sp/>buckets=list(range(0,bittensor.__blocktime__,1)))<sp/></highlight></codeline>
<codeline lineno="54"><highlight class="normal">PROM_prometheus_latency_per_uid<sp/>=<sp/>Summary(</highlight><highlight class="stringliteral">&apos;dendrite_latency_per_uid&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_latency_per_uid&apos;</highlight><highlight class="normal">,<sp/>[</highlight><highlight class="stringliteral">&apos;wallet&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;identifier&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;uid&apos;</highlight><highlight class="normal">])</highlight></codeline>
<codeline lineno="55"><highlight class="normal">PROM_prometheus_successes_per_uid<sp/>=<sp/>Counter(</highlight><highlight class="stringliteral">&apos;dendrite_successes_per_uid&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_successes_per_uid&apos;</highlight><highlight class="normal">,<sp/>[</highlight><highlight class="stringliteral">&apos;wallet&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;identifier&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;uid&apos;</highlight><highlight class="normal">])</highlight></codeline>
<codeline lineno="56"><highlight class="normal">PROM_prometheus_failures_per_uid<sp/>=<sp/>Counter(</highlight><highlight class="stringliteral">&apos;dendrite_failures_per_uid&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_failures_per_uid&apos;</highlight><highlight class="normal">,<sp/>[</highlight><highlight class="stringliteral">&apos;wallet&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;identifier&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;uid&apos;</highlight><highlight class="normal">])</highlight></codeline>
<codeline lineno="57"><highlight class="normal"></highlight></codeline>
<codeline lineno="58" refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">class<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite" kindref="compound">Dendrite</ref>(torch.autograd.Function):</highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>This<sp/>is<sp/>the<sp/>implementation<sp/>class<sp/>for<sp/>a<sp/>bittensor.dendrite().<sp/>The<sp/>dendrite<sp/>class<sp/>operates<sp/>as<sp/>a<sp/>normal<sp/>torch<sp/>autograd<sp/>friendly<sp/>operation</highlight></codeline>
<codeline lineno="60"><highlight class="stringliteral"><sp/><sp/><sp/><sp/>which<sp/>accepts<sp/>a<sp/>list<sp/>of<sp/>bittensor.endpoints<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>a<sp/>list<sp/>of<sp/>torch<sp/>tensors.<sp/>The<sp/>passed<sp/>endpoints<sp/>are<sp/>queried<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>the<sp/>passed<sp/>inputs<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>either<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/><sp/><sp/>results<sp/></highlight><highlight class="keywordflow">or</highlight><highlight class="normal"><sp/>zeros.<sp/>The<sp/>operation<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/>fully<sp/>differentiable<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>a<sp/>torch<sp/>computation<sp/>graph<sp/>such<sp/>that<sp/>calls<sp/>to<sp/>loss.backward()<sp/>produce<sp/>Backward<sp/>calls<sp/>on</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/>the<sp/>passed<sp/>endpoints.</highlight></codeline>
<codeline lineno="63"><highlight class="normal"></highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="65"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>config<sp/>(:obj:`<ref refid="classbittensor_1_1__config_1_1config__impl_1_1_config" kindref="compound">bittensor.Config</ref>`,<sp/>`optional`,<sp/>defaults<sp/>to<sp/>bittensor.dendrite.config()):</highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>config<sp/>namespace<sp/>object<sp/>created<sp/>by<sp/>calling<sp/>bittensor.dendrite.config()</highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>wallet<sp/>(:obj:`<ref refid="classbittensor_1_1__wallet_1_1wallet__impl_1_1_wallet" kindref="compound">bittensor.Wallet</ref>`,<sp/>`optional`,<sp/>defaults<sp/>to<sp/><ref refid="classbittensor_1_1__wallet_1_1wallet" kindref="compound">bittensor.wallet</ref>(<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;default&apos;</highlight><highlight class="normal">,<sp/>wallet<sp/>=</highlight><highlight class="stringliteral">&apos;default&apos;</highlight><highlight class="normal">)):</highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>A<sp/>bittensor<sp/>wallet<sp/>object<sp/>containing<sp/>a<sp/>pair<sp/>of<sp/>cryptographic<sp/>keys,<sp/>the<sp/>hot<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>coldkey,<sp/>used<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>signing<sp/>messages</highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>receptor_pool<sp/>(:obj:`<ref refid="classbittensor_1_1__receptor_1_1receptor__pool__impl_1_1_receptor_pool" kindref="compound">bittensor.ReceptorPool</ref>`,<sp/>`optional`,<sp/>defaults<sp/>to<sp/><ref refid="classbittensor_1_1__receptor_1_1receptor__pool" kindref="compound">bittensor.receptor_pool</ref>()):</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>A<sp/>bittensor<sp/>receptor<sp/>pool<sp/>object<sp/>which<sp/>maintains<sp/>a<sp/>set<sp/>of<sp/>connections<sp/>to<sp/>other<sp/>peers<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>the<sp/>network<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>operates<sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>a<sp/>normal<sp/>torch.nn.Module.<sp/>By<sp/>default<sp/>this<sp/>object<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/>created<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>the<sp/>dendrite<sp/>config.</highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="74"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="75"><highlight class="stringliteral"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a80e3be1a7ae6a4090f8689bd550949c5" kindref="member">__init__</ref>(</highlight></codeline>
<codeline lineno="76"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="77"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>config:<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Config&apos;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>wallet:<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Wallet&apos;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>receptor_pool:<sp/></highlight><highlight class="stringliteral">&apos;bittensor.ReceptorPool&apos;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>manager:<sp/></highlight><highlight class="stringliteral">&apos;BaseManager&apos;</highlight><highlight class="normal"><sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/><sp/><sp/>):</highlight></codeline>
<codeline lineno="82"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Initializes<sp/>a<sp/>new<sp/>Dendrite<sp/>entry<sp/>point.</highlight></codeline>
<codeline lineno="83"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="84"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>receptor_pool<sp/>(:obj:`<ref refid="classbittensor_1_1__receptor_1_1receptor__pool__impl_1_1_receptor_pool" kindref="compound">bittensor.ReceptorPool</ref>`,<sp/>`required`):</highlight></codeline>
<codeline lineno="85"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>bittensor<sp/>receptor<sp/>pool</highlight></codeline>
<codeline lineno="86"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="87"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a004e88ced27124365900597f2ec74fdb" kindref="member">config</ref><sp/>=<sp/>config</highlight></codeline>
<codeline lineno="88"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref><sp/>=<sp/>wallet</highlight></codeline>
<codeline lineno="89"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aba6742399ca4fb120ffc9437d82e0751" kindref="member">receptor_pool</ref><sp/>=<sp/>receptor_pool</highlight></codeline>
<codeline lineno="90"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a8e0f5727d0f7186963334e477ee0d243" kindref="member">manager</ref><sp/>=<sp/>manager</highlight></codeline>
<codeline lineno="91"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Dendrite<sp/>stats</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="92"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>num<sp/>of<sp/>time<sp/>we<sp/>have<sp/>sent<sp/>request<sp/>to<sp/>a<sp/>peer,<sp/>received<sp/>successful<sp/>respond,<sp/>and<sp/>the<sp/>respond<sp/>time</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="93"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref><sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a021071b2859f5bc990a73803ac3f90f7" kindref="member">_init_stats</ref>()</highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref><sp/>=<sp/>uuid.uuid1()</highlight></codeline>
<codeline lineno="95"><highlight class="normal"></highlight></codeline>
<codeline lineno="96"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">__str__(self):</highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="stringliteral">&quot;Dendrite({},<sp/>{})&quot;</highlight><highlight class="normal">.format(self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aba6742399ca4fb120ffc9437d82e0751" kindref="member">receptor_pool</ref>)</highlight></codeline>
<codeline lineno="98"><highlight class="normal"></highlight></codeline>
<codeline lineno="99"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">__repr__(self):</highlight></codeline>
<codeline lineno="100"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a6ad20828b96711b3b05cb5448da88066" kindref="member">__str__</ref>()</highlight></codeline>
<codeline lineno="101"><highlight class="normal"></highlight></codeline>
<codeline lineno="102"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">__del__(self):</highlight></codeline>
<codeline lineno="103"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a8e0f5727d0f7186963334e477ee0d243" kindref="member">manager</ref>:</highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a8e0f5727d0f7186963334e477ee0d243" kindref="member">manager</ref>.deduct_connection_count()</highlight></codeline>
<codeline lineno="105"><highlight class="normal"></highlight></codeline>
<codeline lineno="106"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>bittensor<sp/>!=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>bittensor.logging.success(</highlight><highlight class="stringliteral">&apos;Dendrite<sp/>Deleted&apos;</highlight><highlight class="normal">,<sp/>sufix<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;&apos;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="108"><highlight class="normal"></highlight></codeline>
<codeline lineno="109"><highlight class="normal"></highlight></codeline>
<codeline lineno="110"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="preprocessor">@staticmethod</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1af5a6b8827b65e4e7991aecc1872de492" kindref="member">forward</ref>(</highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ctx,</highlight></codeline>
<codeline lineno="113"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dendrite:<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Dendrite&apos;</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dummy:<sp/>torch.Tensor,</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>List[</highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">],</highlight></codeline>
<codeline lineno="116"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses:<sp/>List[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Synapse&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="117"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout:<sp/>int,</highlight></codeline>
<codeline lineno="118"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad:<sp/>bool,</highlight></codeline>
<codeline lineno="119"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>*inputs:<sp/>torch.Tensor</highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple[torch.Tensor,<sp/>...]:</highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;<sp/>Internal<sp/>autograd-friendly<sp/>Forward<sp/>RPC<sp/>call<sp/>to<sp/>a<sp/>list<sp/>of<sp/>neuron<sp/>endpoints.</highlight></codeline>
<codeline lineno="122"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="123"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="124"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ctx:<sp/>(:obj:`torch.autograd.ctx`,<sp/>`required`):</highlight></codeline>
<codeline lineno="125"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Autograd<sp/>context,<sp/>saves<sp/>state<sp/>information<sp/>between<sp/>forward<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>backward<sp/>calls.<sp/>i.e.<sp/>inputs<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>gradient<sp/>computation.</highlight></codeline>
<codeline lineno="126"><highlight class="normal"></highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dendrite:<sp/>(:obj:`<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite" kindref="compound">bittensor.Dendrite</ref>`,<sp/>`required`):</highlight></codeline>
<codeline lineno="128"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Pointer<sp/>to<sp/>a<sp/>bittensor<sp/>dendrite<sp/>object<sp/>on<sp/>which<sp/>we<sp/>are<sp/>creating<sp/>the<sp/>forward<sp/>requests.</highlight></codeline>
<codeline lineno="129"><highlight class="normal"></highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dummy:<sp/>(:obj:`torch.Tensor`,<sp/>`required`):</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Dummy<sp/>torch<sp/>tensor<sp/>used<sp/>to<sp/>ensure<sp/>that<sp/>torch.backward<sp/>computation<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/>called<sp/>on<sp/>this<sp/>function<sp/></highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>regardless<sp/>of<sp/>the<sp/>input<sp/>types.</highlight></codeline>
<codeline lineno="133"><highlight class="normal"></highlight></codeline>
<codeline lineno="134"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref></highlight><highlight class="stringliteral">&apos;]`<sp/>of<sp/>shape<sp/>:obj:`(n_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="135"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>endpoints<sp/>which<sp/>match<sp/>length<sp/>of<sp/>inputs.<sp/>Inputs<sp/>are<sp/>sent<sp/>forward<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="136"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="137"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>(:obj:`List[<sp/>&apos;bittensor.Synapse&apos;</highlight><highlight class="normal"><sp/>]`<sp/>of<sp/>shape<sp/>:obj:`(num_synapses)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Bittensor<sp/>synapse<sp/>objects<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>arguments.<sp/>Each<sp/>corresponds<sp/>to<sp/>a<sp/>synapse<sp/>function<sp/>on<sp/>the<sp/>axon.</highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Responses<sp/>are<sp/>packed<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>this<sp/>ordering.<sp/></highlight></codeline>
<codeline lineno="140"><highlight class="normal"></highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>(int):</highlight></codeline>
<codeline lineno="142"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>request<sp/>timeout.</highlight></codeline>
<codeline lineno="143"><highlight class="normal"></highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>(int,<sp/>default<sp/>=<sp/>dendrite.requires_grad,<sp/>`optional`):</highlight></codeline>
<codeline lineno="145"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>true,<sp/>the<sp/>backward<sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>triggers<sp/>passing<sp/>gradients<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="146"><highlight class="normal"></highlight></codeline>
<codeline lineno="147"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>(:obj:`List[torch.Tensor]`<sp/>of<sp/>shape<sp/>:obj:`(n_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="148"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>torch<sp/>tensors<sp/>to<sp/>be<sp/>sent<sp/>to<sp/>the<sp/>associated<sp/>endpoints.</highlight></codeline>
<codeline lineno="149"><highlight class="normal"></highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>(:obj:`torch.LongTensor`<sp/>of<sp/>shape<sp/>:obj:`(n_endpoints)`<sp/>`required`):</highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Return<sp/>code<sp/>associated<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>forward<sp/>call.</highlight></codeline>
<codeline lineno="153"><highlight class="normal"></highlight></codeline>
<codeline lineno="154"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>(:obj:`torch.FloatTensor`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="155"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>per<sp/>call.</highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="157"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs<sp/>(:obj:`List[torch.FloatTensor`<sp/>of<sp/>shape<sp/>:obj:`num_synapses<sp/>*<sp/>n_endpoints<sp/>*<sp/>(-1,<sp/>-1,<sp/>-1)<sp/>`,<sp/>`required`):</highlight></codeline>
<codeline lineno="158"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>outputs<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>each<sp/>synapses<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>each<sp/>endpoint<sp/>unfolded<sp/>into<sp/>a<sp/>single<sp/>list.<sp/>Non-responses<sp/>are<sp/>zeroes<sp/>of<sp/>expected<sp/>shape.</highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="160"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ctx.receptor_pool<sp/>=<sp/>dendrite.receptor_pool</highlight></codeline>
<codeline lineno="161"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ctx.endpoints,<sp/>ctx.synapses,<sp/>ctx.inputs,<sp/>ctx.timeout,<sp/>ctx.does_requires_grad<sp/>=<sp/>endpoints,<sp/>synapses,<sp/>inputs,<sp/>timeout,<sp/>requires_grad</highlight></codeline>
<codeline lineno="162"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs:List[torch.Tensor]<sp/>=<sp/>[x.cpu().clone().detach()<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>x<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>inputs]</highlight></codeline>
<codeline lineno="163"><highlight class="normal"></highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Ouputs<sp/>are<sp/>list<sp/>of<sp/>lists<sp/>where<sp/>the<sp/>outer<sp/>list<sp/>corresponds<sp/>to<sp/>the<sp/>endpoints<sp/>and<sp/>the<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>inner<sp/>list<sp/>corresponds<sp/>to<sp/>the<sp/>synapses.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>forward_outputs,<sp/>forward_codes,<sp/>forward_times<sp/>=<sp/>ctx.receptor_pool.forward<sp/>(</highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>=<sp/>endpoints,</highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>synapses,</highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>inputs,</highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>=<sp/>timeout,</highlight></codeline>
<codeline lineno="171"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ctx.forward_codes<sp/>=<sp/>forward_codes</highlight></codeline>
<codeline lineno="173"><highlight class="normal"></highlight></codeline>
<codeline lineno="174"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>We<sp/>need<sp/>to<sp/>flatten<sp/>the<sp/>outputs<sp/>across<sp/>the<sp/>synapse<sp/>dimension.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="175"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">flatten(t):</highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>[item<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>sublist<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>t<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>item<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>sublist]</highlight></codeline>
<codeline lineno="177"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>flattened<sp/>items<sp/>now<sp/>have<sp/>length<sp/>num_endpoints<sp/>*<sp/>num_synapses</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="178"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>where<sp/>endpoint<sp/>i&apos;s<sp/>jth<sp/>outputs<sp/>is<sp/>at<sp/>position<sp/>(num_synapses<sp/>*<sp/>i<sp/>)<sp/>+<sp/>j</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="179"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>flattened_forward_codes:<sp/>List[<sp/>bittensor.proto.ReturnCode<sp/>]<sp/>=<sp/>flatten(<sp/>forward_codes<sp/>)</highlight></codeline>
<codeline lineno="180"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>flattened_forward_times:<sp/>List[float]<sp/>=<sp/>flatten(<sp/>forward_times<sp/>)</highlight></codeline>
<codeline lineno="181"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>flattened_forward_outputs:<sp/>List[torch.Tensor]<sp/>=<sp/>flatten(<sp/>forward_outputs<sp/>)</highlight></codeline>
<codeline lineno="182"><highlight class="normal"></highlight></codeline>
<codeline lineno="183"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>We<sp/>will<sp/>pack<sp/>all<sp/>the<sp/>codes<sp/>and<sp/>times<sp/>into<sp/>a<sp/>single<sp/>tensor<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="184"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>flattened_torch_codes:<sp/>torch.LongTensor<sp/>=<sp/>torch.tensor(flattened_forward_codes,<sp/>dtype=torch.int64)</highlight></codeline>
<codeline lineno="185"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>flattened_torch_times:<sp/>torch.FloatTensor<sp/><sp/>=<sp/>torch.tensor(flattened_forward_times,<sp/>dtype=torch.float32)</highlight></codeline>
<codeline lineno="186"><highlight class="normal"></highlight></codeline>
<codeline lineno="187"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Return<sp/>all<sp/>outputs<sp/>as<sp/>a<sp/>tuple<sp/>of<sp/>torch<sp/>tensors<sp/>of<sp/>length<sp/>2<sp/>+<sp/>(num_endpoints<sp/>*<sp/>num_synapses)<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="188"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>(flattened_torch_codes,<sp/>flattened_torch_times,<sp/>*flattened_forward_outputs)</highlight></codeline>
<codeline lineno="189"><highlight class="normal"></highlight></codeline>
<codeline lineno="190"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="preprocessor">@staticmethod</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="191"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="preprocessor">@once_differentiable</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="192"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a2bff366b9b2753b63a570c84ceec955e" kindref="member">backward</ref>(</highlight></codeline>
<codeline lineno="193"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ctx,</highlight></codeline>
<codeline lineno="194"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>unused_code_grads:<sp/>torch.FloatTensor,</highlight></codeline>
<codeline lineno="195"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>unused_time_grads:<sp/>torch.FloatTensor,</highlight></codeline>
<codeline lineno="196"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>*output_grads:<sp/>torch.FloatTensor</highlight></codeline>
<codeline lineno="197"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple[Optional[torch.Tensor],<sp/>...]:</highlight></codeline>
<codeline lineno="198"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;<sp/>Internal<sp/>autograd-friendly<sp/>Backward<sp/>RPC<sp/>call<sp/>to<sp/>a<sp/>list<sp/>of<sp/>neuron<sp/>endpoints.</highlight></codeline>
<codeline lineno="199"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="200"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="201"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>ctx:<sp/>(:obj:`torch.autograd.ctx`,<sp/>`required`):</highlight></codeline>
<codeline lineno="202"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Autograd<sp/>context,<sp/>saves<sp/>state<sp/>information<sp/>between<sp/>forward<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>backward<sp/>calls.<sp/>i.e.<sp/>inputs<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>gradient<sp/>computation.</highlight></codeline>
<codeline lineno="203"><highlight class="normal"></highlight></codeline>
<codeline lineno="204"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>unused_code_grads:<sp/>(:obj:`List[torch.Tensor]`<sp/>of<sp/>shape<sp/>:obj:`(shape)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="205"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Gradients<sp/>of<sp/>this<sp/>function</highlight><highlight class="stringliteral">&apos;s<sp/>codes.<sp/>(Unused)</highlight></codeline>
<codeline lineno="206"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="207"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>unused_time_grads:<sp/>(:obj:`List[torch.Tensor]`<sp/>of<sp/>shape<sp/>:obj:`(shape)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="208"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Gradients<sp/>of<sp/>this<sp/>function&apos;s<sp/>query<sp/>times.<sp/>(Unused)</highlight></codeline>
<codeline lineno="209"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="210"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>grads<sp/>(:obj:`List[torch.Tensor]`<sp/>of<sp/>shape<sp/>:obj:`(shape)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="211"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Gradients<sp/>of<sp/>this<sp/>function&apos;s<sp/>outputs<sp/>computed<sp/>during<sp/>the<sp/>loss.backward()<sp/>call.</highlight></codeline>
<codeline lineno="212"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>This<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/>a<sp/>list<sp/>item<sp/>of<sp/>size<sp/>num_endpoints<sp/>*<sp/>num_synapses.</highlight></codeline>
<codeline lineno="213"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="214"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="215"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>DUMMY,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="216"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs<sp/>(:obj:`List[torch.FloatTensor],<sp/>`optional`):</highlight></codeline>
<codeline lineno="217"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Gradient<sp/>results<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>each<sp/>input.</highlight></codeline>
<codeline lineno="218"><highlight class="normal"></highlight></codeline>
<codeline lineno="219"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="220"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>output_grads<sp/>is<sp/>a<sp/>list<sp/>of<sp/>gradients<sp/>per<sp/>synapse.<sp/>They<sp/>need<sp/>to<sp/>be<sp/>packed<sp/>(unflattened)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="221"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>into<sp/>a<sp/>list<sp/>of<sp/>lists.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="222"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>packed_grads:<sp/>List[<sp/>List<sp/>[<sp/>torch.FloatTensor<sp/>]<sp/>]<sp/>=<sp/>[<sp/>output_grads[<sp/>s<sp/>:<sp/>s<sp/>+<sp/>len(ctx.synapses)<sp/>]<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>s<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range<sp/>(0,<sp/>len(output_grads),<sp/>len(<sp/>ctx.synapses<sp/>))<sp/>]</highlight></codeline>
<codeline lineno="223"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>ctx.does_requires_grad:</highlight></codeline>
<codeline lineno="224"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input_grads,<sp/>_,<sp/>_<sp/>=<sp/>ctx.receptor_pool.backward(</highlight></codeline>
<codeline lineno="225"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>=<sp/>ctx.endpoints,</highlight></codeline>
<codeline lineno="226"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>ctx.inputs,</highlight></codeline>
<codeline lineno="227"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>ctx.synapses,</highlight></codeline>
<codeline lineno="228"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>grads<sp/>=<sp/>packed_grads,</highlight></codeline>
<codeline lineno="229"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>=<sp/>ctx.timeout,</highlight></codeline>
<codeline lineno="230"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="231"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Input<sp/>grads<sp/>is<sp/>a<sp/>list<sp/>of<sp/>lists</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="232"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>We<sp/>need<sp/>to<sp/>flatten<sp/>the<sp/>outputs<sp/>across<sp/>the<sp/>synapse<sp/>dimension.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="233"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">flatten(t):</highlight></codeline>
<codeline lineno="234"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>[item<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>sublist<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>t<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>item<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>sublist]</highlight></codeline>
<codeline lineno="235"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>flattened_input_grads:<sp/>List[torch.FloatTensor]<sp/><sp/>=<sp/>flatten(<sp/>input_grads<sp/>)</highlight></codeline>
<codeline lineno="236"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/>*flattened_input_grads)</highlight></codeline>
<codeline lineno="237"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="238"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Create<sp/>nill<sp/>responses<sp/>for<sp/>each<sp/>input<sp/>and<sp/>each<sp/>synapse.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="239"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input_grads<sp/>=<sp/>[<sp/>syn.nill_backward_response_tensor<sp/>(<sp/>inp<sp/>)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>inp<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>ctx.inputs<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>syn<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>ctx.synapses<sp/>]</highlight></codeline>
<codeline lineno="240"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/>*input_grads)</highlight></codeline>
<codeline lineno="241"><highlight class="normal"></highlight></codeline>
<codeline lineno="242"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ab0bedbfadc59c5895ad47f48f05b7b69" kindref="member">_forward</ref>(</highlight></codeline>
<codeline lineno="243"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="244"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>List<sp/>[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="245"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses:<sp/>List[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Synapse&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="246"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs:<sp/>List<sp/>[<sp/>torch.Tensor<sp/>],</highlight></codeline>
<codeline lineno="247"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout:<sp/>Optional<sp/>[<sp/>int<sp/>]<sp/><sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="248"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad:<sp/>Optional<sp/>[<sp/>bool<sp/>]<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="249"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple<sp/>[<sp/>List[<sp/>torch.Tensor<sp/>],<sp/>List[<sp/>torch.LongTensor<sp/>],<sp/>List<sp/>[<sp/>torch.FloatTensor<sp/>]]:</highlight></codeline>
<codeline lineno="250"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Internal<sp/>Forward<sp/>tensor<sp/>inputs<sp/>to<sp/>a<sp/>list<sp/>of<sp/>neuron<sp/>endpoints.</highlight></codeline>
<codeline lineno="251"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="252"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="253"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="254"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>remote<sp/>endpoints<sp/>which<sp/>match<sp/>length<sp/>of<sp/>inputs.<sp/>Tensors<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>inputs<sp/>are<sp/>sent<sp/>forward<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="255"><highlight class="normal"></highlight></codeline>
<codeline lineno="256"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>(:obj:`List[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Synapse&apos;</highlight><highlight class="normal"><sp/>]`<sp/>of<sp/>shape<sp/>:obj:`(num_synapses)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="257"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Bittensor<sp/>synapse<sp/>objects<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>arguments.<sp/>Each<sp/>corresponds<sp/>to<sp/>a<sp/>synapse<sp/>function<sp/>on<sp/>the<sp/>axon.</highlight></codeline>
<codeline lineno="258"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Responses<sp/>are<sp/>packed<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>this<sp/>ordering.<sp/></highlight></codeline>
<codeline lineno="259"><highlight class="normal"></highlight></codeline>
<codeline lineno="260"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>(:obj:`List[torch.Tensor]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints<sp/>*<sp/>[shape])`,<sp/>`required`):</highlight></codeline>
<codeline lineno="261"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>tensors<sp/>to<sp/>send<sp/>to<sp/>corresponding<sp/>endpoints.<sp/>Tensors<sp/>are<sp/>of<sp/>arbitrary<sp/>type<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>shape<sp/>depending<sp/>on<sp/>the</highlight></codeline>
<codeline lineno="262"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse.</highlight></codeline>
<codeline lineno="263"><highlight class="normal"></highlight></codeline>
<codeline lineno="264"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>(int,<sp/>default<sp/>=<sp/>dendrite.timeout,<sp/>`optional`):</highlight></codeline>
<codeline lineno="265"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>request<sp/>timeout.</highlight></codeline>
<codeline lineno="266"><highlight class="normal"></highlight></codeline>
<codeline lineno="267"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>(int,<sp/>default<sp/>=<sp/>dendrite.requires_grad,<sp/>`optional`):</highlight></codeline>
<codeline lineno="268"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>true,<sp/>the<sp/>backward<sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>triggers<sp/>passing<sp/>gradients<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="269"><highlight class="normal"></highlight></codeline>
<codeline lineno="270"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="271"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs<sp/>(:obj:`List[torch.FloatTensor]`<sp/>of<sp/>shape<sp/>:obj:`(batch_size,<sp/>sequence_len,<sp/>bittensor.__network_dim__)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="272"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Output<sp/>encodings<sp/>of<sp/>inputs<sp/>produced<sp/>by<sp/>the<sp/>remote<sp/>endpoints.<sp/>Non-responses<sp/>are<sp/>zeroes<sp/>of<sp/>common<sp/>shape.</highlight></codeline>
<codeline lineno="273"><highlight class="normal"></highlight></codeline>
<codeline lineno="274"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>(:obj:`List[torch.LongTensor]`<sp/>of<sp/>shape<sp/>:obj:`[num_endpoints]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="275"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Return<sp/>codes<sp/>per<sp/>endpoint<sp/>per<sp/>synapse.</highlight></codeline>
<codeline lineno="276"><highlight class="normal"></highlight></codeline>
<codeline lineno="277"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>(:obj:`torch.FloatTensor`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="278"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Call<sp/>times<sp/>per<sp/>endpoint<sp/>per<sp/>synapse.</highlight></codeline>
<codeline lineno="279"><highlight class="normal"></highlight></codeline>
<codeline lineno="280"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="281"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout:int<sp/>=<sp/>timeout<sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>timeout<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a004e88ced27124365900597f2ec74fdb" kindref="member">config</ref>.dendrite.timeout</highlight></codeline>
<codeline lineno="282"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad:bool<sp/>=<sp/>requires_grad<sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>requires_grad<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a004e88ced27124365900597f2ec74fdb" kindref="member">config</ref>.dendrite.requires_grad</highlight></codeline>
<codeline lineno="283"><highlight class="normal"></highlight></codeline>
<codeline lineno="284"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>The<sp/>forwarnd<sp/>response<sp/>is<sp/>a<sp/>tuple<sp/>with<sp/>shape<sp/>(flattened_torch_codes,<sp/>flattened_torch_times,<sp/>*flattened_forward_outputs)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="285"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>packed<sp/>with<sp/>torch<sp/>tensors<sp/>of<sp/>length<sp/>2<sp/>+<sp/>(num_endpoints<sp/>*<sp/>num_synapses).<sp/>The<sp/>first<sp/>two<sp/>tensors<sp/>are<sp/>codes<sp/>and<sp/>times</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="286"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>the<sp/>last<sp/>(num_endpoints<sp/>*<sp/>num_synapses)<sp/>tensors<sp/>are<sp/>per<sp/>endpoint<sp/>per<sp/>synapse<sp/>output<sp/>tensors.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="287"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>forward_response:<sp/>List[torch.Tensor]<sp/>=<sp/>Dendrite.apply<sp/>(</highlight></codeline>
<codeline lineno="288"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="289"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>DUMMY,</highlight></codeline>
<codeline lineno="290"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints,</highlight></codeline>
<codeline lineno="291"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses,</highlight></codeline>
<codeline lineno="292"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout,</highlight></codeline>
<codeline lineno="293"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad,</highlight></codeline>
<codeline lineno="294"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>*inputs</highlight></codeline>
<codeline lineno="295"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="296"><highlight class="normal"></highlight></codeline>
<codeline lineno="297"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Split<sp/>codes<sp/>into<sp/>num_synapse<sp/>lists<sp/>of<sp/>codes</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="298"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>split_codes<sp/>is<sp/>a<sp/>list<sp/>of<sp/>tensors<sp/>codes<sp/>each<sp/>with<sp/>length<sp/>num_synapses</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="299"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes:<sp/>torch.LongTensor<sp/>=<sp/>forward_response[0]</highlight></codeline>
<codeline lineno="300"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>packed_codes:<sp/>List[torch.LongTensor]<sp/>=<sp/>torch.split(<sp/>codes,<sp/>len(<sp/>synapses<sp/>)<sp/>)</highlight></codeline>
<codeline lineno="301"><highlight class="normal"></highlight></codeline>
<codeline lineno="302"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Split<sp/>times<sp/>into<sp/>num_synapse<sp/>lists<sp/>of<sp/>codes</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="303"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>split_times<sp/>is<sp/>a<sp/>list<sp/>of<sp/>tensors<sp/>times<sp/>each<sp/>with<sp/>length<sp/>num_synapses</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="304"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times:<sp/>torch.FloatTensor<sp/><sp/>=<sp/>forward_response[1]</highlight></codeline>
<codeline lineno="305"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>packed_times:<sp/>List[torch.FloatTensor]<sp/>=<sp/>torch.split(<sp/>times,<sp/>len(<sp/>synapses<sp/>)<sp/>)</highlight></codeline>
<codeline lineno="306"><highlight class="normal"></highlight></codeline>
<codeline lineno="307"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Output<sp/>responses<sp/>is<sp/>a<sp/>list<sp/>with<sp/>length<sp/>num_endpoints<sp/>num_synapses</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="308"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>we<sp/>need<sp/>to<sp/>pack<sp/>the<sp/>responses<sp/>into<sp/>a<sp/>list<sp/>of<sp/>lists<sp/>corresponding<sp/>to</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="309"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>each<sp/>endpoint.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="310"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs:<sp/>List[torch.Tensor]<sp/>=<sp/>forward_response[2:]</highlight></codeline>
<codeline lineno="311"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>packed_outputs:<sp/>List[<sp/>List[torch.Tensor]<sp/>]<sp/>=<sp/>[<sp/><sp/>outputs[<sp/>s<sp/>:<sp/>s<sp/>+<sp/>len(synapses)<sp/>]<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>s<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range<sp/>(0,<sp/>len(outputs),<sp/>len(<sp/>synapses<sp/>))<sp/>]</highlight></codeline>
<codeline lineno="312"><highlight class="normal"></highlight></codeline>
<codeline lineno="313"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>===<sp/>Prometheus<sp/>counters.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="314"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a004e88ced27124365900597f2ec74fdb" kindref="member">config</ref>.dendrite.prometheus.level<sp/>!=<sp/>bittensor.prometheus.level.OFF.name:</highlight></codeline>
<codeline lineno="315"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;total_requests&apos;</highlight><highlight class="normal"><sp/>).inc()</highlight></codeline>
<codeline lineno="316"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;total_endpoint_requests&apos;</highlight><highlight class="normal"><sp/>).inc(<sp/>len(endpoints)<sp/>)</highlight></codeline>
<codeline lineno="317"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;total_request_bytes&apos;</highlight><highlight class="normal"><sp/>).inc(<sp/>sum(p.element_size()<sp/>*<sp/>p.nelement()<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>p<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>inputs)<sp/>)</highlight></codeline>
<codeline lineno="318"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;total_request_params&apos;</highlight><highlight class="normal"><sp/>).inc(<sp/>sum(p.numel()<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>p<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>inputs)<sp/>)</highlight></codeline>
<codeline lineno="319"><highlight class="normal"></highlight></codeline>
<codeline lineno="320"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Capture<sp/>synapses.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="321"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>synapse<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>enumerate(<sp/>synapses<sp/>):</highlight></codeline>
<codeline lineno="322"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/>str(synapse)<sp/>).inc()</highlight></codeline>
<codeline lineno="323"><highlight class="normal"></highlight></codeline>
<codeline lineno="324"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>i<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(len(endpoints)):</highlight></codeline>
<codeline lineno="325"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>n_success<sp/>=<sp/>(codes[i]<sp/>==<sp/>1).sum().item()</highlight></codeline>
<codeline lineno="326"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>is_success<sp/>=<sp/>(n_success<sp/>&gt;<sp/>0)<sp/></highlight><highlight class="comment">#<sp/>One<sp/>is<sp/>a<sp/>success.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="327"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>response_time<sp/>=<sp/>times[i].mean().item()</highlight></codeline>
<codeline lineno="328"><highlight class="normal"></highlight></codeline>
<codeline lineno="329"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Capture<sp/>outputs.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="330"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;total_response_bytes&apos;</highlight><highlight class="normal"><sp/>).inc(<sp/>sum(p.element_size()<sp/>*<sp/>p.nelement()<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>p<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>outputs[i])<sp/>)</highlight></codeline>
<codeline lineno="331"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;total_response_params&apos;</highlight><highlight class="normal"><sp/>).inc(<sp/>sum(p.numel()<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>p<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>outputs[i])<sp/>)</highlight></codeline>
<codeline lineno="332"><highlight class="normal"></highlight></codeline>
<codeline lineno="333"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Capture<sp/>global<sp/>success<sp/>rates.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="334"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>is_success:<sp/></highlight></codeline>
<codeline lineno="335"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;total_success&apos;</highlight><highlight class="normal"><sp/>).inc()</highlight></codeline>
<codeline lineno="336"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_latency.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>).observe(<sp/>response_time<sp/>)</highlight></codeline>
<codeline lineno="337"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:<sp/></highlight></codeline>
<codeline lineno="338"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_counters.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>name<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;total_failure&apos;</highlight><highlight class="normal"><sp/>).inc()</highlight></codeline>
<codeline lineno="339"><highlight class="normal"></highlight></codeline>
<codeline lineno="340"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>===<sp/>Prometheus<sp/>DEBUG<sp/>(per<sp/>uid<sp/>info.)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="341"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a004e88ced27124365900597f2ec74fdb" kindref="member">config</ref>.dendrite.prometheus.level<sp/>==<sp/>bittensor.prometheus.level.DEBUG.name:</highlight></codeline>
<codeline lineno="342"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>is_success:</highlight></codeline>
<codeline lineno="343"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_latency_per_uid.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>uid<sp/>=<sp/>str(endpoints[i].uid)<sp/>).observe(<sp/>response_time<sp/>)</highlight></codeline>
<codeline lineno="344"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_successes_per_uid.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>uid<sp/>=<sp/>str(endpoints[i].uid)<sp/>).inc()</highlight></codeline>
<codeline lineno="345"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="346"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>PROM_prometheus_failures_per_uid.labels(<sp/>wallet<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ac4939061f29081ffca15953a91d3e842" kindref="member">wallet</ref>.hotkey.ss58_address,<sp/>identifier<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aa4f6aa19bbf9f43e52b04d2c9f86b7fe" kindref="member">_prometheus_uuid</ref>,<sp/>uid<sp/>=<sp/>str(endpoints[i].uid)<sp/>).inc()</highlight></codeline>
<codeline lineno="347"><highlight class="normal"></highlight></codeline>
<codeline lineno="348"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>packed_outputs,<sp/>packed_codes,<sp/>packed_times</highlight></codeline>
<codeline lineno="349"><highlight class="normal"></highlight></codeline>
<codeline lineno="350"><highlight class="normal"></highlight></codeline>
<codeline lineno="351"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a13fd8cc44e4289f9662236107c6577b1" kindref="member">generate</ref>(</highlight></codeline>
<codeline lineno="352"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="353"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>Union[<sp/>torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[</highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">],<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="354"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>prompt:<sp/>Union[str,<sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor],</highlight></codeline>
<codeline lineno="355"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout:<sp/>int<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="356"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>topk:int<sp/>=<sp/>50,<sp/></highlight></codeline>
<codeline lineno="357"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_to_generate:<sp/>int<sp/>=<sp/>256,</highlight></codeline>
<codeline lineno="358"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_beams:<sp/>int<sp/>=<sp/>5,</highlight></codeline>
<codeline lineno="359"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>no_repeat_ngram_size:<sp/>int<sp/>=<sp/>2,</highlight></codeline>
<codeline lineno="360"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>early_stopping:<sp/>bool<sp/>=<sp/></highlight><highlight class="keyword">False</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="361"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_return_sequences:<sp/>int<sp/>=<sp/>1,</highlight></codeline>
<codeline lineno="362"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>do_sample:<sp/>bool<sp/>=<sp/></highlight><highlight class="keyword">False</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="363"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>top_p:<sp/>float<sp/>=<sp/>0.95,<sp/></highlight></codeline>
<codeline lineno="364"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>temperature:<sp/>float<sp/>=<sp/>1.0,</highlight></codeline>
<codeline lineno="365"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>repetition_penalty:<sp/>float<sp/>=<sp/>1.0,</highlight></codeline>
<codeline lineno="366"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>length_penalty:<sp/>float<sp/>=<sp/>1.0,</highlight></codeline>
<codeline lineno="367"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>max_time:<sp/>float<sp/>=<sp/>150,</highlight></codeline>
<codeline lineno="368"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_beam_groups:<sp/>int<sp/>=<sp/>1,</highlight></codeline>
<codeline lineno="369"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple[<sp/>List[str],<sp/>List[float],<sp/>List[str]<sp/>]:</highlight></codeline>
<codeline lineno="370"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="371"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns<sp/>a<sp/>tuple<sp/>containing<sp/>the<sp/>prompt<sp/>generations<sp/>produced<sp/>by<sp/>endpoints<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>corresponding<sp/>parsed<sp/>codes<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>query<sp/>times.</highlight></codeline>
<codeline lineno="372"><highlight class="normal"></highlight></codeline>
<codeline lineno="373"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="374"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`Union[torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>],<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="375"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Endpoints<sp/>to<sp/>send<sp/>inputs<sp/>to.<sp/>Endpoint<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="376"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>tensor<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="377"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>set<sp/>of<sp/>endpoint<sp/>tensors<sp/>shape<sp/>[n,<sp/>250]</highlight></codeline>
<codeline lineno="378"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoints<sp/>tensors<sp/>each<sp/>of<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="379"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>object.<sp/>Inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>this<sp/>endpoint<sp/>alone.</highlight></codeline>
<codeline lineno="380"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoint<sp/>objects.<sp/>All<sp/>inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="381"><highlight class="normal"></highlight></codeline>
<codeline lineno="382"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>prompts<sp/>(:obj:`Union[str,<sp/><sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints<sp/>*<sp/>[batch_size,<sp/>sequence_len])`,<sp/>`required`):</highlight></codeline>
<codeline lineno="383"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Tokenized<sp/>sentences<sp/>to<sp/>send<sp/>on<sp/>the<sp/>wire.<sp/>Inputs<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="384"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>string:<sp/>the<sp/>string<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="385"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>strings:<sp/>the<sp/>strings<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="386"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[batch_size,<sp/>sequence_len],<sp/>assumed<sp/>to<sp/>be<sp/>the<sp/>output<sp/>of<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="387"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[n,<sp/>batch_size,<sp/>sequence_len],<sp/>the<sp/>operation<sp/>will<sp/>unbind<sp/>the<sp/>tensor<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>inputs<sp/>to<sp/>endpoints.</highlight></codeline>
<codeline lineno="388"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>tensors<sp/>of<sp/>type<sp/>long<sp/>each<sp/>representing<sp/>a<sp/>tokenized<sp/>sentence<sp/>to<sp/>be<sp/>sent<sp/>to<sp/>each<sp/>endpoint.</highlight></codeline>
<codeline lineno="389"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>inputs<sp/>are<sp/>tensors<sp/>they<sp/>will<sp/>be<sp/>cast<sp/>to<sp/>int64<sp/>format<sp/>before<sp/>sending<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="390"><highlight class="normal"></highlight></codeline>
<codeline lineno="391"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.timeout<sp/>`optional`):</highlight></codeline>
<codeline lineno="392"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Request<sp/>timeout.<sp/>Queries<sp/>that<sp/>do<sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/>respond<sp/>will<sp/>be<sp/>replaced<sp/>by<sp/>zeros.</highlight></codeline>
<codeline lineno="393"><highlight class="normal"></highlight></codeline>
<codeline lineno="394"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Topk<sp/>(:obj:int,<sp/>:default:<sp/>50):</highlight></codeline>
<codeline lineno="395"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>number<sp/>of<sp/>highest<sp/>probability<sp/>vocabulary<sp/>tokens<sp/>to<sp/>keep<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>top-k-filtering.<sp/></highlight></codeline>
<codeline lineno="396"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_to_generate<sp/>(:obj:<sp/>int,<sp/>:default:<sp/>256):</highlight></codeline>
<codeline lineno="397"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>number<sp/>of<sp/>tokens<sp/>to<sp/>generate<sp/>using<sp/>the<sp/>language<sp/>model</highlight></codeline>
<codeline lineno="398"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_beams<sp/>(:obj:<sp/>int,<sp/>:default:<sp/>5):</highlight></codeline>
<codeline lineno="399"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>number<sp/>of<sp/>beams<sp/>to<sp/>keep<sp/>during<sp/>beam<sp/>search</highlight></codeline>
<codeline lineno="400"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>no_repeat_ngram_size<sp/>(:obj:<sp/>int,<sp/>:default:<sp/>2):</highlight></codeline>
<codeline lineno="401"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>number<sp/>of<sp/>repeat<sp/>n<sp/>gram<sp/>allowed</highlight></codeline>
<codeline lineno="402"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>early_stopping:<sp/>(:obj:<sp/>bool,<sp/>:default:<sp/></highlight><highlight class="keyword">True</highlight><highlight class="normal">):</highlight></codeline>
<codeline lineno="403"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>the<sp/>model<sp/>should<sp/>early<sp/>stop<sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>the<sp/>probabilty<sp/>drops<sp/>a<sp/>certain<sp/>threshold</highlight></codeline>
<codeline lineno="404"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_return_sequences:<sp/>(:obj:<sp/>int,<sp/>:default:<sp/>1):</highlight></codeline>
<codeline lineno="405"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>How<sp/>many<sp/>sequences<sp/>should<sp/>the<sp/>model<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="406"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>do_sample<sp/>(:obj:<sp/>bool,<sp/>:default:<sp/></highlight><highlight class="keyword">False</highlight><highlight class="normal">):</highlight></codeline>
<codeline lineno="407"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>the<sp/>model<sp/>should<sp/>do<sp/>sample<sp/>its<sp/>probablity<sp/>during<sp/>generation</highlight></codeline>
<codeline lineno="408"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>top_p<sp/>(:obj:<sp/>float,<sp/>:default:<sp/>0.95):<sp/></highlight></codeline>
<codeline lineno="409"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>probability<sp/>cutoff<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>top<sp/>p<sp/>sampling</highlight></codeline>
<codeline lineno="410"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>temperature:<sp/>(:obj:<sp/>float,<sp/>:default:<sp/>1.0):</highlight></codeline>
<codeline lineno="411"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>value<sp/>used<sp/>to<sp/>module<sp/>the<sp/>next<sp/>token<sp/>probabilities<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>the<sp/>softmax<sp/>calculation</highlight></codeline>
<codeline lineno="412"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>repetition_penalty<sp/>(:obj:<sp/>float,<sp/>:default:<sp/>1.0):</highlight></codeline>
<codeline lineno="413"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>parameter<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>repetition<sp/>penalty.<sp/>1.0<sp/>means<sp/>no<sp/>penalty.</highlight></codeline>
<codeline lineno="414"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>length_penalty<sp/>(:obj:<sp/>float,<sp/>:default:<sp/>1.0):<sp/></highlight></codeline>
<codeline lineno="415"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>parameter<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>length<sp/>penalty.<sp/>0.0<sp/>means<sp/>no<sp/>penalty,<sp/>&lt;0<sp/>to<sp/>encourage<sp/>longer<sp/>sequences.</highlight></codeline>
<codeline lineno="416"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>max_time<sp/>(:obj:<sp/>float,<sp/>:default:<sp/>150):<sp/></highlight></codeline>
<codeline lineno="417"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>maximum<sp/>time<sp/>that<sp/>a<sp/>server<sp/>can<sp/>use<sp/>to<sp/>generate</highlight></codeline>
<codeline lineno="418"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_beam_groups<sp/>(:obj:<sp/>int,<sp/>:default:<sp/>1):</highlight></codeline>
<codeline lineno="419"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Number<sp/>of<sp/>groups<sp/>to<sp/>divide<sp/>num_beams<sp/>into<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>order<sp/>to<sp/>ensure<sp/>diversity<sp/>among<sp/>different<sp/>groups<sp/>of<sp/>beams.<sp/></highlight></codeline>
<codeline lineno="420"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="421"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>(:obj:`List[str]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="422"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Parsed<sp/>codes<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>each<sp/>endpoint<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>query.</highlight></codeline>
<codeline lineno="423"><highlight class="normal"></highlight></codeline>
<codeline lineno="424"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>(:obj:`List[float]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="425"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Query<sp/>times<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>each<sp/>call<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>each<sp/>endpoint.</highlight></codeline>
<codeline lineno="426"><highlight class="normal"></highlight></codeline>
<codeline lineno="427"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>generations<sp/>(:obj:`List[str]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="428"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Generations<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>each<sp/>endpoint.</highlight></codeline>
<codeline lineno="429"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="430"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>tokenizer<sp/>=<sp/><ref refid="classbittensor_1_1__tokenizer_1_1tokenizer" kindref="compound">bittensor.tokenizer</ref>()</highlight></codeline>
<codeline lineno="431"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>response<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1af64a1b06ea6d77b00c6b191f2b95daad" kindref="member">text</ref><sp/>(<sp/></highlight></codeline>
<codeline lineno="432"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints=endpoints,<sp/></highlight></codeline>
<codeline lineno="433"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>prompt,</highlight></codeline>
<codeline lineno="434"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>[</highlight></codeline>
<codeline lineno="435"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse.TextSeq2Seq(</highlight></codeline>
<codeline lineno="436"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>topk<sp/>=<sp/>topk,</highlight></codeline>
<codeline lineno="437"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_to_generate<sp/>=<sp/>num_to_generate,</highlight></codeline>
<codeline lineno="438"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_beams<sp/>=<sp/>num_beams,</highlight></codeline>
<codeline lineno="439"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>no_repeat_ngram_size<sp/>=<sp/>no_repeat_ngram_size,</highlight></codeline>
<codeline lineno="440"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>early_stopping<sp/>=<sp/>early_stopping,</highlight></codeline>
<codeline lineno="441"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_return_sequences<sp/>=<sp/>num_return_sequences,</highlight></codeline>
<codeline lineno="442"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>do_sample<sp/>=<sp/>do_sample,</highlight></codeline>
<codeline lineno="443"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>top_p<sp/>=<sp/>top_p,</highlight></codeline>
<codeline lineno="444"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>temperature<sp/>=<sp/>temperature,</highlight></codeline>
<codeline lineno="445"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>repetition_penalty<sp/>=<sp/>repetition_penalty,</highlight></codeline>
<codeline lineno="446"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>length_penalty<sp/>=<sp/>length_penalty,</highlight></codeline>
<codeline lineno="447"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>max_time<sp/>=<sp/>max_time,</highlight></codeline>
<codeline lineno="448"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>num_beam_groups<sp/>=<sp/>num_beam_groups,</highlight></codeline>
<codeline lineno="449"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="450"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>],</highlight></codeline>
<codeline lineno="451"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>=<sp/>timeout</highlight></codeline>
<codeline lineno="452"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="453"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Parse<sp/>responses<sp/>to<sp/>natural<sp/>language.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="454"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>generations<sp/>=<sp/>[]</highlight></codeline>
<codeline lineno="455"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>text_tensor<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>response[0]:</highlight></codeline>
<codeline lineno="456"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>generations.append(<sp/>tokenizer.decode(<sp/>text_tensor[0][0].long()<sp/>)<sp/>)</highlight></codeline>
<codeline lineno="457"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>=<sp/>[]</highlight></codeline>
<codeline lineno="458"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>code_tensor<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>response[1]:</highlight></codeline>
<codeline lineno="459"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes.append(<sp/><ref refid="namespacebittensor_1_1utils_1_1codes_1ad8c20d0a2927539fd3757cc18bebd6bb" kindref="member">bittensor.utils.codes.code_to_string</ref>(<sp/>code_tensor<sp/>)<sp/>)</highlight></codeline>
<codeline lineno="460"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>=<sp/>[]</highlight></codeline>
<codeline lineno="461"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>time_tensor<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>response[2]:</highlight></codeline>
<codeline lineno="462"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times.append(<sp/>time_tensor.item()<sp/>)</highlight></codeline>
<codeline lineno="463"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>codes,<sp/>times,<sp/>generations</highlight></codeline>
<codeline lineno="464"><highlight class="normal"></highlight></codeline>
<codeline lineno="465"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1af64a1b06ea6d77b00c6b191f2b95daad" kindref="member">text</ref><sp/>(</highlight></codeline>
<codeline lineno="466"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="467"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>Union[<sp/>torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[</highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">],<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="468"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses:<sp/>List[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Synapse&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="469"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs:<sp/>Union[str,<sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor],</highlight></codeline>
<codeline lineno="470"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout:<sp/>int<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="471"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad:<sp/>bool<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="472"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple[<sp/>Union[List[torch.FloatTensor],<sp/>torch.FloatTensor],<sp/>torch.LongTensor,<sp/>torch.FloatTensor]:</highlight></codeline>
<codeline lineno="473"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Forward<sp/>text<sp/>inputs<sp/>to<sp/>a<sp/>list<sp/>of<sp/>neuron<sp/>endpoints<sp/>and<sp/>returns<sp/>logit<sp/>encodings<sp/>or<sp/>timeout.</highlight></codeline>
<codeline lineno="474"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="475"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="476"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`Union[torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>],<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="477"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Endpoints<sp/>to<sp/>send<sp/>inputs<sp/>to.<sp/>Endpoint<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="478"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>tensor<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="479"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>set<sp/>of<sp/>endpoint<sp/>tensors<sp/>shape<sp/>[n,<sp/>250]</highlight></codeline>
<codeline lineno="480"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoints<sp/>tensors<sp/>each<sp/>of<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="481"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>object.<sp/>Inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>this<sp/>endpoint<sp/>alone.</highlight></codeline>
<codeline lineno="482"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoint<sp/>objects.<sp/>All<sp/>inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="483"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="484"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>(:obj:`List[<sp/>&apos;bittensor.Synapse&apos;</highlight><highlight class="normal"><sp/>]`<sp/>of<sp/>shape<sp/>:obj:`(num_synapses)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="485"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Bittensor<sp/>synapse<sp/>objects<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>arguments.<sp/>Each<sp/>corresponds<sp/>to<sp/>a<sp/>synapse<sp/>function<sp/>on<sp/>the<sp/>axon.</highlight></codeline>
<codeline lineno="486"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Responses<sp/>are<sp/>packed<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>this<sp/>ordering.<sp/></highlight></codeline>
<codeline lineno="487"><highlight class="normal"></highlight></codeline>
<codeline lineno="488"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>(:obj:`Union[str,<sp/><sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints<sp/>*<sp/>[batch_size,<sp/>sequence_len])`,<sp/>`required`):</highlight></codeline>
<codeline lineno="489"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Tokenized<sp/>sentences<sp/>to<sp/>send<sp/>on<sp/>the<sp/>wire.<sp/>Inputs<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="490"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>string:<sp/>the<sp/>string<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="491"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>strings:<sp/>the<sp/>strings<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="492"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[batch_size,<sp/>sequence_len],<sp/>assumed<sp/>to<sp/>be<sp/>the<sp/>output<sp/>of<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="493"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[n,<sp/>batch_size,<sp/>sequence_len],<sp/>the<sp/>operation<sp/>will<sp/>unbind<sp/>the<sp/>tensor<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>inputs<sp/>to<sp/>endpoints.</highlight></codeline>
<codeline lineno="494"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>tensors<sp/>of<sp/>type<sp/>long<sp/>each<sp/>representing<sp/>a<sp/>tokenized<sp/>sentence<sp/>to<sp/>be<sp/>sent<sp/>to<sp/>each<sp/>endpoint.</highlight></codeline>
<codeline lineno="495"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>inputs<sp/>are<sp/>tensors<sp/>they<sp/>will<sp/>be<sp/>cast<sp/>to<sp/>int64<sp/>format<sp/>before<sp/>sending<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="496"><highlight class="normal"></highlight></codeline>
<codeline lineno="497"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.timeout<sp/>`optional`):</highlight></codeline>
<codeline lineno="498"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Request<sp/>timeout.<sp/>Queries<sp/>that<sp/>do<sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/>respond<sp/>will<sp/>be<sp/>replaced<sp/>by<sp/>zeros.</highlight></codeline>
<codeline lineno="499"><highlight class="normal"></highlight></codeline>
<codeline lineno="500"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.requires_grad,<sp/>`optional`):</highlight></codeline>
<codeline lineno="501"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>true,<sp/>the<sp/>backward<sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>triggers<sp/>passing<sp/>gradients<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="502"><highlight class="normal"></highlight></codeline>
<codeline lineno="503"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="504"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs<sp/>(:obj:`List[<sp/>List[<sp/>torch.FloatTensor<sp/>]<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`num_synapses<sp/>*<sp/>(<sp/>num_endpoints<sp/>*<sp/>(<sp/>-1,<sp/>-1,<sp/>-1<sp/>)<sp/>)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="505"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>outputs<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>synapses,<sp/>each<sp/>a<sp/>list<sp/>of<sp/>size<sp/>num_endpoints<sp/>of<sp/>tensors<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>relevant<sp/>size.<sp/>Non-responses<sp/>are<sp/>zeroes<sp/>of<sp/>relevant<sp/></highlight></codeline>
<codeline lineno="506"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse<sp/>shape.</highlight></codeline>
<codeline lineno="507"><highlight class="normal"></highlight></codeline>
<codeline lineno="508"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>(:obj:`List<sp/>[<sp/>torch.LongTensor<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="509"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Return<sp/>code<sp/>per<sp/>call<sp/>per<sp/>synapse.</highlight></codeline>
<codeline lineno="510"><highlight class="normal"></highlight></codeline>
<codeline lineno="511"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>(:obj:`List<sp/>[<sp/>torch.FloatTensor<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="512"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Times<sp/>per<sp/>call<sp/>per<sp/>synapse.</highlight></codeline>
<codeline lineno="513"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="514"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints,<sp/>formatted_inputs<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1abab26bb7988e58f64548aef9489d8830" kindref="member">format_text_inputs</ref><sp/>(<sp/></highlight></codeline>
<codeline lineno="515"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>=<sp/>endpoints,<sp/></highlight></codeline>
<codeline lineno="516"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>inputs</highlight></codeline>
<codeline lineno="517"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="518"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs,<sp/>codes,<sp/>times<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ab0bedbfadc59c5895ad47f48f05b7b69" kindref="member">_forward</ref><sp/>(</highlight></codeline>
<codeline lineno="519"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>=<sp/>formatted_endpoints,</highlight></codeline>
<codeline lineno="520"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>synapses,</highlight></codeline>
<codeline lineno="521"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>formatted_inputs,</highlight></codeline>
<codeline lineno="522"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>=<sp/>timeout,</highlight></codeline>
<codeline lineno="523"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>=<sp/>requires_grad,</highlight></codeline>
<codeline lineno="524"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="525"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Return.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="526"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a52f56fdee119d8db1bc4528266623519" kindref="member">update_stats</ref>(<sp/>formatted_endpoints,<sp/>synapses,<sp/>formatted_inputs,<sp/>outputs,<sp/>codes,<sp/>times<sp/>)</highlight></codeline>
<codeline lineno="527"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>outputs,<sp/>codes,<sp/>times</highlight></codeline>
<codeline lineno="528"><highlight class="normal"></highlight></codeline>
<codeline lineno="529"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ad12fdba0d1db1b1e0eb4cd5a8e209d5b" kindref="member">text_causal_lm</ref><sp/>(</highlight></codeline>
<codeline lineno="530"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="531"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>Union<sp/>[<sp/>torch.LongTensor,<sp/>List<sp/>[<sp/>torch.LongTensor<sp/>],<sp/>List[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal"><sp/>],<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="532"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs:<sp/>Union<sp/>[<sp/>str,<sp/>List[<sp/>str<sp/>],<sp/>List<sp/>[<sp/>torch.LongTensor<sp/>],<sp/>torch.LongTensor],</highlight></codeline>
<codeline lineno="533"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse:<sp/>Optional[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.synapse.TextCausalLM&apos;</highlight><highlight class="normal"><sp/>]<sp/>=<sp/>synapse.TextCausalLM(),</highlight></codeline>
<codeline lineno="534"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout:<sp/>Optional<sp/>[<sp/>int<sp/>]<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="535"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad:<sp/>Optional<sp/>[<sp/>bool<sp/>]<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="536"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple[Union[List[torch.FloatTensor],<sp/>torch.FloatTensor],<sp/>torch.LongTensor,<sp/>torch.FloatTensor]:</highlight></codeline>
<codeline lineno="537"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Forward<sp/>text<sp/>inputs<sp/>to<sp/>a<sp/>list<sp/>of<sp/>neuron<sp/>endpoints<sp/>and<sp/>returns<sp/>logit<sp/>encodings<sp/>or<sp/>timeout.</highlight></codeline>
<codeline lineno="538"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="539"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="540"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`Union[torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>],<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="541"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Endpoints<sp/>to<sp/>send<sp/>inputs<sp/>to.<sp/>Endpoint<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="542"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>tensor<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="543"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>set<sp/>of<sp/>endpoint<sp/>tensors<sp/>shape<sp/>[n,<sp/>250]</highlight></codeline>
<codeline lineno="544"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoints<sp/>tensors<sp/>each<sp/>of<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="545"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>object.<sp/>Inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>this<sp/>endpoint<sp/>alone.</highlight></codeline>
<codeline lineno="546"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoint<sp/>objects.<sp/>All<sp/>inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="547"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="548"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="549"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>(:obj:`Union[str,<sp/><sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints<sp/>*<sp/>[batch_size,<sp/>sequence_len])`,<sp/>`required`):</highlight></codeline>
<codeline lineno="550"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Tokenized<sp/>sentences<sp/>to<sp/>send<sp/>on<sp/>the<sp/>wire.<sp/>Inputs<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="551"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>string:<sp/>the<sp/>string<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="552"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>strings:<sp/>the<sp/>strings<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="553"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[batch_size,<sp/>sequence_len],<sp/>assumed<sp/>to<sp/>be<sp/>the<sp/>output<sp/>of<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="554"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[n,<sp/>batch_size,<sp/>sequence_len],<sp/>the<sp/>operation<sp/>will<sp/>unbind<sp/>the<sp/>tensor<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>inputs<sp/>to<sp/>endpoints.</highlight></codeline>
<codeline lineno="555"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>tensors<sp/>of<sp/>type<sp/>long<sp/>each<sp/>representing<sp/>a<sp/>tokenized<sp/>sentence<sp/>to<sp/>be<sp/>sent<sp/>to<sp/>each<sp/>endpoint.</highlight></codeline>
<codeline lineno="556"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>inputs<sp/>are<sp/>tensors<sp/>they<sp/>will<sp/>be<sp/>cast<sp/>to<sp/>int64<sp/>format<sp/>before<sp/>sending<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="557"><highlight class="normal"></highlight></codeline>
<codeline lineno="558"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse<sp/>(:type:`</highlight><highlight class="stringliteral">&apos;bittensor.synapse.TextCausalLM&apos;</highlight><highlight class="normal">`,<sp/>default<sp/>=<sp/>bittensor.synapse.TextCausalLM(),<sp/>`optional`):</highlight></codeline>
<codeline lineno="559"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Synapse<sp/>axon<sp/>function<sp/>call<sp/>which<sp/>defaults<sp/>to<sp/>bittensor.synapse.TextCausalLM().</highlight></codeline>
<codeline lineno="560"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="561"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.timeout<sp/>`optional`):</highlight></codeline>
<codeline lineno="562"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Request<sp/>timeout.<sp/>Queries<sp/>that<sp/>do<sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/>respond<sp/>will<sp/>be<sp/>replaced<sp/>by<sp/>zeros.</highlight></codeline>
<codeline lineno="563"><highlight class="normal"></highlight></codeline>
<codeline lineno="564"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.requires_grad,<sp/>`optional`):</highlight></codeline>
<codeline lineno="565"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>true,<sp/>the<sp/>backward<sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>triggers<sp/>passing<sp/>gradients<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="566"><highlight class="normal"></highlight></codeline>
<codeline lineno="567"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="568"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs<sp/>(:obj:`List[<sp/>torch.FloatTensor<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`num_endpoints<sp/>*<sp/>(batch_size,<sp/>sequence_len,<sp/>bittensor.__vocab_size__<sp/>)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="569"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>output<sp/>logit<sp/>encodings<sp/>of<sp/>inputs<sp/>produced<sp/>by<sp/>each<sp/>remote<sp/>endpoints.<sp/>Non-responses<sp/>are<sp/>zeroes<sp/>of<sp/>input<sp/>shape<sp/>plus<sp/>output<sp/>dimension.</highlight></codeline>
<codeline lineno="570"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>first<sp/>dimension<sp/>will<sp/>match<sp/>the<sp/>number<sp/>of<sp/>endpoints<sp/>queried.</highlight></codeline>
<codeline lineno="571"><highlight class="normal"></highlight></codeline>
<codeline lineno="572"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>(:obj:`torch.LongTensor`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="573"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dendrite<sp/>call<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>ops.</highlight></codeline>
<codeline lineno="574"><highlight class="normal"></highlight></codeline>
<codeline lineno="575"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>(:obj:`torch.FloatTensor`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="576"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>per<sp/>call.</highlight></codeline>
<codeline lineno="577"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="578"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>synapse.synapse_type<sp/>!=<sp/>bittensor.proto.Synapse.SynapseType.TEXT_CAUSAL_LM:</highlight></codeline>
<codeline lineno="579"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(<sp/></highlight><highlight class="stringliteral">&quot;Passed<sp/>synapse<sp/>must<sp/>have<sp/>type:<sp/>{}<sp/>got<sp/>{}<sp/>instead&quot;</highlight><highlight class="normal">.formate(<sp/>bittensor.proto.Synapse.SynapseType.TEXT_CAUSAL_LM,<sp/>synapses.synapse_type<sp/>)<sp/>)</highlight></codeline>
<codeline lineno="580"><highlight class="normal"></highlight></codeline>
<codeline lineno="581"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Format<sp/>inputs.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="582"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints,<sp/>formatted_inputs<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1abab26bb7988e58f64548aef9489d8830" kindref="member">format_text_inputs</ref><sp/>(<sp/></highlight></codeline>
<codeline lineno="583"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>=<sp/>endpoints,<sp/></highlight></codeline>
<codeline lineno="584"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>inputs</highlight></codeline>
<codeline lineno="585"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="586"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Optionally<sp/>convert<sp/>synapses<sp/>and<sp/>set<sp/>typing<sp/>info.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="587"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>[<sp/>synapse<sp/>]</highlight></codeline>
<codeline lineno="588"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Make<sp/>calls.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="589"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs,<sp/>codes,<sp/>times<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ab0bedbfadc59c5895ad47f48f05b7b69" kindref="member">_forward</ref><sp/>(</highlight></codeline>
<codeline lineno="590"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>=<sp/>formatted_endpoints,</highlight></codeline>
<codeline lineno="591"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>synapses,</highlight></codeline>
<codeline lineno="592"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>formatted_inputs,</highlight></codeline>
<codeline lineno="593"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>=<sp/>timeout,</highlight></codeline>
<codeline lineno="594"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>=<sp/>requires_grad,</highlight></codeline>
<codeline lineno="595"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="596"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Return.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="597"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a52f56fdee119d8db1bc4528266623519" kindref="member">update_stats</ref>(<sp/>formatted_endpoints,<sp/>synapses,<sp/>formatted_inputs,<sp/>outputs,<sp/>codes,<sp/>times<sp/>)</highlight></codeline>
<codeline lineno="598"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>outputs[0],<sp/>codes[0],<sp/>times[0]</highlight></codeline>
<codeline lineno="599"><highlight class="normal"></highlight></codeline>
<codeline lineno="600"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a0cf9d7590cb94638a20627417b057c78" kindref="member">text_causal_lm_next</ref>(</highlight></codeline>
<codeline lineno="601"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="602"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>Union[torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[</highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">],<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">],</highlight></codeline>
<codeline lineno="603"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs:<sp/>Union[str,<sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor],</highlight></codeline>
<codeline lineno="604"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse:<sp/>Optional[</highlight><highlight class="stringliteral">&apos;bittensor.synapse.TextCausalLMNext&apos;</highlight><highlight class="normal">]<sp/>=<sp/>synapse.TextCausalLMNext(),</highlight></codeline>
<codeline lineno="605"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout:<sp/>Optional[int]<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="606"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad:<sp/>Optional[bool]<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="607"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple[Union[List[torch.FloatTensor],<sp/>torch.FloatTensor],<sp/>torch.LongTensor,<sp/>torch.FloatTensor]:</highlight></codeline>
<codeline lineno="608"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Forward<sp/>text<sp/>inputs<sp/>to<sp/>a<sp/>list<sp/>of<sp/>neuron<sp/>endpoints<sp/>and<sp/>returns<sp/>logit<sp/>encodings<sp/>or<sp/>timeout.</highlight></codeline>
<codeline lineno="609"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="610"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="611"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`Union[torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>],<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="612"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Endpoints<sp/>to<sp/>send<sp/>inputs<sp/>to.<sp/>Endpoint<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="613"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>tensor<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="614"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>set<sp/>of<sp/>endpoint<sp/>tensors<sp/>shape<sp/>[n,<sp/>250]</highlight></codeline>
<codeline lineno="615"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoints<sp/>tensors<sp/>each<sp/>of<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="616"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>object.<sp/>Inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>this<sp/>endpoint<sp/>alone.</highlight></codeline>
<codeline lineno="617"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoint<sp/>objects.<sp/>All<sp/>inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="618"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="619"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="620"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>(:obj:`Union[str,<sp/><sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints<sp/>*<sp/>[batch_size,<sp/>sequence_len])`,<sp/>`required`):</highlight></codeline>
<codeline lineno="621"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Tokenized<sp/>sentences<sp/>to<sp/>send<sp/>on<sp/>the<sp/>wire.<sp/>Inputs<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="622"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>string:<sp/>the<sp/>string<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="623"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>strings:<sp/>the<sp/>strings<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="624"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[batch_size,<sp/>sequence_len],<sp/>assumed<sp/>to<sp/>be<sp/>the<sp/>output<sp/>of<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="625"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[n,<sp/>batch_size,<sp/>sequence_len],<sp/>the<sp/>operation<sp/>will<sp/>unbind<sp/>the<sp/>tensor<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>inputs<sp/>to<sp/>endpoints.</highlight></codeline>
<codeline lineno="626"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>tensors<sp/>of<sp/>type<sp/>long<sp/>each<sp/>representing<sp/>a<sp/>tokenized<sp/>sentence<sp/>to<sp/>be<sp/>sent<sp/>to<sp/>each<sp/>endpoint.</highlight></codeline>
<codeline lineno="627"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>inputs<sp/>are<sp/>tensors<sp/>they<sp/>will<sp/>be<sp/>cast<sp/>to<sp/>int64<sp/>format<sp/>before<sp/>sending<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="628"><highlight class="normal"></highlight></codeline>
<codeline lineno="629"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse<sp/>(:type:`</highlight><highlight class="stringliteral">&apos;bittensor.synapse.TextCausalLMNext&apos;</highlight><highlight class="normal">`,<sp/>default<sp/>=<sp/>bittensor.synapse.TextCausalLMNext(),<sp/>`optional`):</highlight></codeline>
<codeline lineno="630"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Synapse<sp/>axon<sp/>function<sp/>call<sp/>which<sp/>defaults<sp/>to<sp/>bittensor.synapse.TextCausalLMNext().</highlight></codeline>
<codeline lineno="631"><highlight class="normal"></highlight></codeline>
<codeline lineno="632"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.timeout<sp/>`optional`):</highlight></codeline>
<codeline lineno="633"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Request<sp/>timeout.<sp/>Queries<sp/>that<sp/>do<sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/>respond<sp/>will<sp/>be<sp/>replaced<sp/>by<sp/>zeros.</highlight></codeline>
<codeline lineno="634"><highlight class="normal"></highlight></codeline>
<codeline lineno="635"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.requires_grad,<sp/>`optional`):</highlight></codeline>
<codeline lineno="636"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>true,<sp/>the<sp/>backward<sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>triggers<sp/>passing<sp/>gradients<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="637"><highlight class="normal"></highlight></codeline>
<codeline lineno="638"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="639"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs<sp/>(:obj:`List[<sp/>torch.FloatTensor<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`num_endpoints<sp/>*<sp/>(<sp/>&gt;=<sp/>batch_size<sp/>*<sp/>(2<sp/>*<sp/>topk<sp/>+<sp/>1)<sp/>)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="640"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>output<sp/>topk<sp/>phrases<sp/>encodings<sp/>of<sp/>inputs<sp/>produced<sp/>by<sp/>each<sp/>remote<sp/>endpoints.</highlight></codeline>
<codeline lineno="641"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Non-responses<sp/>are<sp/>zeroes<sp/>of<sp/>input<sp/>shape<sp/>plus<sp/>output<sp/>dimension.</highlight></codeline>
<codeline lineno="642"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>first<sp/>dimension<sp/>will<sp/>match<sp/>the<sp/>number<sp/>of<sp/>endpoints<sp/>queried.</highlight></codeline>
<codeline lineno="643"><highlight class="normal"></highlight></codeline>
<codeline lineno="644"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>(:obj:`torch.LongTensor`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="645"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dendrite<sp/>call<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>ops.</highlight></codeline>
<codeline lineno="646"><highlight class="normal"></highlight></codeline>
<codeline lineno="647"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>(:obj:`torch.FloatTensor`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="648"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>per<sp/>call.</highlight></codeline>
<codeline lineno="649"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="650"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>synapse.synapse_type<sp/>!=<sp/>bittensor.proto.Synapse.SynapseType.TEXT_CAUSAL_LM_NEXT:</highlight></codeline>
<codeline lineno="651"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(f</highlight><highlight class="stringliteral">&quot;Passed<sp/>synapse<sp/>must<sp/>have<sp/>type:<sp/>{bittensor.proto.Synapse.SynapseType.TEXT_CAUSAL_LM_NEXT}<sp/>&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="652"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>f</highlight><highlight class="stringliteral">&quot;got<sp/>{synapse.synapse_type}<sp/>instead&quot;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="653"><highlight class="normal"></highlight></codeline>
<codeline lineno="654"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Format<sp/>inputs.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="655"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints,<sp/>formatted_inputs<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1abab26bb7988e58f64548aef9489d8830" kindref="member">format_text_inputs</ref>(</highlight></codeline>
<codeline lineno="656"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints=endpoints,</highlight></codeline>
<codeline lineno="657"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs=inputs</highlight></codeline>
<codeline lineno="658"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="659"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Optionally<sp/>convert<sp/>synapses<sp/>and<sp/>set<sp/>typing<sp/>info.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="660"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>[synapse]</highlight></codeline>
<codeline lineno="661"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Make<sp/>calls.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="662"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs,<sp/>codes,<sp/>times<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ab0bedbfadc59c5895ad47f48f05b7b69" kindref="member">_forward</ref>(</highlight></codeline>
<codeline lineno="663"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints=formatted_endpoints,</highlight></codeline>
<codeline lineno="664"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses=synapses,</highlight></codeline>
<codeline lineno="665"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs=formatted_inputs,</highlight></codeline>
<codeline lineno="666"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout=timeout,</highlight></codeline>
<codeline lineno="667"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad=requires_grad,</highlight></codeline>
<codeline lineno="668"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="669"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Return.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="670"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a52f56fdee119d8db1bc4528266623519" kindref="member">update_stats</ref>(formatted_endpoints,<sp/>synapses,<sp/>formatted_inputs,<sp/>outputs,<sp/>codes,<sp/>times)</highlight></codeline>
<codeline lineno="671"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>outputs[0],<sp/>codes[0],<sp/>times[0]</highlight></codeline>
<codeline lineno="672"><highlight class="normal"></highlight></codeline>
<codeline lineno="673"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a847c81a7312898dcca79439dab3e1420" kindref="member">text_last_hidden_state</ref>(</highlight></codeline>
<codeline lineno="674"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="675"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>Union[<sp/>torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[</highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">],<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="676"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs:<sp/>Union[str,<sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor],</highlight></codeline>
<codeline lineno="677"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse:<sp/>Optional[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.synapse.TextLastHiddenState&apos;</highlight><highlight class="normal"><sp/>]<sp/>=<sp/>synapse.TextLastHiddenState(),</highlight></codeline>
<codeline lineno="678"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout:<sp/>int<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="679"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad:<sp/>bool<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="680"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple[Union[List[torch.FloatTensor],<sp/>torch.FloatTensor],<sp/>torch.LongTensor,<sp/>torch.FloatTensor]:</highlight></codeline>
<codeline lineno="681"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Forward<sp/>text<sp/>inputs<sp/>to<sp/>a<sp/>list<sp/>of<sp/>neuron<sp/>endpoints<sp/>and<sp/>block<sp/>until<sp/>last<sp/>hidden<sp/>state<sp/>responses<sp/>or<sp/>timeout.</highlight></codeline>
<codeline lineno="682"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="683"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="684"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`Union[torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>],<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="685"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Endpoints<sp/>to<sp/>send<sp/>inputs<sp/>to.<sp/>Endpoint<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="686"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>tensor<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="687"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>set<sp/>of<sp/>endpoint<sp/>tensors<sp/>shape<sp/>[n,<sp/>250]</highlight></codeline>
<codeline lineno="688"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoints<sp/>tensors<sp/>each<sp/>of<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="689"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>object.<sp/>Inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>this<sp/>endpoint<sp/>alone.</highlight></codeline>
<codeline lineno="690"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoint<sp/>objects.<sp/>All<sp/>inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="691"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="692"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>(:obj:`Union[str,<sp/><sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints<sp/>*<sp/>[batch_size,<sp/>sequence_len])`,<sp/>`required`):</highlight></codeline>
<codeline lineno="693"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Tokenized<sp/>sentences<sp/>to<sp/>send<sp/>on<sp/>the<sp/>wire.<sp/>Inputs<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="694"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>string:<sp/>the<sp/>string<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="695"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>strings:<sp/>the<sp/>strings<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="696"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[batch_size,<sp/>sequence_len],<sp/>assumed<sp/>to<sp/>be<sp/>the<sp/>output<sp/>of<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="697"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[n,<sp/>batch_size,<sp/>sequence_len],<sp/>the<sp/>operation<sp/>will<sp/>unbind<sp/>the<sp/>tensor<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>inputs<sp/>to<sp/>endpoints.</highlight></codeline>
<codeline lineno="698"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>inputs<sp/>are<sp/>tensors<sp/>they<sp/>will<sp/>be<sp/>cast<sp/>to<sp/>int64<sp/>format<sp/>before<sp/>sending<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="699"><highlight class="normal"></highlight></codeline>
<codeline lineno="700"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse<sp/>(:type:`</highlight><highlight class="stringliteral">&apos;bittensor.synapse.TextLastHiddenState&apos;</highlight><highlight class="normal">`,<sp/>default<sp/>=<sp/>bittensor.synapse.TextLastHiddenState(),<sp/>`optional`):</highlight></codeline>
<codeline lineno="701"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Synapse<sp/>axon<sp/>function<sp/>call<sp/>which<sp/>defaults<sp/>to<sp/>bittensor.synapse.TextLastHiddenState().</highlight></codeline>
<codeline lineno="702"><highlight class="normal"></highlight></codeline>
<codeline lineno="703"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.timeout<sp/>`optional`):</highlight></codeline>
<codeline lineno="704"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Request<sp/>timeout.<sp/>Queries<sp/>that<sp/>do<sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/>respond<sp/>will<sp/>be<sp/>replaced<sp/>by<sp/>zeros.</highlight></codeline>
<codeline lineno="705"><highlight class="normal"></highlight></codeline>
<codeline lineno="706"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>(:type:`int`,<sp/>default<sp/>=<sp/>dendrite.requires_grad,<sp/>`optional`):</highlight></codeline>
<codeline lineno="707"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>true,<sp/>the<sp/>backward<sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>triggers<sp/>passing<sp/>gradients<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="708"><highlight class="normal"></highlight></codeline>
<codeline lineno="709"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="710"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs<sp/>(:obj:`List<sp/>[<sp/>torch.FloatTensor<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`<sp/>num_endpoints<sp/>*<sp/>(<sp/>-1,<sp/>sequence_len,<sp/>bittensor.__network_dim__<sp/>)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="711"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>output<sp/>last<sp/>hidden<sp/>state<sp/>encodings<sp/>of<sp/>inputs<sp/>produced<sp/>by<sp/>remote<sp/>endpoints.<sp/>Non-responses<sp/>are<sp/>zeroes<sp/>of<sp/>input<sp/>shape<sp/>plus<sp/>output<sp/>dimension.</highlight></codeline>
<codeline lineno="712"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>first<sp/>dimension<sp/>will<sp/>match<sp/>the<sp/>number<sp/>of<sp/>endpoints<sp/>queried.</highlight></codeline>
<codeline lineno="713"><highlight class="normal"></highlight></codeline>
<codeline lineno="714"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>(:obj:`torch.LongTensor`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="715"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dendrite<sp/>call<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>ops.</highlight></codeline>
<codeline lineno="716"><highlight class="normal"></highlight></codeline>
<codeline lineno="717"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>(:obj:`torch.FloatTensor`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="718"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>per<sp/>call.</highlight></codeline>
<codeline lineno="719"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="720"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>synapse.synapse_type<sp/>!=<sp/>bittensor.proto.Synapse.SynapseType.TEXT_LAST_HIDDEN_STATE:</highlight></codeline>
<codeline lineno="721"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(<sp/></highlight><highlight class="stringliteral">&quot;Passed<sp/>synapse<sp/>must<sp/>have<sp/>type:{}<sp/>got:{}<sp/>instead&quot;</highlight><highlight class="normal">.formate(<sp/>bittensor.proto.Synapse.SynapseType.TEXT_LAST_HIDDEN_STATE,<sp/>synapses.synapse_type<sp/>)<sp/>)</highlight></codeline>
<codeline lineno="722"><highlight class="normal"></highlight></codeline>
<codeline lineno="723"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Format<sp/>inputs.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="724"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints,<sp/>formatted_inputs<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1abab26bb7988e58f64548aef9489d8830" kindref="member">format_text_inputs</ref><sp/>(<sp/></highlight></codeline>
<codeline lineno="725"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>=<sp/>endpoints,<sp/></highlight></codeline>
<codeline lineno="726"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>inputs</highlight></codeline>
<codeline lineno="727"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="728"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>[<sp/>synapse<sp/>]</highlight></codeline>
<codeline lineno="729"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Make<sp/>calls.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="730"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs,<sp/>codes,<sp/>times<sp/>=<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1ab0bedbfadc59c5895ad47f48f05b7b69" kindref="member">_forward</ref><sp/>(</highlight></codeline>
<codeline lineno="731"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>=<sp/>formatted_endpoints,</highlight></codeline>
<codeline lineno="732"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>=<sp/>synapses,</highlight></codeline>
<codeline lineno="733"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>formatted_inputs,</highlight></codeline>
<codeline lineno="734"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>timeout<sp/>=<sp/>timeout,</highlight></codeline>
<codeline lineno="735"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requires_grad<sp/>=<sp/>requires_grad,</highlight></codeline>
<codeline lineno="736"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="737"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Return.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="738"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a52f56fdee119d8db1bc4528266623519" kindref="member">update_stats</ref>(<sp/>formatted_endpoints,<sp/>synapses,<sp/>formatted_inputs,<sp/>outputs,<sp/>codes,<sp/>times<sp/>)</highlight></codeline>
<codeline lineno="739"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>outputs[0],<sp/>codes[0],<sp/>times[0]</highlight></codeline>
<codeline lineno="740"><highlight class="normal"></highlight></codeline>
<codeline lineno="741"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1abab26bb7988e58f64548aef9489d8830" kindref="member">format_text_inputs</ref><sp/>(</highlight></codeline>
<codeline lineno="742"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="743"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>Union[<sp/>torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[</highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">],<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal"><sp/>],</highlight></codeline>
<codeline lineno="744"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs:<sp/>Union[str,<sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor],</highlight></codeline>
<codeline lineno="745"><highlight class="normal"><sp/><sp/><sp/><sp/>)<sp/>-&gt;<sp/>Tuple[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">,<sp/>List[torch.LongTensor]<sp/>]:</highlight></codeline>
<codeline lineno="746"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Formats<sp/>endpoint<sp/>and<sp/>inputs<sp/>args<sp/>to<sp/>a<sp/>common<sp/>format.</highlight></codeline>
<codeline lineno="747"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="748"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`Union[torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>],<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="749"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Endpoints<sp/>to<sp/>send<sp/>inputs<sp/>to.<sp/>Endpoint<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="750"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>tensor<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="751"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>set<sp/>of<sp/>endpoint<sp/>tensors<sp/>shape<sp/>[n,<sp/>250]</highlight></codeline>
<codeline lineno="752"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoints<sp/>tensors<sp/>each<sp/>of<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="753"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>object.<sp/>Inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>this<sp/>endpoint<sp/>alone.</highlight></codeline>
<codeline lineno="754"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoint<sp/>objects.<sp/>All<sp/>inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="755"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="756"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>(:obj:`Union[str,<sp/><sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints<sp/>*<sp/>[batch_size,<sp/>sequence_len])`,<sp/>`required`):</highlight></codeline>
<codeline lineno="757"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Tokenized<sp/>sentences<sp/>to<sp/>send<sp/>on<sp/>the<sp/>wire.<sp/>Inputs<sp/>can<sp/>be<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="758"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>string:<sp/>the<sp/>string<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="759"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>strings:<sp/>the<sp/>strings<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="760"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[batch_size,<sp/>sequence_len],<sp/>assumed<sp/>to<sp/>be<sp/>the<sp/>output<sp/>of<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="761"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[n,<sp/>batch_size,<sp/>sequence_len],<sp/>the<sp/>operation<sp/>will<sp/>unbind<sp/>the<sp/>tensor<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>inputs<sp/>to<sp/>endpoints.</highlight></codeline>
<codeline lineno="762"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/>inputs<sp/>are<sp/>tensors<sp/>they<sp/>will<sp/>be<sp/>cast<sp/>to<sp/>int64<sp/>format<sp/>before<sp/>sending<sp/>on<sp/>the<sp/>wire.</highlight></codeline>
<codeline lineno="763"><highlight class="normal"></highlight></codeline>
<codeline lineno="764"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="765"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints<sp/>(:obj:`Union[torch.LongTensor,<sp/>List[torch.LongTensor],<sp/>List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>],<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="766"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>A<sp/>list<sp/>of<sp/>endpoint<sp/>objects.<sp/>All<sp/>inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="767"><highlight class="normal"></highlight></codeline>
<codeline lineno="768"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_inputs<sp/>(:obj:`Union[str,<sp/><sp/>List[str],<sp/>List[torch.LongTensor],<sp/>torch.LongTensor]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints<sp/>*<sp/>[batch_size,<sp/>sequence_len])`,<sp/>`required`):</highlight></codeline>
<codeline lineno="769"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>A<sp/>list<sp/>of<sp/>tensor<sp/>of<sp/>type<sp/>long<sp/>each<sp/>representing<sp/>a<sp/>tokenized<sp/>sentence<sp/>to<sp/>be<sp/>sent<sp/>to<sp/>each<sp/>endpoint.</highlight></codeline>
<codeline lineno="770"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="771"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>To<sp/>be<sp/>filled.<sp/>Inputs<sp/>and<sp/>endpoint<sp/>must<sp/>be<sp/>list<sp/>with<sp/>the<sp/>same<sp/>number<sp/>of<sp/>elements.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="772"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_inputs<sp/>=<sp/>[]</highlight></codeline>
<codeline lineno="773"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints<sp/>=<sp/>[]</highlight></codeline>
<codeline lineno="774"><highlight class="normal"></highlight></codeline>
<codeline lineno="775"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>&lt;&lt;Helper<sp/>function&gt;&gt;<sp/>optional<sp/>casts<sp/>and<sp/>then<sp/>checks<sp/>shape<sp/>of<sp/>inputs.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="776"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">cast_and_check_tensor_input(tensor_input)<sp/>-&gt;<sp/>torch.LongTensor:</highlight></codeline>
<codeline lineno="777"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/>isinstance(tensor_input,<sp/>torch.LongTensor):</highlight></codeline>
<codeline lineno="778"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">try</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="779"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>tensor_input<sp/>=<sp/>tensor_input.to(torch.int64)</highlight></codeline>
<codeline lineno="780"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">except</highlight><highlight class="normal"><sp/>Exception<sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>E:</highlight></codeline>
<codeline lineno="781"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>error_msg<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;Error<sp/>while<sp/>casting<sp/>tensor<sp/>input<sp/>{}<sp/>to<sp/>int64<sp/>{}&apos;</highlight><highlight class="normal">.format(tensor_input,<sp/>E)</highlight></codeline>
<codeline lineno="782"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(error_msg)<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>ValueError()</highlight></codeline>
<codeline lineno="783"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/>(isinstance(tensor_input,<sp/>torch.cuda.LongTensor)<sp/></highlight><highlight class="keywordflow">or</highlight><highlight class="normal"><sp/>isinstance(tensor_input,<sp/>torch.LongTensor)):</highlight></codeline>
<codeline lineno="784"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(</highlight></codeline>
<codeline lineno="785"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;input<sp/>{}<sp/>must<sp/>be<sp/>of<sp/>type<sp/>torch.LongTensor.<sp/>Got<sp/>{}&apos;</highlight><highlight class="normal">.format(tensor_input,<sp/>type(tensor_input)))</highlight></codeline>
<codeline lineno="786"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Expand<sp/>shape<sp/>if<sp/>it<sp/>is<sp/>a<sp/>singular<sp/>dimension.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="787"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>len(tensor_input.shape)<sp/>==<sp/>1:</highlight></codeline>
<codeline lineno="788"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>tensor_input<sp/>=<sp/>tensor_input.view(1,<sp/>-1)</highlight></codeline>
<codeline lineno="789"><highlight class="normal"></highlight></codeline>
<codeline lineno="790"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Check<sp/>shape.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="791"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>len(tensor_input.shape)<sp/>!=<sp/>2:</highlight></codeline>
<codeline lineno="792"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>error_msg<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;Text<sp/>inputs<sp/>should<sp/>be<sp/>rank<sp/>2<sp/>with<sp/>semantic<sp/>shape:<sp/>[batch_size,<sp/>sequence_len]&apos;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="793"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(error_msg)</highlight></codeline>
<codeline lineno="794"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>tensor_input</highlight></codeline>
<codeline lineno="795"><highlight class="normal"></highlight></codeline>
<codeline lineno="796"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Endpoints<sp/>is<sp/>singular.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="797"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>isinstance(endpoints,<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>):</highlight></codeline>
<codeline lineno="798"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints<sp/>=<sp/>[endpoints]</highlight></codeline>
<codeline lineno="799"><highlight class="normal"></highlight></codeline>
<codeline lineno="800"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Endpoints<sp/>is<sp/>a<sp/>list<sp/>of<sp/>Endpoints.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="801"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>isinstance(endpoints,<sp/>list)<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>len(endpoints)<sp/>&gt;<sp/>0<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>isinstance(endpoints[0],<sp/><ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>):</highlight></codeline>
<codeline lineno="802"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints<sp/>=<sp/>endpoints</highlight></codeline>
<codeline lineno="803"><highlight class="normal"></highlight></codeline>
<codeline lineno="804"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Endpoints<sp/>is<sp/>a<sp/>torch<sp/>tensor.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="805"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>isinstance(endpoints,<sp/>torch.LongTensor):</highlight></codeline>
<codeline lineno="806"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>len(endpoints.shape)<sp/>==<sp/>1:</highlight></codeline>
<codeline lineno="807"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints<sp/>=<sp/>[bittensor.endpoint.from_tensor(endpoints)]</highlight></codeline>
<codeline lineno="808"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>len(endpoints.shape)<sp/>==<sp/>2:</highlight></codeline>
<codeline lineno="809"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints<sp/>=<sp/>[bittensor.endpoint.from_tensor(row)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>row<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>endpoints]</highlight></codeline>
<codeline lineno="810"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="811"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>error_msg<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;Endpoints<sp/>tensor<sp/>should<sp/>have<sp/>semantic<sp/>shape<sp/>[n,<sp/>250],<sp/>got<sp/>{}&apos;</highlight><highlight class="normal">.format(endpoints)</highlight></codeline>
<codeline lineno="812"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(error_msg)</highlight></codeline>
<codeline lineno="813"><highlight class="normal"></highlight></codeline>
<codeline lineno="814"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Endpoints<sp/>is<sp/>a<sp/>list<sp/>of<sp/>tensors.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="815"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>isinstance(endpoints,<sp/>list)<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>len(endpoints)<sp/>&gt;<sp/>0<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>isinstance(endpoints[0],<sp/>torch.LongTensor):</highlight></codeline>
<codeline lineno="816"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>tensor<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>endpoints:</highlight></codeline>
<codeline lineno="817"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>len(tensor.shape)<sp/>==<sp/>1:</highlight></codeline>
<codeline lineno="818"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints.append(bittensor.endpoint.from_tensor(tensor))</highlight></codeline>
<codeline lineno="819"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>len(tensor.shape)<sp/>==<sp/>2:</highlight></codeline>
<codeline lineno="820"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>row<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>tensor:</highlight></codeline>
<codeline lineno="821"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints.append(bittensor.endpoint.from_tensor(row))</highlight></codeline>
<codeline lineno="822"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="823"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>error_msg<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;Endpoints<sp/>tensor<sp/>should<sp/>have<sp/>semantic<sp/>shape<sp/>[n,<sp/>250],<sp/>got<sp/>{}&apos;</highlight><highlight class="normal">.format(tensor)</highlight></codeline>
<codeline lineno="824"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(error_msg)</highlight></codeline>
<codeline lineno="825"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="826"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>error_msg<sp/>=<sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;<sp/>Endpoints<sp/>should<sp/>have<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types.</highlight></codeline>
<codeline lineno="827"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>tensor<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="828"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>set<sp/>of<sp/>endpoint<sp/>tensors<sp/>shape<sp/>[n,<sp/>250]</highlight></codeline>
<codeline lineno="829"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoints<sp/>tensors<sp/>each<sp/>of<sp/>shape<sp/>[250]</highlight></codeline>
<codeline lineno="830"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>endpoint<sp/>object.<sp/>Inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>this<sp/>endpoint<sp/>alone.</highlight></codeline>
<codeline lineno="831"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>endpoint<sp/>objects.<sp/>All<sp/>inputs<sp/>will<sp/>be<sp/>sent<sp/>to<sp/>these<sp/>endpoints.</highlight></codeline>
<codeline lineno="832"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Got<sp/>{}<sp/>&quot;&quot;&quot;.format(endpoints)</highlight></codeline>
<codeline lineno="833"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(error_msg)</highlight></codeline>
<codeline lineno="834"><highlight class="normal"></highlight></codeline>
<codeline lineno="835"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Inputs<sp/>is<sp/>a<sp/>string</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="836"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>isinstance(inputs,<sp/>str):</highlight></codeline>
<codeline lineno="837"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Encode<sp/>to<sp/>tensors.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="838"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>tokenizer<sp/>=<sp/><ref refid="classbittensor_1_1__tokenizer_1_1tokenizer" kindref="compound">bittensor.tokenizer</ref>()</highlight></codeline>
<codeline lineno="839"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs_list<sp/>=<sp/><ref refid="classbittensor_1_1__tokenizer_1_1tokenizer" kindref="compound">tokenizer</ref>(inputs)[</highlight><highlight class="stringliteral">&apos;input_ids&apos;</highlight><highlight class="normal">]</highlight></codeline>
<codeline lineno="840"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs_tensor<sp/>=<sp/>cast_and_check_tensor_input(torch.tensor([inputs_list],<sp/>dtype=torch.int64))</highlight></codeline>
<codeline lineno="841"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Expand<sp/>to<sp/>length.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="842"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_inputs<sp/>=<sp/>[inputs_tensor<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>_<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>formatted_endpoints]</highlight></codeline>
<codeline lineno="843"><highlight class="normal"></highlight></codeline>
<codeline lineno="844"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Inputs<sp/>is<sp/>a<sp/>list<sp/>of<sp/>strings.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="845"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>isinstance(inputs,<sp/>list)<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>len(inputs)<sp/>&gt;<sp/>0<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>isinstance(inputs[0],<sp/>str):</highlight></codeline>
<codeline lineno="846"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Encode<sp/>to<sp/>tensors.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="847"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>tokenizer<sp/>=<sp/><ref refid="classbittensor_1_1__tokenizer_1_1tokenizer" kindref="compound">bittensor.tokenizer</ref>()</highlight></codeline>
<codeline lineno="848"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>tokenized_sentences<sp/>=<sp/><ref refid="classbittensor_1_1__tokenizer_1_1tokenizer" kindref="compound">tokenizer</ref>(inputs,<sp/>padding<sp/>=<sp/></highlight><highlight class="keyword">True</highlight><highlight class="normal">,<sp/>truncation=</highlight><highlight class="keyword">True</highlight><highlight class="normal">)[</highlight><highlight class="stringliteral">&apos;input_ids&apos;</highlight><highlight class="normal">]</highlight></codeline>
<codeline lineno="849"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>tokenizer_tensor<sp/>=<sp/>cast_and_check_tensor_input(torch.tensor(tokenized_sentences,<sp/>dtype=torch.int64))</highlight></codeline>
<codeline lineno="850"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_inputs<sp/>=<sp/>[tokenizer_tensor<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>_<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>formatted_endpoints]</highlight></codeline>
<codeline lineno="851"><highlight class="normal"></highlight></codeline>
<codeline lineno="852"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Inputs<sp/>is<sp/>a<sp/>single<sp/>tensor</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="853"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>isinstance(inputs,<sp/>torch.Tensor)<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>len(inputs.shape)<sp/>&lt;=<sp/>2:</highlight></codeline>
<codeline lineno="854"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>=<sp/>cast_and_check_tensor_input(inputs)</highlight></codeline>
<codeline lineno="855"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Expand<sp/>to<sp/>length.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="856"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_inputs<sp/>=<sp/>[inputs<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>_<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>formatted_endpoints]</highlight></codeline>
<codeline lineno="857"><highlight class="normal"></highlight></codeline>
<codeline lineno="858"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Inputs<sp/>is<sp/>tensor<sp/>with<sp/>shape<sp/>[n_endpoints,<sp/>batch_size,<sp/>sequence_len]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="859"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>isinstance(inputs,<sp/>torch.Tensor)<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>len(inputs.shape)<sp/>==<sp/>3<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>inputs.shape[0]<sp/>==<sp/>len(</highlight></codeline>
<codeline lineno="860"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_endpoints):</highlight></codeline>
<codeline lineno="861"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Unbind<sp/>inputs<sp/>into<sp/>list<sp/>the<sp/>same<sp/>length<sp/>as<sp/>endpoints.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="862"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_inputs<sp/>=<sp/>[cast_and_check_tensor_input(input)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>input<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>torch.unbind(inputs)]</highlight></codeline>
<codeline lineno="863"><highlight class="normal"></highlight></codeline>
<codeline lineno="864"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Inputs<sp/>is<sp/>a<sp/>list<sp/>of<sp/>tensors</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="865"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">elif</highlight><highlight class="normal"><sp/>isinstance(inputs,<sp/>list)<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>len(inputs)<sp/>&gt;<sp/>0<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>isinstance(inputs[0],<sp/>torch.Tensor):</highlight></codeline>
<codeline lineno="866"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>formatted_inputs<sp/>=<sp/>[cast_and_check_tensor_input(input)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>input<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>inputs]</highlight></codeline>
<codeline lineno="867"><highlight class="normal"></highlight></codeline>
<codeline lineno="868"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="869"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>error_msg<sp/>=<sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;<sp/>Inputs<sp/>should<sp/>have<sp/>one<sp/>of<sp/>the<sp/>following<sp/>types:</highlight></codeline>
<codeline lineno="870"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>single<sp/>string:<sp/>the<sp/>string<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="871"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>list<sp/>of<sp/>strings:<sp/>the<sp/>strings<sp/>will<sp/>be<sp/>tokenized<sp/>using<sp/>the<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="872"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[batch_size,<sp/>sequence_len],<sp/>assumed<sp/>to<sp/>be<sp/>the<sp/>output<sp/>of<sp/>bittensor<sp/>tokenizer.</highlight></codeline>
<codeline lineno="873"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>-<sp/>a<sp/>tensor<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>shape<sp/>[n,<sp/>batch_size,<sp/>sequence_len],<sp/>the<sp/>operation<sp/>will<sp/>unbind<sp/>the<sp/>tensor<sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"><sp/>inputs<sp/>to<sp/>endpoints.</highlight></codeline>
<codeline lineno="874"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Got<sp/>{}<sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;.format(inputs)</highlight></codeline>
<codeline lineno="875"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(error_msg)</highlight></codeline>
<codeline lineno="876"><highlight class="normal"></highlight></codeline>
<codeline lineno="877"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>----<sp/>Check<sp/>length.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="878"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>len(formatted_inputs)<sp/>!=<sp/>len(formatted_endpoints):</highlight></codeline>
<codeline lineno="879"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>error_msg<sp/>=<sp/></highlight><highlight class="stringliteral">&apos;List<sp/>of<sp/>text<sp/>inputs<sp/>should<sp/>have<sp/>the<sp/>same<sp/>length<sp/>as<sp/>passed<sp/>destination<sp/>endpoints,<sp/>got<sp/>{}<sp/>and<sp/>{}&apos;</highlight><highlight class="normal">.format(</highlight></codeline>
<codeline lineno="880"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>len(inputs),<sp/>len(endpoints))</highlight></codeline>
<codeline lineno="881"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(error_msg)</highlight></codeline>
<codeline lineno="882"><highlight class="normal"></highlight></codeline>
<codeline lineno="883"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>formatted_endpoints,<sp/>formatted_inputs</highlight></codeline>
<codeline lineno="884"><highlight class="normal"></highlight></codeline>
<codeline lineno="885"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal">_init_stats(self):</highlight></codeline>
<codeline lineno="886"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>SimpleNamespace(</highlight></codeline>
<codeline lineno="887"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>total_requests<sp/>=<sp/>0,</highlight></codeline>
<codeline lineno="888"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>queries<sp/>on<sp/>dendrite<sp/>per<sp/>second.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="889"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>qps<sp/>=<sp/>stat_utils.EventsPerSecondRollingAverage(<sp/>0,<sp/>0.01<sp/>),</highlight></codeline>
<codeline lineno="890"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>total<sp/>bytes<sp/>recieved<sp/>by<sp/>this<sp/>dendrite<sp/>per<sp/>second.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="891"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>avg_in_bytes_per_second<sp/>=<sp/>stat_utils.AmountPerSecondRollingAverage(<sp/>0,<sp/>0.01<sp/>),</highlight></codeline>
<codeline lineno="892"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>total<sp/>sent<sp/>by<sp/>this<sp/>dendrite<sp/>per<sp/>second.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="893"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>avg_out_bytes_per_second<sp/>=<sp/>stat_utils.AmountPerSecondRollingAverage(<sp/>0,<sp/>0.01<sp/>),</highlight></codeline>
<codeline lineno="894"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Codes<sp/>recieved<sp/>per<sp/>pubkey.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="895"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes_per_pubkey<sp/>=<sp/>{},</highlight></codeline>
<codeline lineno="896"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Number<sp/>of<sp/>requests<sp/>per<sp/>pubkey.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="897"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>requests_per_pubkey<sp/>=<sp/>{},</highlight></codeline>
<codeline lineno="898"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Success<sp/>rate<sp/>per<sp/>pubkey.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="899"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>successes_per_pubkey<sp/>=<sp/>{},</highlight></codeline>
<codeline lineno="900"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Query<sp/>time<sp/>per<sp/>pubkey.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="901"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>query_times_per_pubkey<sp/>=<sp/>{},</highlight></codeline>
<codeline lineno="902"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Bytes<sp/>recieved<sp/>per<sp/>pubkey.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="903"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>avg_in_bytes_per_pubkey<sp/>=<sp/>{},</highlight></codeline>
<codeline lineno="904"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Bytes<sp/>sent<sp/>per<sp/>pubkey.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="905"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>avg_out_bytes_per_pubkey<sp/>=<sp/>{},</highlight></codeline>
<codeline lineno="906"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>QPS<sp/>per<sp/>pubkey.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="907"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>qps_per_pubkey<sp/>=<sp/>{},</highlight></codeline>
<codeline lineno="908"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="909"><highlight class="normal"></highlight></codeline>
<codeline lineno="910"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a52f56fdee119d8db1bc4528266623519" kindref="member">update_stats</ref>(</highlight></codeline>
<codeline lineno="911"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,<sp/></highlight></codeline>
<codeline lineno="912"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints:<sp/>List[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.Endpoint&apos;</highlight><highlight class="normal">],<sp/></highlight></codeline>
<codeline lineno="913"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses:<sp/>List[<sp/></highlight><highlight class="stringliteral">&apos;bittensor.proto.Synapse&apos;</highlight><highlight class="normal"><sp/>],<sp/></highlight></codeline>
<codeline lineno="914"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs:<sp/>List[torch.Tensor],</highlight></codeline>
<codeline lineno="915"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs:<sp/>List[<sp/>List[<sp/>torch.Tensor<sp/>]<sp/>],</highlight></codeline>
<codeline lineno="916"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes:<sp/>List<sp/>[<sp/>List[<sp/>torch.LongTensor<sp/>]<sp/>],</highlight></codeline>
<codeline lineno="917"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times:<sp/>List<sp/>[<sp/>List[<sp/>torch.FloatTensor<sp/>]<sp/>]</highlight></codeline>
<codeline lineno="918"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>):</highlight></codeline>
<codeline lineno="919"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Update<sp/>dendrite<sp/>stat<sp/>according<sp/>to<sp/>the<sp/>response<sp/>we<sp/>get<sp/>from<sp/>peers.<sp/>Updates<sp/>were<sp/>saved<sp/>to<sp/>self.stats.</highlight></codeline>
<codeline lineno="920"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="921"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>endpoints<sp/>(:obj:`List[<ref refid="classbittensor_1_1__endpoint_1_1endpoint__impl_1_1_endpoint" kindref="compound">bittensor.Endpoint</ref>]`<sp/>of<sp/>shape<sp/>:obj:`(num_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="922"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>The<sp/>set<sp/>of<sp/>endpoints<sp/>that<sp/>dendrite<sp/>sent<sp/>request<sp/>to.</highlight></codeline>
<codeline lineno="923"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="924"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapses<sp/>(:obj:`List[<sp/>&apos;bittensor.Synapse&apos;</highlight><highlight class="normal"><sp/>]`<sp/>of<sp/>shape<sp/>:obj:`(num_synapses)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="925"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Bittensor<sp/>synapse<sp/>objects<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>arguments.<sp/>Each<sp/>corresponds<sp/>to<sp/>a<sp/>synapse<sp/>function<sp/>on<sp/>the<sp/>axon.</highlight></codeline>
<codeline lineno="926"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Responses<sp/>are<sp/>packed<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>this<sp/>ordering.<sp/></highlight></codeline>
<codeline lineno="927"><highlight class="normal"></highlight></codeline>
<codeline lineno="928"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>inputs<sp/>(:obj:`List[torch.Tensor]`<sp/>of<sp/>shape<sp/>:obj:`(n_endpoints)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="929"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>torch<sp/>tensors<sp/>to<sp/>be<sp/>sent<sp/>to<sp/>the<sp/>associated<sp/>endpoints.</highlight></codeline>
<codeline lineno="930"><highlight class="normal"></highlight></codeline>
<codeline lineno="931"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>outputs<sp/>(:obj:`List[<sp/>List[<sp/>torch.FloatTensor<sp/>]<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`num_synapses<sp/>*<sp/>(<sp/>num_endpoints<sp/>*<sp/>(<sp/>-1,<sp/>-1,<sp/>-1<sp/>)<sp/>)`,<sp/>`required`):</highlight></codeline>
<codeline lineno="932"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>List<sp/>of<sp/>outputs<sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>synapses,<sp/>each<sp/>a<sp/>list<sp/>of<sp/>size<sp/>num_endpoints<sp/>of<sp/>tensors<sp/></highlight><highlight class="keyword">with</highlight><highlight class="normal"><sp/>relevant<sp/>size.<sp/>Non-responses<sp/>are<sp/>zeroes<sp/>of<sp/>relevant<sp/></highlight></codeline>
<codeline lineno="933"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>synapse<sp/>shape.</highlight></codeline>
<codeline lineno="934"><highlight class="normal"></highlight></codeline>
<codeline lineno="935"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>codes<sp/>(:obj:`List<sp/>[<sp/>torch.LongTensor<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="936"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Return<sp/>code<sp/>per<sp/>call<sp/>per<sp/>synapse.</highlight></codeline>
<codeline lineno="937"><highlight class="normal"></highlight></codeline>
<codeline lineno="938"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>times<sp/>(:obj:`List<sp/>[<sp/>torch.FloatTensor<sp/>]`<sp/>of<sp/>shape<sp/>:obj:`[<sp/>num_endpoints<sp/>]`,<sp/>`required`):</highlight></codeline>
<codeline lineno="939"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Times<sp/>per<sp/>call<sp/>per<sp/>synapse.</highlight></codeline>
<codeline lineno="940"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="941"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.qps.event()</highlight></codeline>
<codeline lineno="942"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.total_requests<sp/>+=<sp/>1</highlight></codeline>
<codeline lineno="943"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>total_in_bytes_per_second<sp/>=<sp/>0</highlight></codeline>
<codeline lineno="944"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_out_bytes_per_second.event(<sp/>float(sys.getsizeof(inputs))<sp/>)</highlight></codeline>
<codeline lineno="945"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(end_i,<sp/>syn_i,<sp/>inps_i,<sp/>outs_i,<sp/>codes_i,<sp/>times_i)<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>list(<sp/>zip<sp/>(<sp/>endpoints,<sp/>synapses,<sp/>inputs,<sp/>outputs,<sp/>codes,<sp/>times<sp/>)<sp/>):</highlight></codeline>
<codeline lineno="946"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>pubkey<sp/>=<sp/>end_i.hotkey</highlight></codeline>
<codeline lineno="947"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>First<sp/>time<sp/>for<sp/>this<sp/>pubkey<sp/>we<sp/>create<sp/>a<sp/>new<sp/>entry.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="948"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>pubkey<sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.requests_per_pubkey:</highlight></codeline>
<codeline lineno="949"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.requests_per_pubkey[pubkey]<sp/>=<sp/>0</highlight></codeline>
<codeline lineno="950"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.successes_per_pubkey[pubkey]<sp/>=<sp/>0</highlight></codeline>
<codeline lineno="951"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.codes_per_pubkey[pubkey]<sp/>=<sp/>dict([(k,0)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>k<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>bittensor.proto.ReturnCode.keys()])</highlight></codeline>
<codeline lineno="952"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.query_times_per_pubkey[pubkey]<sp/>=<sp/>stat_utils.AmountPerSecondRollingAverage(<sp/>0,<sp/>0.01<sp/>)</highlight></codeline>
<codeline lineno="953"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_in_bytes_per_pubkey[pubkey]<sp/>=<sp/>stat_utils.AmountPerSecondRollingAverage(<sp/>0,<sp/>0.01<sp/>)</highlight></codeline>
<codeline lineno="954"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_out_bytes_per_pubkey[pubkey]<sp/>=<sp/>stat_utils.AmountPerSecondRollingAverage(<sp/>0,<sp/>0.01<sp/>)</highlight></codeline>
<codeline lineno="955"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.qps_per_pubkey[pubkey]<sp/>=<sp/>stat_utils.EventsPerSecondRollingAverage(<sp/>0,<sp/>0.01<sp/>)</highlight></codeline>
<codeline lineno="956"><highlight class="normal"></highlight></codeline>
<codeline lineno="957"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.requests_per_pubkey[pubkey]<sp/>+=<sp/>1</highlight></codeline>
<codeline lineno="958"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.successes_per_pubkey[pubkey]<sp/>+=<sp/>(codes_i<sp/>==<sp/>1).sum().int()</highlight></codeline>
<codeline lineno="959"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.query_times_per_pubkey[pubkey].event(<sp/>float(<sp/>times_i.max()<sp/>)<sp/>)</highlight></codeline>
<codeline lineno="960"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_in_bytes_per_pubkey[pubkey].event(<sp/>float(sys.getsizeof(<sp/>outs_i<sp/>))<sp/>)</highlight></codeline>
<codeline lineno="961"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_out_bytes_per_pubkey[pubkey].event(<sp/>float(sys.getsizeof(<sp/>inps_i<sp/>))<sp/>)</highlight></codeline>
<codeline lineno="962"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.qps_per_pubkey[pubkey].event()</highlight></codeline>
<codeline lineno="963"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>total_in_bytes_per_second<sp/>+=<sp/>sys.getsizeof(outs_i)<sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(codes_i<sp/>==<sp/>1).sum().int()<sp/>==<sp/>len(<sp/>synapses<sp/>)<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>0<sp/></highlight></codeline>
<codeline lineno="964"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">try</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="965"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>code_i_s<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>codes_i:</highlight></codeline>
<codeline lineno="966"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>bittensor.proto.ReturnCode.Name(code_i_s)<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.codes_per_pubkey[pubkey].keys():</highlight></codeline>
<codeline lineno="967"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.codes_per_pubkey[pubkey][bittensor.proto.ReturnCode.Name(code_i_s)]<sp/>+=<sp/>1</highlight></codeline>
<codeline lineno="968"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">except</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="969"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Code<sp/>may<sp/>be<sp/>faulty.</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="970"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">pass</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="971"><highlight class="normal"></highlight></codeline>
<codeline lineno="972"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_in_bytes_per_second.event(<sp/>float(<sp/>total_in_bytes_per_second<sp/>)<sp/>)</highlight></codeline>
<codeline lineno="973"><highlight class="normal"></highlight></codeline>
<codeline lineno="974"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a162b4285d8ae80681dc18c33379aa38d" kindref="member">to_dataframe</ref><sp/>(<sp/>self,<sp/>metagraph<sp/>):</highlight></codeline>
<codeline lineno="975"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Return<sp/>a<sp/>stats<sp/>info<sp/>as<sp/>a<sp/>pandas<sp/>dataframe<sp/>indexed<sp/>by<sp/>the<sp/>metagraph<sp/>or<sp/>pubkey<sp/>if<sp/>not<sp/>existend.</highlight></codeline>
<codeline lineno="976"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="977"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>metagraph:<sp/>(<ref refid="classbittensor_1_1__metagraph_1_1metagraph__impl_1_1_metagraph" kindref="compound">bittensor.Metagraph</ref>):</highlight></codeline>
<codeline lineno="978"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Indexes<sp/>the<sp/>stats<sp/>data<sp/>using<sp/>metagraph<sp/>hotkeys.</highlight></codeline>
<codeline lineno="979"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Return:</highlight></codeline>
<codeline lineno="980"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dataframe<sp/>(:obj:`pandas.Dataframe`)</highlight></codeline>
<codeline lineno="981"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="982"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">try</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="983"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>index<sp/>=<sp/>[<sp/>metagraph.hotkeys.index(pubkey)<sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>pubkey<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.requests_per_pubkey.keys()<sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>pubkey<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>metagraph.hotkeys]</highlight></codeline>
<codeline lineno="984"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>columns<sp/>=<sp/>[<sp/></highlight><highlight class="stringliteral">&apos;dendrite_n_requested&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_n_success&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_query_time&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_avg_inbytes&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_avg_outbytes&apos;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&apos;dendrite_qps&apos;</highlight><highlight class="normal"><sp/>]</highlight></codeline>
<codeline lineno="985"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dataframe<sp/>=<sp/>pandas.DataFrame(columns<sp/>=<sp/>columns,<sp/>index<sp/>=<sp/>index)</highlight></codeline>
<codeline lineno="986"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>pubkey<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.requests_per_pubkey.keys():</highlight></codeline>
<codeline lineno="987"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>pubkey<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>metagraph.hotkeys:</highlight></codeline>
<codeline lineno="988"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>uid<sp/>=<sp/>metagraph.hotkeys.index(pubkey)</highlight></codeline>
<codeline lineno="989"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>dataframe.loc[<sp/>uid<sp/>]<sp/>=<sp/>pandas.Series(<sp/>{</highlight></codeline>
<codeline lineno="990"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite_n_requested&apos;</highlight><highlight class="normal">:<sp/>int(self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.requests_per_pubkey[pubkey]),</highlight></codeline>
<codeline lineno="991"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite_n_success&apos;</highlight><highlight class="normal">:<sp/>int(self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.successes_per_pubkey[pubkey]),</highlight></codeline>
<codeline lineno="992"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite_query_time&apos;</highlight><highlight class="normal">:<sp/>float(self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.query_times_per_pubkey[pubkey].get()),<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="993"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite_avg_inbytes&apos;</highlight><highlight class="normal">:<sp/>float(self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_in_bytes_per_pubkey[pubkey].get()),</highlight></codeline>
<codeline lineno="994"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite_avg_outbytes&apos;</highlight><highlight class="normal">:<sp/>float(self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_out_bytes_per_pubkey[pubkey].get()),</highlight></codeline>
<codeline lineno="995"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite_qps&apos;</highlight><highlight class="normal">:<sp/>float(self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.qps_per_pubkey[pubkey].get())</highlight></codeline>
<codeline lineno="996"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}<sp/>)</highlight></codeline>
<codeline lineno="997"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>dataframe</highlight></codeline>
<codeline lineno="998"><highlight class="normal"></highlight></codeline>
<codeline lineno="999"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">except</highlight><highlight class="normal"><sp/>Exception<sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>e:</highlight></codeline>
<codeline lineno="1000"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>bittensor.logging.error(<sp/>prefix=</highlight><highlight class="stringliteral">&apos;failed<sp/>dendrite.to_dataframe()&apos;</highlight><highlight class="normal">,<sp/>sufix=str(e)<sp/>)</highlight></codeline>
<codeline lineno="1001"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>pandas.DataFrame()</highlight></codeline>
<codeline lineno="1002"><highlight class="normal"></highlight></codeline>
<codeline lineno="1003"><highlight class="normal"></highlight></codeline>
<codeline lineno="1004"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1a9489a72a71cd70e2b6bf11aa4a892d5b" kindref="member">to_wandb</ref>(<sp/>self<sp/>):</highlight></codeline>
<codeline lineno="1005"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">r&quot;&quot;&quot;<sp/>Return<sp/>a<sp/>dictionary<sp/>of<sp/>dendrite<sp/>stats<sp/>as<sp/>wandb<sp/>logging<sp/>info.</highlight></codeline>
<codeline lineno="1006"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="1007"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>metagraph:<sp/>(<ref refid="classbittensor_1_1__metagraph_1_1metagraph__impl_1_1_metagraph" kindref="compound">bittensor.Metagraph</ref>):</highlight></codeline>
<codeline lineno="1008"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>If<sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,<sp/>indexes<sp/>the<sp/>wandb<sp/>data<sp/>using<sp/>int<sp/>uids<sp/>rather<sp/>than<sp/>string<sp/>pubkeys.</highlight></codeline>
<codeline lineno="1009"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Return:</highlight></codeline>
<codeline lineno="1010"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>wandb_info<sp/>(:obj:`Dict`)</highlight></codeline>
<codeline lineno="1011"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="1012"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">try</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="1013"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>wandb_info<sp/>=<sp/>{</highlight></codeline>
<codeline lineno="1014"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite/qps&apos;</highlight><highlight class="normal">:<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.qps.get(),</highlight></codeline>
<codeline lineno="1015"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite/total_requests&apos;</highlight><highlight class="normal"><sp/>:<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1aba6742399ca4fb120ffc9437d82e0751" kindref="member">receptor_pool</ref>.get_total_requests(),</highlight></codeline>
<codeline lineno="1016"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite/avg_in_bytes_per_second&apos;</highlight><highlight class="normal"><sp/>:<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_in_bytes_per_second.get(),</highlight></codeline>
<codeline lineno="1017"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite/avg_out_bytes_per_second&apos;</highlight><highlight class="normal"><sp/>:<sp/>self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.avg_out_bytes_per_second.get(),</highlight></codeline>
<codeline lineno="1018"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&apos;dendrite/Total<sp/>unique<sp/>queries&apos;</highlight><highlight class="normal">:<sp/>len(self.<ref refid="classbittensor_1_1__dendrite_1_1dendrite__impl_1_1_dendrite_1affd0640a693e4281a8a0927cd4058859" kindref="member">stats</ref>.requests_per_pubkey.keys()),</highlight></codeline>
<codeline lineno="1019"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="1020"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>wandb_info</highlight></codeline>
<codeline lineno="1021"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">except</highlight><highlight class="normal"><sp/>Exception<sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>e:</highlight></codeline>
<codeline lineno="1022"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>bittensor.logging.error(<sp/>prefix=</highlight><highlight class="stringliteral">&apos;failed<sp/>dendrite.to_wandb()&apos;</highlight><highlight class="normal">,<sp/>sufix<sp/>=<sp/>str(e))</highlight></codeline>
<codeline lineno="1023"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>{}</highlight></codeline>
    </programlisting>
    <location file="/Users/macthrasher/bittensor/bittensor/_dendrite/dendrite_impl.py"/>
  </compounddef>
</doxygen>
